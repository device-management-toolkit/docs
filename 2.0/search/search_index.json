{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 Open Active Management Technology Cloud Toolkit ( Open AMT Cloud Toolkit ) provides open-source, modular microservices and libraries for integration of Intel\u00ae Active Management Technology ( Intel\u00ae AMT ). As an open source implementation, the toolkit makes it easier for IT departments and independent software vendors (ISVs) to adopt, integrate, and customize Out-of-band Management ( OOB Management ) solutions for Intel vPro\u00ae Platforms. Figure 1: Open AMT Cloud Toolkit features OOB Management . Intel\u00ae AMT supports remote manageability with: OOB Management : This hardware-based remote management solution operates below the operating system. Call Home : This capability enables administrators to control, update, and modify remote clients with OOB Management . Goals \u00b6 The toolkit guide provides instructions to: Deploy the Management Presence Server ( MPS ) and Remote Provisioning Server ( RPS ) on the development system. Build and run Remote Provisioning Client ( RPC ) on the managed device. Connect the managed device (edge device). Additional sections provide guidance on the reference implementation UI Toolkit , REST API usage, asset security, and more. Figure 2: High-level architecture consists of four major software components. As shown in Figure 2, Open AMT Cloud Toolkit high-level architecture consists of five components: MPS - A microservice that uses an Intel vPro\u00ae Platform feature, Client Initiated Remote Access ( CIRA ), for enabling edge, cloud devices to maintain a persistent connection for out-of-band manageability features, such as power control or Keyboard, Video, Mouse ( KVM ) control. RPS - A microservice that activates Intel\u00ae AMT platforms using predefined profiles and connects them to the MPS for manageability use cases. RPC - A lightweight client application that communicates with the RPS server to activate Intel\u00ae AMT . UI Toolkit - A toolkit that includes prebuilt React components and a reference implementation web console. The React-based snippets simplify the task of adding complex manageability-related UI controls, such as the KVM , to a console. Sample Web UI - A web based UI that demonstrates how to use the UI-Toolkit. It also provides a way to interact with the microservices and to help provide context as to how each microservice is used. Integrate the Open AMT Cloud Toolkit into new and existing management consoles, software solutions, and more. Toolkit Setup \u00b6 Microservices as Containers \u00b6 Set up microservices quickly as Docker containers with this recommended method. Get Started Now Estimated completion time: Approximately 30 minutes Additional Intel\u00ae AMT Resources \u00b6 For additional information about Intel\u00ae AMT , see the following links: Intel vPro\u00ae Platform Overview Video Link Detailed Setup document","title":"Overview"},{"location":"#overview","text":"Open Active Management Technology Cloud Toolkit ( Open AMT Cloud Toolkit ) provides open-source, modular microservices and libraries for integration of Intel\u00ae Active Management Technology ( Intel\u00ae AMT ). As an open source implementation, the toolkit makes it easier for IT departments and independent software vendors (ISVs) to adopt, integrate, and customize Out-of-band Management ( OOB Management ) solutions for Intel vPro\u00ae Platforms. Figure 1: Open AMT Cloud Toolkit features OOB Management . Intel\u00ae AMT supports remote manageability with: OOB Management : This hardware-based remote management solution operates below the operating system. Call Home : This capability enables administrators to control, update, and modify remote clients with OOB Management .","title":"Overview"},{"location":"#goals","text":"The toolkit guide provides instructions to: Deploy the Management Presence Server ( MPS ) and Remote Provisioning Server ( RPS ) on the development system. Build and run Remote Provisioning Client ( RPC ) on the managed device. Connect the managed device (edge device). Additional sections provide guidance on the reference implementation UI Toolkit , REST API usage, asset security, and more. Figure 2: High-level architecture consists of four major software components. As shown in Figure 2, Open AMT Cloud Toolkit high-level architecture consists of five components: MPS - A microservice that uses an Intel vPro\u00ae Platform feature, Client Initiated Remote Access ( CIRA ), for enabling edge, cloud devices to maintain a persistent connection for out-of-band manageability features, such as power control or Keyboard, Video, Mouse ( KVM ) control. RPS - A microservice that activates Intel\u00ae AMT platforms using predefined profiles and connects them to the MPS for manageability use cases. RPC - A lightweight client application that communicates with the RPS server to activate Intel\u00ae AMT . UI Toolkit - A toolkit that includes prebuilt React components and a reference implementation web console. The React-based snippets simplify the task of adding complex manageability-related UI controls, such as the KVM , to a console. Sample Web UI - A web based UI that demonstrates how to use the UI-Toolkit. It also provides a way to interact with the microservices and to help provide context as to how each microservice is used. Integrate the Open AMT Cloud Toolkit into new and existing management consoles, software solutions, and more.","title":"Goals"},{"location":"#toolkit-setup","text":"","title":"Toolkit Setup"},{"location":"#microservices-as-containers","text":"Set up microservices quickly as Docker containers with this recommended method. Get Started Now Estimated completion time: Approximately 30 minutes","title":"Microservices as Containers"},{"location":"#additional-intel-amt-resources","text":"For additional information about Intel\u00ae AMT , see the following links: Intel vPro\u00ae Platform Overview Video Link Detailed Setup document","title":"Additional Intel\u00ae AMT Resources"},{"location":"Glossary/","text":"Glossary \u00b6 Open Active Management Technology (Open AMT) Cloud Toolkit, also referred to as (OAMTCT) Related Terminology, Technologies, and Acronyms A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z A \u00b6 admin control mode (ACM): A mode of provisioning Intel\u00ae AMT that requires a purchased provisioning certificate from a Certificate Authority (CA), the creation of a domain, and the creation of a profile in the Remote Provisioning Server (RPS) application. ACM achieves a higher level of trust than client control mode (CCM). This is the required mode for Keyboard, Video, Mouse (KVM) or Redirection without user consent. See also CCM and provisioning . ACM Activation: The act of loading a purchased certificate and associating it with an OAMTCT profile. allowlist: A list permitting access to a privilege, service, network, etc. B \u00b6 Basic Input/Output System (BIOS): Firmware that performs hardware initialization and configuration upon startup. See MEBX . C \u00b6 certificate (provisioning): A digitally signed document used in the provisioning of an edge device featuring Intel\u00ae AMT. The Intel\u00ae AMT firmware is pre-loaded with Transport Layer Security (TLS) certificate thumbprints of different certificate vendors. A digital certificate binds the identity of the certificate holder to vendor-specific thumbprints. To provision an edge device, users must purchase a certificate from an approved vendor. Client Initiated Remote Access (CIRA): An out-of-band (OOB) management communication protocol that network clients can use to initiate a secure connection with a server. Client Control Mode (CCM): An alternative to ACM provisioning mode that does not require a purchased certificate. Use this mode to set up OAMTCT software features quickly. Container (Docker*): The instantiation, or running instance, of a Docker image. D \u00b6 development system: The system on which Management Presence Server (MPS) and Remote Provision Server (RPS) are installed. Docker*: A platform that employs the idea of containerization, isolating a unit of software, such as an application, from its environment. Containerization creates applications as lightweight, discrete processes that can be deployed to the cloud as services. See Docker for more information. Domain Name System (DNS) suffix: A suffix appended to the hostname of a DNS name. domain suffix: The top-level portion or end of a domain name (i.e., com, net, org). E \u00b6 Edge Devices: A device or piece of hardware that serves as an entry point into an enterprise or service provider network. Edge devices include those related to banking, retail, hospitality, point-of-sale, etc. G \u00b6 Globally Unique Identifier (GUID): A 128-bit integer used to identify a system resource. I \u00b6 Intel\u00ae Active Management Technology (Intel\u00ae AMT): A technology that provides out-of-band management and security features on an Intel vPro\u00ae Platform. See general overview of features. Intel vPro\u00ae Platform: An Intel\u00ae platform created for business environments. Intel vPro\u00ae technology features Intel\u00ae Core\u2122 i5, Intel\u00ae Core\u2122 i7, and Intel\u00ae Core\u2122 i9 vPro\u00ae processors, built-in security features, and out-of-band manageability using Intel\u00ae AMT. See more about the platform. Images (Docker*): a set of instructions that determine the creation of an instantiated container on a Docker platform. K \u00b6 Keyboard, Video, Mouse (KVM): A technology, often a device, that allows a user to control multiple computers from a single keyboard, mouse, and video source. L \u00b6 lights-out management (LOM): See out-of-band management . M \u00b6 managed (edge) device: An Intel vPro\u00ae Platform that features Intel\u00ae AMT and functions as an edge device. Manageability Engine BIOS Extensions (MEBX): A BIOS extension that enables the configuration of the Intel\u00ae AMT. Management Presence Server (MPS): A microservice that resides on the development system and enables platforms featuring featuring Intel\u00ae AMT. The MPS receives CIRA requests from the managed device. microservice: A software unit or module of a microservice architecture. In OAMTCT architecture, MPS and RPS are microservices residing on the development system. microservice architecture: An architecture in which the component parts are broken into discrete services, called microservices, that perform specific, limited functions. N \u00b6 Node.js*: An open source JavaScript* runtime created for asynchronous, event-driven backend network applications. See more about node.js. Node Package Manager (npm): a command line utility in node.js. The utility enables the management of packages, versions, and dependencies in node projects. O \u00b6 Open Active Management Technology (Open AMT) Cloud Toolkit: An open source software architecture consisting of modular microservices and libraries for integration of out-of-band manageability into existing network infrastructures. The software enables network administrators and independent software vendors (ISVs) to explore key Intel\u00ae AMT features. See more about Open AMT Cloud Toolkit features. out-of-band (OOB) manageability: A remote management technology that allows administrators to perform actions on network assets or devices using a secure alternative to LAN-based communication protocols. Actions include reboot, power up, power down, system updates, and more. As long as the network device or asset is connected to power, OAMTCT software can perform remote management, including powering up a system that is currently powered down. P \u00b6 profile : A set of configuration information, including a password and provisioning method, provided to Intel\u00ae AMT firmware during the activation process. provision or provisioning: The act of setting up a remote client, system, or device, on a network using a digitally signed certificate as a security credential. Q \u00b6 R \u00b6 Remote Provision Client (RPC): A lightweight client application that resides on the managed device. The RPC communicates with the Manageability Engine Interface (MEI) in the Management Engine (ME) driver to activate Intel\u00ae AMT. Remote Provision Server (RPS): A node.js-based microservice that works with the Remote Provision Client (RPC) to activate Intel\u00ae AMT using a pre-defined profile. REpresentational State Transfer (REST) API : An architectural style or set of rules describing constraints that allow administrators and developers to take advantage of various Web services. In the context of OAMTCT, administrators can construct REST API calls and run them with node, use provided REST code snippets to expand the reference implementation console, and use provided REST code snippets as a springboard for developing and expanding custom consoles. S \u00b6 Sample Web UI: A reference UI implementation serving as a demo vehicle and utilizing components of the UI toolkit. T \u00b6 U \u00b6 UI Toolkit: A modular, REST-based API consisting of code snippets developers can use to implement AMT features and services to their manageability console. V \u00b6 vcpkg : A command-line application that helps manage package creation and C and C++ libraries on Windows , Linux , and MacOS*. Vault storage : A service that manages encryption and storage of infrastructure secrets. W \u00b6 WebSocket*: A communication protocol that enables persistent connections and full-duplex communication between clients and servers. Web Service Management (WS-MAN): A SOAP-based protocol for exchanging management data between network devices. X \u00b6 Y \u00b6 Z \u00b6","title":"Glossary"},{"location":"Glossary/#glossary","text":"Open Active Management Technology (Open AMT) Cloud Toolkit, also referred to as (OAMTCT) Related Terminology, Technologies, and Acronyms A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z","title":"Glossary"},{"location":"Glossary/#a","text":"admin control mode (ACM): A mode of provisioning Intel\u00ae AMT that requires a purchased provisioning certificate from a Certificate Authority (CA), the creation of a domain, and the creation of a profile in the Remote Provisioning Server (RPS) application. ACM achieves a higher level of trust than client control mode (CCM). This is the required mode for Keyboard, Video, Mouse (KVM) or Redirection without user consent. See also CCM and provisioning . ACM Activation: The act of loading a purchased certificate and associating it with an OAMTCT profile. allowlist: A list permitting access to a privilege, service, network, etc.","title":"A"},{"location":"Glossary/#b","text":"Basic Input/Output System (BIOS): Firmware that performs hardware initialization and configuration upon startup. See MEBX .","title":"B"},{"location":"Glossary/#c","text":"certificate (provisioning): A digitally signed document used in the provisioning of an edge device featuring Intel\u00ae AMT. The Intel\u00ae AMT firmware is pre-loaded with Transport Layer Security (TLS) certificate thumbprints of different certificate vendors. A digital certificate binds the identity of the certificate holder to vendor-specific thumbprints. To provision an edge device, users must purchase a certificate from an approved vendor. Client Initiated Remote Access (CIRA): An out-of-band (OOB) management communication protocol that network clients can use to initiate a secure connection with a server. Client Control Mode (CCM): An alternative to ACM provisioning mode that does not require a purchased certificate. Use this mode to set up OAMTCT software features quickly. Container (Docker*): The instantiation, or running instance, of a Docker image.","title":"C"},{"location":"Glossary/#d","text":"development system: The system on which Management Presence Server (MPS) and Remote Provision Server (RPS) are installed. Docker*: A platform that employs the idea of containerization, isolating a unit of software, such as an application, from its environment. Containerization creates applications as lightweight, discrete processes that can be deployed to the cloud as services. See Docker for more information. Domain Name System (DNS) suffix: A suffix appended to the hostname of a DNS name. domain suffix: The top-level portion or end of a domain name (i.e., com, net, org).","title":"D"},{"location":"Glossary/#e","text":"Edge Devices: A device or piece of hardware that serves as an entry point into an enterprise or service provider network. Edge devices include those related to banking, retail, hospitality, point-of-sale, etc.","title":"E"},{"location":"Glossary/#g","text":"Globally Unique Identifier (GUID): A 128-bit integer used to identify a system resource.","title":"G"},{"location":"Glossary/#i","text":"Intel\u00ae Active Management Technology (Intel\u00ae AMT): A technology that provides out-of-band management and security features on an Intel vPro\u00ae Platform. See general overview of features. Intel vPro\u00ae Platform: An Intel\u00ae platform created for business environments. Intel vPro\u00ae technology features Intel\u00ae Core\u2122 i5, Intel\u00ae Core\u2122 i7, and Intel\u00ae Core\u2122 i9 vPro\u00ae processors, built-in security features, and out-of-band manageability using Intel\u00ae AMT. See more about the platform. Images (Docker*): a set of instructions that determine the creation of an instantiated container on a Docker platform.","title":"I"},{"location":"Glossary/#k","text":"Keyboard, Video, Mouse (KVM): A technology, often a device, that allows a user to control multiple computers from a single keyboard, mouse, and video source.","title":"K"},{"location":"Glossary/#l","text":"lights-out management (LOM): See out-of-band management .","title":"L"},{"location":"Glossary/#m","text":"managed (edge) device: An Intel vPro\u00ae Platform that features Intel\u00ae AMT and functions as an edge device. Manageability Engine BIOS Extensions (MEBX): A BIOS extension that enables the configuration of the Intel\u00ae AMT. Management Presence Server (MPS): A microservice that resides on the development system and enables platforms featuring featuring Intel\u00ae AMT. The MPS receives CIRA requests from the managed device. microservice: A software unit or module of a microservice architecture. In OAMTCT architecture, MPS and RPS are microservices residing on the development system. microservice architecture: An architecture in which the component parts are broken into discrete services, called microservices, that perform specific, limited functions.","title":"M"},{"location":"Glossary/#n","text":"Node.js*: An open source JavaScript* runtime created for asynchronous, event-driven backend network applications. See more about node.js. Node Package Manager (npm): a command line utility in node.js. The utility enables the management of packages, versions, and dependencies in node projects.","title":"N"},{"location":"Glossary/#o","text":"Open Active Management Technology (Open AMT) Cloud Toolkit: An open source software architecture consisting of modular microservices and libraries for integration of out-of-band manageability into existing network infrastructures. The software enables network administrators and independent software vendors (ISVs) to explore key Intel\u00ae AMT features. See more about Open AMT Cloud Toolkit features. out-of-band (OOB) manageability: A remote management technology that allows administrators to perform actions on network assets or devices using a secure alternative to LAN-based communication protocols. Actions include reboot, power up, power down, system updates, and more. As long as the network device or asset is connected to power, OAMTCT software can perform remote management, including powering up a system that is currently powered down.","title":"O"},{"location":"Glossary/#p","text":"profile : A set of configuration information, including a password and provisioning method, provided to Intel\u00ae AMT firmware during the activation process. provision or provisioning: The act of setting up a remote client, system, or device, on a network using a digitally signed certificate as a security credential.","title":"P"},{"location":"Glossary/#q","text":"","title":"Q"},{"location":"Glossary/#r","text":"Remote Provision Client (RPC): A lightweight client application that resides on the managed device. The RPC communicates with the Manageability Engine Interface (MEI) in the Management Engine (ME) driver to activate Intel\u00ae AMT. Remote Provision Server (RPS): A node.js-based microservice that works with the Remote Provision Client (RPC) to activate Intel\u00ae AMT using a pre-defined profile. REpresentational State Transfer (REST) API : An architectural style or set of rules describing constraints that allow administrators and developers to take advantage of various Web services. In the context of OAMTCT, administrators can construct REST API calls and run them with node, use provided REST code snippets to expand the reference implementation console, and use provided REST code snippets as a springboard for developing and expanding custom consoles.","title":"R"},{"location":"Glossary/#s","text":"Sample Web UI: A reference UI implementation serving as a demo vehicle and utilizing components of the UI toolkit.","title":"S"},{"location":"Glossary/#t","text":"","title":"T"},{"location":"Glossary/#u","text":"UI Toolkit: A modular, REST-based API consisting of code snippets developers can use to implement AMT features and services to their manageability console.","title":"U"},{"location":"Glossary/#v","text":"vcpkg : A command-line application that helps manage package creation and C and C++ libraries on Windows , Linux , and MacOS*. Vault storage : A service that manages encryption and storage of infrastructure secrets.","title":"V"},{"location":"Glossary/#w","text":"WebSocket*: A communication protocol that enables persistent connections and full-duplex communication between clients and servers. Web Service Management (WS-MAN): A SOAP-based protocol for exchanging management data between network devices.","title":"W"},{"location":"Glossary/#x","text":"","title":"X"},{"location":"Glossary/#y","text":"","title":"Y"},{"location":"Glossary/#z","text":"","title":"Z"},{"location":"announcements/","text":"Announcements \u00b6 Open AMT Cloud Toolkit 2.0 is here! \u00b6 We have been preparing for this for quite a while and we know many of our customers have been eagerly awaiting this announcement, our Long Term Support (LTS) release is here! What does having an LTS release mean? \u00b6 Starting with LTS, Open AMT Cloud Toolkit will now have two release streams that customers can use. The current Rapid release stream continues to operate as it has been since the beginning of this year. Every six weeks we'll release new features and fixes that customers can use to add out-of-band functionality to their device management solution. For Long Term Support releases, new features will be added roughly every six months. Only critical security and bug fixes will be applied between feature releases, maintaining a stable feature set for the LTS release. When we release a new LTS version, all of the features in the current Rapid release stream will be merged to the LTS release stream. Similar to Rapid Releases, only the latest LTS release will be actively supported and maintained. With this release, both the Rapid and LTS releases are set to 2.0 and have the exact same feature set. As we continue to release new Rapid releases, the Rapid release stream will continue to add new features while the LTS release stream will continue with the 2.0 feature set. Compatibility between versions \u00b6 As we previously announced, with the major version change, we are strictly following semantic versioning, making all 2.X components compatible with each other. It also means that our 1.X components are not supported with 2.X components. In this release, all of our components have been versioned up to 2.0 and validated together to ensure compatibility. While both Rapid and LTS releases that share the same major version should be compatible with each other, we won't be validating Rapid and LTS combinations, so it is recommended that customers use either all Rapid or all LTS components. Changes coming for Remote Provisioning Client \u00b6 For 2.0, we are deprecating the C++ version of RPC in favor of our Go-based implementation. The reason for this is two-fold. First, we want to be able to take advantage of more modern tooling such as Snyk for Vulnerability Scanning, and Dependabot for dependency updates, among others. Secondly, the cloud focused technologies and protocols we use, which include REST and Websockets, have better support in modern languages. We still needed to balance the interaction between the AMT Firmware and the cloud which led to Go being a natural choice to use. With the 2.0 release, we are providing an early look at the Go version of RPC . Over the next few Rapid releases the functionality of the Go version will exceed that of the C++ version and customers will be encouraged to migrate. The entire Open AMT Cloud Toolkit team hopes you are as excited about this release as we are and we look forward to continuing to working with you! You can read more about this release in our release notes .","title":"Announcements"},{"location":"announcements/#announcements","text":"","title":"Announcements"},{"location":"announcements/#open-amt-cloud-toolkit-20-is-here","text":"We have been preparing for this for quite a while and we know many of our customers have been eagerly awaiting this announcement, our Long Term Support (LTS) release is here!","title":"Open AMT Cloud Toolkit 2.0 is here!"},{"location":"announcements/#what-does-having-an-lts-release-mean","text":"Starting with LTS, Open AMT Cloud Toolkit will now have two release streams that customers can use. The current Rapid release stream continues to operate as it has been since the beginning of this year. Every six weeks we'll release new features and fixes that customers can use to add out-of-band functionality to their device management solution. For Long Term Support releases, new features will be added roughly every six months. Only critical security and bug fixes will be applied between feature releases, maintaining a stable feature set for the LTS release. When we release a new LTS version, all of the features in the current Rapid release stream will be merged to the LTS release stream. Similar to Rapid Releases, only the latest LTS release will be actively supported and maintained. With this release, both the Rapid and LTS releases are set to 2.0 and have the exact same feature set. As we continue to release new Rapid releases, the Rapid release stream will continue to add new features while the LTS release stream will continue with the 2.0 feature set.","title":"What does having an LTS release mean?"},{"location":"announcements/#compatibility-between-versions","text":"As we previously announced, with the major version change, we are strictly following semantic versioning, making all 2.X components compatible with each other. It also means that our 1.X components are not supported with 2.X components. In this release, all of our components have been versioned up to 2.0 and validated together to ensure compatibility. While both Rapid and LTS releases that share the same major version should be compatible with each other, we won't be validating Rapid and LTS combinations, so it is recommended that customers use either all Rapid or all LTS components.","title":"Compatibility between versions"},{"location":"announcements/#changes-coming-for-remote-provisioning-client","text":"For 2.0, we are deprecating the C++ version of RPC in favor of our Go-based implementation. The reason for this is two-fold. First, we want to be able to take advantage of more modern tooling such as Snyk for Vulnerability Scanning, and Dependabot for dependency updates, among others. Secondly, the cloud focused technologies and protocols we use, which include REST and Websockets, have better support in modern languages. We still needed to balance the interaction between the AMT Firmware and the cloud which led to Go being a natural choice to use. With the 2.0 release, we are providing an early look at the Go version of RPC . Over the next few Rapid releases the functionality of the Go version will exceed that of the C++ version and customers will be encouraged to migrate. The entire Open AMT Cloud Toolkit team hopes you are as excited about this release as we are and we look forward to continuing to working with you! You can read more about this release in our release notes .","title":"Changes coming for Remote Provisioning Client"},{"location":"license/","text":"License \u00b6 Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2019 Intel Corporation Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2019 Intel Corporation Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"release-notes/","text":"Release Notes \u00b6 Please see the release announcements for additional information regarding this release. Key Feature Changes for 2.0 \u00b6 This section outlines key features changes between versions 1.5 and 2.0 for Open AMT Cloud Toolkit . Additions, Modifications, and Removals \u00b6 Breaking Changes \u00b6 tenantId is a new field in the db and all queries now require it Open AMT Cloud Toolkit \u00b6 env.template: optimized reuse of settings postgres: removed postgres deployment from K8S, AKS , and EKS. Recommend using managed DB service from cloud provided for these deployments postgres: enabled ssl communication for db connections deployment: added EKS deployment scripts (Amazon Elastic Kubernetes Service) deployment: added support for Kuma service mesh. This enables MTLS between containers to enhance security as well as adding additional productivity capabilities. RPS \u00b6 ciraconfig: allow null values for ciraconfigname in profile edit (#f3b2659) multitenancy: add support for multiple tenants (#bbbdf95) multitenancy: device creation with MPS now includes tenantId (#e01cd79) activation: update client response message (#23a7a0b) activation: now device is saved after activation in acm ( #416 ) (#c1b02f4) mqtt: adds activation success message (#cfd6a34) network: now removes all the profiles with priority 0 ( #424 ) (#b00e6a9) network: get wifi passphrase from vault ( #409 ) (#35532d2) wireless: Updated passphrase key name in vault to sync with other keys ( #419 ) (#313daa2) MPS \u00b6 api: added api for request, cancel and send user consent code to AMT ( #332 ) (#e4fbe58) api: cert now pulls from config instead of disk (#d9e04e3) multitenancy: add multi tenancy support (#4e323c8) docs: updated swagger documentation (#7aee48a) RPC \u00b6 security: update to OpenSSL 1.1.1l wireless: add AMT wireless adapter info to amtinfo LAN settings. refactor: format json status messages Sample Web UI \u00b6 amtfeatures: replaced enabled features box to work with checkboxes (#8a86c9f) ciraconfig: allow clearing out cira config in profile (#abf0bee) dashboard: add wireless config link to dashboard page (#5b4c61c) device: now displays AMT FW and Provisioning Mode (#fdd439a) devices: add power status to device list (#1b58bac) notification: updated power actions notifications and resolved merge conflicts ( #390 ) (#5610e60) pagesize: updated page size options (#5b8b624) paging: implemented paging for cira, domains, devices, profiles and wifi ( #370 ) (#bfc554d) userconsent: a dialog to enter user consent code ( #395 ) (#269d1e2) errors: show better error messages for deleting associated ciraconfig and wifi config (#e4651c8) profile: fix no wifi config found message on input focus (#3802ea5) wireless: table now hidden when no data (#ce50bca) Resolved Issues in this release \u00b6 Intel\u00ae AMT \u00b6 Intel\u00ae AMT device fails to re-connect to MPS after MPS is not available for an extended period of time: We have added this issue to our troubleshooting documentation Open AMT Cloud Toolkit \u00b6 Power policy should be selected at BIOS under Intel\u00aeME Power Control screen -Mobile: On in So, MEWake in S3, S4-5 \u2013Power Package 2 for performing device poweron/off operations Scaling- KVM shows white screen Scaling- Connecting to SOL does not work correctly RPS \u00b6 Wi-Fi config: Intel AMT system disconnects from mps stack after powering off the device Software Event Notifications MPS \u00b6 AMT 12 dropping CIRA when sending command while system is off MPS API /ciracert always reads from file UI-Toolkit \u00b6 KVM freeze intermittently: We have root caused and implemented the fix in the UI-Toolkit KVM module. Sample-Web-UI \u00b6 AMT Responses should return status (i.e. NOT_READY) instead of \"Sent Succesfully\" Can't clear out CIRA config once selected in AMT Profile WiFi Profiles drop-down says \"No Wifi configs found\" before typing anything Open Issues in 2.0 \u00b6 RPS \u00b6 RPS should support wildcard domain suffix : Enhancement Data shouldn't be added if vault calls fail : Bug AMT Wi-Fi Configuration not supported on non-Windows systems : Known Issue MQTT messaging needs to be updated for some of the events : Enhancement Use database abstraction/ORM layer to support multiple SQL-based database : Enhancement MPS \u00b6 Direct Connection from MPS to AMT : Enhancement Should return error on additional KVM connections for a single device : Enhancement AMT does not connect to MPS after configuration : Known Issue Audit Log calls never respond on specific versions of AMT : Known Issue Use database abstraction/ORM layer to support multiple SQL-based database : Enhancement","title":"Release notes"},{"location":"release-notes/#release-notes","text":"Please see the release announcements for additional information regarding this release.","title":"Release Notes"},{"location":"release-notes/#key-feature-changes-for-20","text":"This section outlines key features changes between versions 1.5 and 2.0 for Open AMT Cloud Toolkit .","title":"Key Feature Changes for 2.0"},{"location":"release-notes/#additions-modifications-and-removals","text":"","title":"Additions, Modifications, and Removals"},{"location":"release-notes/#breaking-changes","text":"tenantId is a new field in the db and all queries now require it","title":"Breaking Changes"},{"location":"release-notes/#open-amt-cloud-toolkit","text":"env.template: optimized reuse of settings postgres: removed postgres deployment from K8S, AKS , and EKS. Recommend using managed DB service from cloud provided for these deployments postgres: enabled ssl communication for db connections deployment: added EKS deployment scripts (Amazon Elastic Kubernetes Service) deployment: added support for Kuma service mesh. This enables MTLS between containers to enhance security as well as adding additional productivity capabilities.","title":"Open AMT Cloud Toolkit"},{"location":"release-notes/#rps","text":"ciraconfig: allow null values for ciraconfigname in profile edit (#f3b2659) multitenancy: add support for multiple tenants (#bbbdf95) multitenancy: device creation with MPS now includes tenantId (#e01cd79) activation: update client response message (#23a7a0b) activation: now device is saved after activation in acm ( #416 ) (#c1b02f4) mqtt: adds activation success message (#cfd6a34) network: now removes all the profiles with priority 0 ( #424 ) (#b00e6a9) network: get wifi passphrase from vault ( #409 ) (#35532d2) wireless: Updated passphrase key name in vault to sync with other keys ( #419 ) (#313daa2)","title":"RPS"},{"location":"release-notes/#mps","text":"api: added api for request, cancel and send user consent code to AMT ( #332 ) (#e4fbe58) api: cert now pulls from config instead of disk (#d9e04e3) multitenancy: add multi tenancy support (#4e323c8) docs: updated swagger documentation (#7aee48a)","title":"MPS"},{"location":"release-notes/#rpc","text":"security: update to OpenSSL 1.1.1l wireless: add AMT wireless adapter info to amtinfo LAN settings. refactor: format json status messages","title":"RPC"},{"location":"release-notes/#sample-web-ui","text":"amtfeatures: replaced enabled features box to work with checkboxes (#8a86c9f) ciraconfig: allow clearing out cira config in profile (#abf0bee) dashboard: add wireless config link to dashboard page (#5b4c61c) device: now displays AMT FW and Provisioning Mode (#fdd439a) devices: add power status to device list (#1b58bac) notification: updated power actions notifications and resolved merge conflicts ( #390 ) (#5610e60) pagesize: updated page size options (#5b8b624) paging: implemented paging for cira, domains, devices, profiles and wifi ( #370 ) (#bfc554d) userconsent: a dialog to enter user consent code ( #395 ) (#269d1e2) errors: show better error messages for deleting associated ciraconfig and wifi config (#e4651c8) profile: fix no wifi config found message on input focus (#3802ea5) wireless: table now hidden when no data (#ce50bca)","title":"Sample Web UI"},{"location":"release-notes/#resolved-issues-in-this-release","text":"","title":"Resolved Issues in this release"},{"location":"release-notes/#intel-amt","text":"Intel\u00ae AMT device fails to re-connect to MPS after MPS is not available for an extended period of time: We have added this issue to our troubleshooting documentation","title":"Intel&reg; AMT"},{"location":"release-notes/#open-amt-cloud-toolkit_1","text":"Power policy should be selected at BIOS under Intel\u00aeME Power Control screen -Mobile: On in So, MEWake in S3, S4-5 \u2013Power Package 2 for performing device poweron/off operations Scaling- KVM shows white screen Scaling- Connecting to SOL does not work correctly","title":"Open AMT Cloud Toolkit"},{"location":"release-notes/#rps_1","text":"Wi-Fi config: Intel AMT system disconnects from mps stack after powering off the device Software Event Notifications","title":"RPS"},{"location":"release-notes/#mps_1","text":"AMT 12 dropping CIRA when sending command while system is off MPS API /ciracert always reads from file","title":"MPS"},{"location":"release-notes/#ui-toolkit","text":"KVM freeze intermittently: We have root caused and implemented the fix in the UI-Toolkit KVM module.","title":"UI-Toolkit"},{"location":"release-notes/#sample-web-ui_1","text":"AMT Responses should return status (i.e. NOT_READY) instead of \"Sent Succesfully\" Can't clear out CIRA config once selected in AMT Profile WiFi Profiles drop-down says \"No Wifi configs found\" before typing anything","title":"Sample-Web-UI"},{"location":"release-notes/#open-issues-in-20","text":"","title":"Open Issues in 2.0"},{"location":"release-notes/#rps_2","text":"RPS should support wildcard domain suffix : Enhancement Data shouldn't be added if vault calls fail : Bug AMT Wi-Fi Configuration not supported on non-Windows systems : Known Issue MQTT messaging needs to be updated for some of the events : Enhancement Use database abstraction/ORM layer to support multiple SQL-based database : Enhancement","title":"RPS"},{"location":"release-notes/#mps_2","text":"Direct Connection from MPS to AMT : Enhancement Should return error on additional KVM connections for a single device : Enhancement AMT does not connect to MPS after configuration : Known Issue Audit Log calls never respond on specific versions of AMT : Known Issue Use database abstraction/ORM layer to support multiple SQL-based database : Enhancement","title":"MPS"},{"location":"APIs/indexMPS/","text":".md-typeset h1, .md-content__button { display: none; } const ui = SwaggerUIBundle({ url: 'https://api.swaggerhub.com/apis/rbheopenamt/mps/2.0.0', dom_id: '#swagger-ui', })","title":"Management Presence Server"},{"location":"APIs/indexRPS/","text":".md-typeset h1, .md-content__button { display: none; } const ui = SwaggerUIBundle({ url: 'https://api.swaggerhub.com/apis/rbheopenamt/rps/2.0.0', dom_id: '#swagger-ui', })","title":"Remote Provisioning Server"},{"location":"Deployment/database/","text":"The docker based PostgreSQL image that is used in the docker-compose.yml is great for proof-of-concept of and development with the Open AMT Cloud Toolkit . However, when gearing up for production it is recommended to leverage a managed database instance offered by a public cloud provider or perhaps a database hosted by your internal IT. Regardless of your deployment scenario (ie. a VM, Kubernetes, Docker Swarm, a native environment), managing state in your own cluster comes with a higher risk of data loss than that of a managed database instance. Reference Implementation \u00b6 Postgres Example Replacements \u00b6 Azure Managed Postgres Azure MSSQL Amazon RDS MySQL MariaDB Services That Require Updating \u00b6 MPS RPS What you need to do \u00b6 For this guide, we'll be focusing on RPS . We'll walk through the primary steps required to swap out the database with another provider. In this example, we'll be using mssql. At a high level, there are a few main tasks to accomplish: Review DB Schema Add DB Client Dependency Configuration Code Implementation DB Schema Overview \u00b6 RPS \u00b6 erDiagram DOMAIN { string name string domain_suffix string provisioning_cert string provisioning_cert_storage_format string provisioning_cert_key datetime creation_date string created_by string tenant_id } erDiagram PROFILE o|--o| CIRACONFIG : has PROFILE ||--|{ PROFILES_WIRELESSCONFIGS : associated PROFILE { string profile_name string activation string amt_password string cira_config_name datetime creation_date string created_by string mebx_password string tags boolean dhcp_enabled string tenant_id } CIRACONFIG CIRACONFIG { string cira_config_name string mps_server_address int mps_port string user_name string password string generate_random_password string random_password_length string common_name int server_address_format int auth_method string mps_root_certificate string proxydetails string tenant_id } WIRELESSCONFIGS ||--|{ PROFILES_WIRELESSCONFIGS : belongs WIRELESSCONFIGS { string wireless_profile_name integer authentication_method integer encryption_method string ssid int psk_value string psk_passphrase int link_policy datetime creation_date string created_by string tenant_id } PROFILES_WIRELESSCONFIGS { string wireless_profile_name string profile_name datetime creation_date string created_by string tenant_id } MPS \u00b6 erDiagram DEVICE { guid uuid string tags string hostname string mpsinstance boolean connectionstatus string mpsusername string tenantid } Add DB Client \u00b6 The first step is to add your database client library that you will use to connect to your database. Since this example is for mssql, we will use node-mssql . npm install node-mssql --save Update Configuration \u00b6 Next, you'll need to update the connection string and a folder name for your db either in your ENV or .rc file: \"db_provider\" : \"mssql\" , // t his nee ds t o ma t ch t he f older na me you crea te i n t he ne x t s te p \"connection_string\" : \"Server=localhost,1433;Database=database;User Id=username;Password=password;Encrypt=true'\" , Write Code \u00b6 After you've got your configuration correct and db client added, next is to update the code to support the new database. Add a new folder named exactly as what you provided for the db_provider property to the ./src/data folder. For our example we'll use mssql . Next, we'll need to create an index.ts file that implements our IDB interface. Take a look at the interface below: export interface IDB { ciraConfigs : ICiraConfigTable domains : IDomainsTable profiles : IProfilesTable wirelessProfiles : IWirelessProfilesTable profileWirelessConfigs : IProfilesWifiConfigsTable query : ( text : string , params? : any ) => Promise < any > } We'll first implement the query method: async query < T > ( text : string , params? : any ) : Promise < mssql . IResult < T >> { let result const start = Date . now () return await new Promise (( resolve , reject ) => { this . sqlPool . connect ( async ( err ) => { if ( err ) { this . log . error ( err ) reject ( err ) } result = await this . sqlPool . request (). query ( text ) const duration = Date . now () - start this . log . verbose ( `executed query: ${ JSON . stringify ({ text , duration , rows : result.recordset.length } )}` ) resolve ( result ) }) }) } The above is just an example to demonstrate that this function should be responsible for taking in the query and parameters and performing the execution. Next, You'll need to implement each one of the table interfaces. The base interface looks like this: export interface ITable < T > { getCount : ( tenantId? : string ) => Promise < number > get : ( limit : number , offset : number , tenantId? : string ) => Promise < T [] > getByName : ( name : string , tenantId? : string ) => Promise < T > delete : ( name : string , tenantId? : string ) => Promise < boolean > insert : ( item : T ) => Promise < T > update : ( item : T ) => Promise < T > } There are interfaces for each table in the ./interfaces/database that adds specific functions on top of the the base ITable<> interface. Here's an example of the get implementation for Domains: /** * @description Get all Domains from DB * @param {number} top * @param {number} skip * @returns {AMTDomain[]} returns an array of AMT Domain objects from DB */ async get ( top : number = DEFAULT_TOP , skip : number = DEFAULT_SKIP , tenantId : string = '' ) : Promise < AMTDomain [] > { const results = await this . db . query ( ` SELECT name as profileName, domain_suffix as domainSuffix, provisioning_cert as provisioningCert, provisioning_cert_storage_format as provisioningCertStorageFormat, provisioning_cert_key as provisioningCertPassword, tenant_id tenantId FROM domains ORDER BY name` ) return result } Once you've completed all of the queries for each function for each table, you should be good to go! It's a good idea to run our API Tests w/ Postman provided in the ./src/test/collections folder to ensure all the APIs are working as expected when implementing a new database provider.","title":"Database"},{"location":"Deployment/database/#reference-implementation","text":"Postgres","title":"Reference Implementation"},{"location":"Deployment/database/#example-replacements","text":"Azure Managed Postgres Azure MSSQL Amazon RDS MySQL MariaDB","title":"Example Replacements"},{"location":"Deployment/database/#services-that-require-updating","text":"MPS RPS","title":"Services That Require Updating"},{"location":"Deployment/database/#what-you-need-to-do","text":"For this guide, we'll be focusing on RPS . We'll walk through the primary steps required to swap out the database with another provider. In this example, we'll be using mssql. At a high level, there are a few main tasks to accomplish: Review DB Schema Add DB Client Dependency Configuration Code Implementation","title":"What you need to do"},{"location":"Deployment/database/#db-schema-overview","text":"","title":"DB Schema Overview"},{"location":"Deployment/database/#rps","text":"erDiagram DOMAIN { string name string domain_suffix string provisioning_cert string provisioning_cert_storage_format string provisioning_cert_key datetime creation_date string created_by string tenant_id } erDiagram PROFILE o|--o| CIRACONFIG : has PROFILE ||--|{ PROFILES_WIRELESSCONFIGS : associated PROFILE { string profile_name string activation string amt_password string cira_config_name datetime creation_date string created_by string mebx_password string tags boolean dhcp_enabled string tenant_id } CIRACONFIG CIRACONFIG { string cira_config_name string mps_server_address int mps_port string user_name string password string generate_random_password string random_password_length string common_name int server_address_format int auth_method string mps_root_certificate string proxydetails string tenant_id } WIRELESSCONFIGS ||--|{ PROFILES_WIRELESSCONFIGS : belongs WIRELESSCONFIGS { string wireless_profile_name integer authentication_method integer encryption_method string ssid int psk_value string psk_passphrase int link_policy datetime creation_date string created_by string tenant_id } PROFILES_WIRELESSCONFIGS { string wireless_profile_name string profile_name datetime creation_date string created_by string tenant_id }","title":"RPS"},{"location":"Deployment/database/#mps","text":"erDiagram DEVICE { guid uuid string tags string hostname string mpsinstance boolean connectionstatus string mpsusername string tenantid }","title":"MPS"},{"location":"Deployment/database/#add-db-client","text":"The first step is to add your database client library that you will use to connect to your database. Since this example is for mssql, we will use node-mssql . npm install node-mssql --save","title":"Add DB Client"},{"location":"Deployment/database/#update-configuration","text":"Next, you'll need to update the connection string and a folder name for your db either in your ENV or .rc file: \"db_provider\" : \"mssql\" , // t his nee ds t o ma t ch t he f older na me you crea te i n t he ne x t s te p \"connection_string\" : \"Server=localhost,1433;Database=database;User Id=username;Password=password;Encrypt=true'\" ,","title":"Update Configuration"},{"location":"Deployment/database/#write-code","text":"After you've got your configuration correct and db client added, next is to update the code to support the new database. Add a new folder named exactly as what you provided for the db_provider property to the ./src/data folder. For our example we'll use mssql . Next, we'll need to create an index.ts file that implements our IDB interface. Take a look at the interface below: export interface IDB { ciraConfigs : ICiraConfigTable domains : IDomainsTable profiles : IProfilesTable wirelessProfiles : IWirelessProfilesTable profileWirelessConfigs : IProfilesWifiConfigsTable query : ( text : string , params? : any ) => Promise < any > } We'll first implement the query method: async query < T > ( text : string , params? : any ) : Promise < mssql . IResult < T >> { let result const start = Date . now () return await new Promise (( resolve , reject ) => { this . sqlPool . connect ( async ( err ) => { if ( err ) { this . log . error ( err ) reject ( err ) } result = await this . sqlPool . request (). query ( text ) const duration = Date . now () - start this . log . verbose ( `executed query: ${ JSON . stringify ({ text , duration , rows : result.recordset.length } )}` ) resolve ( result ) }) }) } The above is just an example to demonstrate that this function should be responsible for taking in the query and parameters and performing the execution. Next, You'll need to implement each one of the table interfaces. The base interface looks like this: export interface ITable < T > { getCount : ( tenantId? : string ) => Promise < number > get : ( limit : number , offset : number , tenantId? : string ) => Promise < T [] > getByName : ( name : string , tenantId? : string ) => Promise < T > delete : ( name : string , tenantId? : string ) => Promise < boolean > insert : ( item : T ) => Promise < T > update : ( item : T ) => Promise < T > } There are interfaces for each table in the ./interfaces/database that adds specific functions on top of the the base ITable<> interface. Here's an example of the get implementation for Domains: /** * @description Get all Domains from DB * @param {number} top * @param {number} skip * @returns {AMTDomain[]} returns an array of AMT Domain objects from DB */ async get ( top : number = DEFAULT_TOP , skip : number = DEFAULT_SKIP , tenantId : string = '' ) : Promise < AMTDomain [] > { const results = await this . db . query ( ` SELECT name as profileName, domain_suffix as domainSuffix, provisioning_cert as provisioningCert, provisioning_cert_storage_format as provisioningCertStorageFormat, provisioning_cert_key as provisioningCertPassword, tenant_id tenantId FROM domains ORDER BY name` ) return result } Once you've completed all of the queries for each function for each table, you should be good to go! It's a good idea to run our API Tests w/ Postman provided in the ./src/test/collections folder to ensure all the APIs are working as expected when implementing a new database provider.","title":"Write Code"},{"location":"Deployment/overview/","text":"When it comes time to deploy the Open AMT Cloud Toolkit to production there are some crucial decisions that need to made in order to determine the work to be done to prepare the toolkit properly. For each topic below we list what is provided as a reference implementation and as well as some recommended options that can be used as a replacement for the reference implementation. Database Selection \u00b6 The docker based PostgreSQL image that is used in the docker-compose.yml is great for proof-of-concept of and development with the Open AMT Cloud Toolkit. However, when gearing up for production it is recommended to leverage a managed database instance offered by a public cloud provider or perhaps a database hosted by your internal IT. Regardless of your deployment scenario (ie. a VM, Kubernetes, Docker Swarm, a native environment), managing state in your own cluster comes with a higher risk of data loss than that of a managed database instance. Reference Implementation \u00b6 Postgres Example Replacements \u00b6 Azure Managed Postgres Azure MSSQL Amazon RDS MySQL MariaDB For a short guide on how to swap out the database read this guide . Secret Management/Handling \u00b6 Secret Management is essential in a microservice architecture as it provides a secure repository for the services to access required sensitive assets. The Open AMT Cloud toolkit uses Hashicorp Vault as its tool for securely accessing these assets. A secret is anything that you want to tightly control access to, such as API keys, passwords, or certificates. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log. Similar to the database section above, when it comes time to scale Open AMT Cloud Toolkit for production, managing state can be difficult. While Vault has a comprehensive solution for managing and persisting state in a K8s cluster, we recommend leveraging a managed secret provider such as Azure Key Vault to offload this role and help reduce the overhead of managing this aspect of the toolkit. Additionally, you may consider that a Secret Provider is not necessary for your deployment and may wish to remove it leveraging some other backing store for secrets. Reference Implementation \u00b6 HashiCorp Vault Example Replacements \u00b6 Azure Key Vault AWS Key Management Service For a short guide on how to swap out the secret provider read this guide . API Gateway \u00b6 The API gateway is an important concept in microservices architecture. It provides an entry point for external clients(anything that is not part of the microservice system). It is a component that acts as an entry point for the Open AMT Cloud toolkit. We have chosen Kong as our reference implementation as it is open source and provides a comprehensive suite of plugins for various scenarios. Reference Implementation \u00b6 Kong Example Replacements \u00b6 Azure API Gateway Amazon API Gateway Google Cloud Endpoints Tyk","title":"Overview"},{"location":"Deployment/overview/#database-selection","text":"The docker based PostgreSQL image that is used in the docker-compose.yml is great for proof-of-concept of and development with the Open AMT Cloud Toolkit. However, when gearing up for production it is recommended to leverage a managed database instance offered by a public cloud provider or perhaps a database hosted by your internal IT. Regardless of your deployment scenario (ie. a VM, Kubernetes, Docker Swarm, a native environment), managing state in your own cluster comes with a higher risk of data loss than that of a managed database instance.","title":"Database Selection"},{"location":"Deployment/overview/#reference-implementation","text":"Postgres","title":"Reference Implementation"},{"location":"Deployment/overview/#example-replacements","text":"Azure Managed Postgres Azure MSSQL Amazon RDS MySQL MariaDB For a short guide on how to swap out the database read this guide .","title":"Example Replacements"},{"location":"Deployment/overview/#secret-managementhandling","text":"Secret Management is essential in a microservice architecture as it provides a secure repository for the services to access required sensitive assets. The Open AMT Cloud toolkit uses Hashicorp Vault as its tool for securely accessing these assets. A secret is anything that you want to tightly control access to, such as API keys, passwords, or certificates. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log. Similar to the database section above, when it comes time to scale Open AMT Cloud Toolkit for production, managing state can be difficult. While Vault has a comprehensive solution for managing and persisting state in a K8s cluster, we recommend leveraging a managed secret provider such as Azure Key Vault to offload this role and help reduce the overhead of managing this aspect of the toolkit. Additionally, you may consider that a Secret Provider is not necessary for your deployment and may wish to remove it leveraging some other backing store for secrets.","title":"Secret Management/Handling"},{"location":"Deployment/overview/#reference-implementation_1","text":"HashiCorp Vault","title":"Reference Implementation"},{"location":"Deployment/overview/#example-replacements_1","text":"Azure Key Vault AWS Key Management Service For a short guide on how to swap out the secret provider read this guide .","title":"Example Replacements"},{"location":"Deployment/overview/#api-gateway","text":"The API gateway is an important concept in microservices architecture. It provides an entry point for external clients(anything that is not part of the microservice system). It is a component that acts as an entry point for the Open AMT Cloud toolkit. We have chosen Kong as our reference implementation as it is open source and provides a comprehensive suite of plugins for various scenarios.","title":"API Gateway"},{"location":"Deployment/overview/#reference-implementation_2","text":"Kong","title":"Reference Implementation"},{"location":"Deployment/overview/#example-replacements_2","text":"Azure API Gateway Amazon API Gateway Google Cloud Endpoints Tyk","title":"Example Replacements"},{"location":"Deployment/secrets/","text":"Secret Management is essential in a microservice architecture as it provides a secure repository for the services to access required sensitive assets. The Open AMT Cloud toolkit uses Hashicorp Vault as its tool for securely accessing these assets. A secret is anything that you want to tightly control access to, such as API keys, passwords, or certificates. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log. Similar to the database section above, when it comes time to scale Open AMT Cloud Toolkit for production, managing state can be difficult. While Vault has a comprehensive solution for managing and persisting state in a K8s cluster, we recommend leveraging a managed secret provider such as Azure Key Vault to offload this role and help reduce the overhead of managing this aspect of the toolkit. Additionally, you may consider that a Secret Provider is not necessary for your deployment and may wish to remove it leveraging some other backing store for secrets. Reference Implementation \u00b6 HashiCorp Vault Example Replacements \u00b6 Azure Key Vault AWS Key Management Service Services That Require Updating \u00b6 MPS RPS What you need to do \u00b6 We'll walk through the primary steps required to swap out the secret provider with another provider. In this example, we'll be using Azure Key Vault. At a high level, there are a few main tasks to accomplish: Review Vault Schema Add Secret Provider Dependency (if necessary) Configuration Code Implementation Review Vault Schema \u00b6 Below are the paths/keys in the vault that are used by the Open AMT Cloud Toolkit. # RPS CIRAConfigs/[cira_config_name]/MPS_PASSWORD certs/[domain_profile_name]/CERT certs/[domain_profile_name]/CERT_PASSWORD profiles/[profile_name]/AMT_PASSWORD profiles/[profile_name]/MEBX_PASSWORD wireless/[wireless_profile_name]/PSK_PASSPHRASE # MPS devices/[device_guid]/AMT_PASSWORD devices/[device_guid]/MEBX_PASSWORD devices/[device_guid]/MPS_PASSWORD Add Secret Provider Dependency \u00b6 For this example, we'll swap out the Hashicorp Vault for Azure Key Vault. We first need to install the required dependencies. npm install @azure/keyvault-secrets npm install @azure/identity To read more about this dependency check out https://www.npmjs.com/package/@azure/keyvault-secrets . Note This guide will assume Azure Key Vault is already configured and ready for use as it focuses on the code that needs to be implemented in the microservices. Configuration \u00b6 For Hashicorp Vault, we have the following three properties that need to be configured. { \"secrets_path\" : \"secret/data/\" , \"vault_address\" : \"http://localhost:8200\" , \"vault_token\" : \"myroot\" , } For Azure Key Vault, we don't need all of these so we'll set just the address: { \"secrets_path\" : \"\" , \"vault_address\" : \"https://<YOUR KEYVAULT NAME>.vault.azure.net\" , \"vault_token\" : \"\" , } Additionally, the following three ENV variables must be set: AZURE_TENANT_ID = <YOUR-TENANT-ID> AZURE_CLIENT_ID = <YOUR-CLIENT-ID> AZURE_CLIENT_SECRET = <YOUR-CLIENT-SECRET> Code \u00b6 Let's take a look at our ISecretManagerService interface: export interface ISecretManagerService { getSecretFromKey : ( path : string , key : string ) => Promise < string > getSecretAtPath : ( path : string ) => Promise < any > listSecretsAtPath : ( path : string ) => Promise < any > readJsonFromKey : ( path : string , key : string ) => Promise < string > writeSecretWithKey : ( path : string , key : string , keyvalue : any ) => Promise < void > writeSecretWithObject : ( path : string , data : any ) => Promise < void > deleteSecretWithPath : ( path : string ) => Promise < void > } For this example, we'll focus on setup and implementing the getSecretFromKey . const { DefaultAzureCredential } = require ( \"@azure/identity\" ) const { SecretClient } = require ( \"@azure/keyvault-secrets\" ) export class AzureSecretManagerService implements ISecretManagerService { vaultClient : SecretClient logger : ILogger constructor ( logger : ILogger ) { // DefaultAzureCredential expects the following three environment variables: // * AZURE_TENANT_ID: The tenant ID in Azure Active Directory // * AZURE_CLIENT_ID: The application (client) ID registered in the AAD tenant // * AZURE_CLIENT_SECRET: The client secret for the registered application const credential = new DefaultAzureCredential () // Lastly, create our secrets client and connect to the service const client = new SecretClient ( EnvReader . GlobalEnvConfig . VaultConfig . address , credential ); } async getSecretFromKey ( path : string , key : string ) : Promise < string > { try { this . logger . verbose ( `getting secret from vault: ${ path } , ${ key } ` ) const latestSecret = await client . getSecret ( key ); this . logger . debug ( `got data back from vault: ${ path } , ${ key } ` ) return latestSecret } catch ( error ) { this . logger . error ( 'getSecretFromKey error \\r\\n' ) this . logger . error ( error ) return null } } } After all the functions have been implemented, the last step is to wire it up. This is done in the src/Configurator.ts file. constructor (){ //existing //this.secretsManager = new SecretManagerService(new Logger('SecretManagerService')) this . secretsManager = new AzureSecretManagerService ( new Logger ( 'AzureSecretManagerService' )) } That's it! After implementing the interface in both RPS and MPS. It's a good idea to run the Postman API tests located in ./src/test/collections to ensure everything is in working order.","title":"Secret Provider"},{"location":"Deployment/secrets/#reference-implementation","text":"HashiCorp Vault","title":"Reference Implementation"},{"location":"Deployment/secrets/#example-replacements","text":"Azure Key Vault AWS Key Management Service","title":"Example Replacements"},{"location":"Deployment/secrets/#services-that-require-updating","text":"MPS RPS","title":"Services That Require Updating"},{"location":"Deployment/secrets/#what-you-need-to-do","text":"We'll walk through the primary steps required to swap out the secret provider with another provider. In this example, we'll be using Azure Key Vault. At a high level, there are a few main tasks to accomplish: Review Vault Schema Add Secret Provider Dependency (if necessary) Configuration Code Implementation","title":"What you need to do"},{"location":"Deployment/secrets/#review-vault-schema","text":"Below are the paths/keys in the vault that are used by the Open AMT Cloud Toolkit. # RPS CIRAConfigs/[cira_config_name]/MPS_PASSWORD certs/[domain_profile_name]/CERT certs/[domain_profile_name]/CERT_PASSWORD profiles/[profile_name]/AMT_PASSWORD profiles/[profile_name]/MEBX_PASSWORD wireless/[wireless_profile_name]/PSK_PASSPHRASE # MPS devices/[device_guid]/AMT_PASSWORD devices/[device_guid]/MEBX_PASSWORD devices/[device_guid]/MPS_PASSWORD","title":"Review Vault Schema"},{"location":"Deployment/secrets/#add-secret-provider-dependency","text":"For this example, we'll swap out the Hashicorp Vault for Azure Key Vault. We first need to install the required dependencies. npm install @azure/keyvault-secrets npm install @azure/identity To read more about this dependency check out https://www.npmjs.com/package/@azure/keyvault-secrets . Note This guide will assume Azure Key Vault is already configured and ready for use as it focuses on the code that needs to be implemented in the microservices.","title":"Add Secret Provider Dependency"},{"location":"Deployment/secrets/#configuration","text":"For Hashicorp Vault, we have the following three properties that need to be configured. { \"secrets_path\" : \"secret/data/\" , \"vault_address\" : \"http://localhost:8200\" , \"vault_token\" : \"myroot\" , } For Azure Key Vault, we don't need all of these so we'll set just the address: { \"secrets_path\" : \"\" , \"vault_address\" : \"https://<YOUR KEYVAULT NAME>.vault.azure.net\" , \"vault_token\" : \"\" , } Additionally, the following three ENV variables must be set: AZURE_TENANT_ID = <YOUR-TENANT-ID> AZURE_CLIENT_ID = <YOUR-CLIENT-ID> AZURE_CLIENT_SECRET = <YOUR-CLIENT-SECRET>","title":"Configuration"},{"location":"Deployment/secrets/#code","text":"Let's take a look at our ISecretManagerService interface: export interface ISecretManagerService { getSecretFromKey : ( path : string , key : string ) => Promise < string > getSecretAtPath : ( path : string ) => Promise < any > listSecretsAtPath : ( path : string ) => Promise < any > readJsonFromKey : ( path : string , key : string ) => Promise < string > writeSecretWithKey : ( path : string , key : string , keyvalue : any ) => Promise < void > writeSecretWithObject : ( path : string , data : any ) => Promise < void > deleteSecretWithPath : ( path : string ) => Promise < void > } For this example, we'll focus on setup and implementing the getSecretFromKey . const { DefaultAzureCredential } = require ( \"@azure/identity\" ) const { SecretClient } = require ( \"@azure/keyvault-secrets\" ) export class AzureSecretManagerService implements ISecretManagerService { vaultClient : SecretClient logger : ILogger constructor ( logger : ILogger ) { // DefaultAzureCredential expects the following three environment variables: // * AZURE_TENANT_ID: The tenant ID in Azure Active Directory // * AZURE_CLIENT_ID: The application (client) ID registered in the AAD tenant // * AZURE_CLIENT_SECRET: The client secret for the registered application const credential = new DefaultAzureCredential () // Lastly, create our secrets client and connect to the service const client = new SecretClient ( EnvReader . GlobalEnvConfig . VaultConfig . address , credential ); } async getSecretFromKey ( path : string , key : string ) : Promise < string > { try { this . logger . verbose ( `getting secret from vault: ${ path } , ${ key } ` ) const latestSecret = await client . getSecret ( key ); this . logger . debug ( `got data back from vault: ${ path } , ${ key } ` ) return latestSecret } catch ( error ) { this . logger . error ( 'getSecretFromKey error \\r\\n' ) this . logger . error ( error ) return null } } } After all the functions have been implemented, the last step is to wire it up. This is done in the src/Configurator.ts file. constructor (){ //existing //this.secretsManager = new SecretManagerService(new Logger('SecretManagerService')) this . secretsManager = new AzureSecretManagerService ( new Logger ( 'AzureSecretManagerService' )) } That's it! After implementing the interface in both RPS and MPS. It's a good idea to run the Postman API tests located in ./src/test/collections to ensure everything is in working order.","title":"Code"},{"location":"GetStarted/buildRPC/","text":"The Remote Provisioning Client ( RPC ), when executed on an Intel\u00ae Active Management Technology ( Intel\u00ae AMT ) device, works in concert with the Remote Provisioning Server ( RPS ) to setup the Intel\u00ae AMT firmware. Once properly configured, the remote device can call home to the Management Presence Server ( MPS ) by establishing a Client Initiated Remote Access ( CIRA ) connection with the MPS . After running the RPC , the Intel\u00ae AMT managed device can be managed remotely using the web interface! Production Environment In a production environment, RPC can be deployed with an in-band manageability agent to distribute it to the fleet of AMT devices. The in-band manageability agent can invoke RPC to run and activate the AMT devices. Figure 1: RPC Configuration Figure 1 Details The RPC on a managed device communicates with the Intel\u00ae Management Engine Interface (Intel\u00ae MEI, previously known as HECI) Driver and the Remote Provisioning Server ( RPS ) interfaces. The Driver uses the Intel\u00ae MEI to talk to Intel\u00ae AMT . The RPC activates Intel\u00ae AMT with an AMT profile, which is associated with a CIRA configuration (Step 3). The profile, which also distinguishes between Client Control Mode ( CCM ) or Admin Control Mode ( ACM ), and configuration were created in Create a CIRA Config or Create an AMT Profile . After running RPC with a profile, Intel\u00ae AMT will establish a CIRA connection with the MPS (Step 4) allowing MPS to manage the remote device and issue AMT commands (Step 5). Build RPC \u00b6 We leverage GitHub Actions as a means to build RPC automatically leveraging Github's CI/CD Infrastructure. This avoids having to deal with the challenges of getting your build environment just right on your local machine and allows you to get up and running much faster. However, if you wish to build and compile RPC locally, see Build & Run RPC (Manual) . Optionally, to build RPC with Docker, skip to Docker Build . Read more about GitHub Actions here . Github Actions \u00b6 To Build the RPC with Github Actions \u00b6 Create a fork of the repository. Choose your account to fork to. Fork rpc on github Click on the Actions tab at the top. Enable workflows by clicking I understand my workflows, go ahead and enable them . Choose the Build RPC (Native) Debug/Release workflow. Click the Run workflow dropdown. Type \"v\" to see the list of release branches from the Use workflow from dropdown. Select the v2.0.0 branch. By default, the Build Type should be release . Click the Run Workflow button. The build time ranges from 15 to 20 minutes. Once the download is complete, click the completed job which will feature a green checkmark. Download the appropriate RPC for your managed device's OS under the Artifacts section. Docker Build (For Linux Hosts) \u00b6 Keep in mind, the image created with this method is only suitable for Docker on a Linux host. To build RPC with Docker, use the following command from the open-amt-cloud-toolkit/rpc directory: docker build -f \"Dockerfile\" -t rpc:latest . Note If you wish to perform this docker build on Windows, ensure Use the WSL 2 based engine is enabled in Docker Desktop. Once the build is complete, you will need to get the built image to your Linux system running Docker. Run RPC to Activate and Connect the AMT Device \u00b6 To run the application and connect the managed device: After building the RPC , copy the executable to the managed device. On the managed device, open a Terminal (Linux) or Powershell/Command Prompt as Administrator (Windows). Navigate to the directory containing the RPC application. Run RPC with the following command to activate and configure Intel\u00ae AMT . It will take 1-2 minutes to finish provisioning the device. Replace [Development-IP-Address] with the development system's IP address, where the MPS and RPS servers are running. Replace [profile-name] with your created profile from the Web Server. The RPC application command line parameters are case sensitive. Linux sudo ./rpc -u wss:// [ Development-IP-Address ] /activate --nocertcheck -c \"activate --profile [profile-name]\" Docker (On Linux Host Only) sudo docker run --device = /dev/mei0 rpc:latest --url wss:// [ Development-IP-Address ] /activate --nocertcheck -c \"activate --profile [profile-name]\" Windows is not supported due to current limitations. See Devices in Containers on Windows for more information. Windows .\\rpc.exe -u wss://[Development-IP-Address]/activate --nocertcheck -c \"activate --profile [profile-name]\" Note - RPC Arguments Because we are using a self-signed certificate for easier development testing, we need to supply the nocertcheck flag. In production, you would opt for a CA signed certificate. Find out more information about the flag and other arguments . Success Example Output after Activating and Configuring a device into ACM : Troubleshooting Run into an issue? Try these troubleshooting steps . Next up \u00b6 Manage AMT Device","title":"Build & Run RPC"},{"location":"GetStarted/buildRPC/#build-rpc","text":"We leverage GitHub Actions as a means to build RPC automatically leveraging Github's CI/CD Infrastructure. This avoids having to deal with the challenges of getting your build environment just right on your local machine and allows you to get up and running much faster. However, if you wish to build and compile RPC locally, see Build & Run RPC (Manual) . Optionally, to build RPC with Docker, skip to Docker Build . Read more about GitHub Actions here .","title":"Build RPC"},{"location":"GetStarted/buildRPC/#github-actions","text":"","title":"Github Actions"},{"location":"GetStarted/buildRPC/#to-build-the-rpc-with-github-actions","text":"Create a fork of the repository. Choose your account to fork to. Fork rpc on github Click on the Actions tab at the top. Enable workflows by clicking I understand my workflows, go ahead and enable them . Choose the Build RPC (Native) Debug/Release workflow. Click the Run workflow dropdown. Type \"v\" to see the list of release branches from the Use workflow from dropdown. Select the v2.0.0 branch. By default, the Build Type should be release . Click the Run Workflow button. The build time ranges from 15 to 20 minutes. Once the download is complete, click the completed job which will feature a green checkmark. Download the appropriate RPC for your managed device's OS under the Artifacts section.","title":"To Build the RPC with Github Actions"},{"location":"GetStarted/buildRPC/#docker-build-for-linux-hosts","text":"Keep in mind, the image created with this method is only suitable for Docker on a Linux host. To build RPC with Docker, use the following command from the open-amt-cloud-toolkit/rpc directory: docker build -f \"Dockerfile\" -t rpc:latest . Note If you wish to perform this docker build on Windows, ensure Use the WSL 2 based engine is enabled in Docker Desktop. Once the build is complete, you will need to get the built image to your Linux system running Docker.","title":"Docker Build  (For Linux Hosts)"},{"location":"GetStarted/buildRPC/#run-rpc-to-activate-and-connect-the-amt-device","text":"To run the application and connect the managed device: After building the RPC , copy the executable to the managed device. On the managed device, open a Terminal (Linux) or Powershell/Command Prompt as Administrator (Windows). Navigate to the directory containing the RPC application. Run RPC with the following command to activate and configure Intel\u00ae AMT . It will take 1-2 minutes to finish provisioning the device. Replace [Development-IP-Address] with the development system's IP address, where the MPS and RPS servers are running. Replace [profile-name] with your created profile from the Web Server. The RPC application command line parameters are case sensitive. Linux sudo ./rpc -u wss:// [ Development-IP-Address ] /activate --nocertcheck -c \"activate --profile [profile-name]\" Docker (On Linux Host Only) sudo docker run --device = /dev/mei0 rpc:latest --url wss:// [ Development-IP-Address ] /activate --nocertcheck -c \"activate --profile [profile-name]\" Windows is not supported due to current limitations. See Devices in Containers on Windows for more information. Windows .\\rpc.exe -u wss://[Development-IP-Address]/activate --nocertcheck -c \"activate --profile [profile-name]\" Note - RPC Arguments Because we are using a self-signed certificate for easier development testing, we need to supply the nocertcheck flag. In production, you would opt for a CA signed certificate. Find out more information about the flag and other arguments . Success Example Output after Activating and Configuring a device into ACM : Troubleshooting Run into an issue? Try these troubleshooting steps .","title":"Run RPC to Activate and Connect the AMT Device"},{"location":"GetStarted/buildRPC/#next-up","text":"Manage AMT Device","title":"Next up"},{"location":"GetStarted/createCIRAConfig/","text":"Client Initiated Remote Access ( CIRA ) enables a CIRA -capable edge device to initiate and establish a persistent connection to the MPS . As long as the managed device is connected to the network and to a power source, it can maintain a persistent connection. Note - Wireless Activations This express setup assumes the managed device (i.e. AMT device) is on a wired connection for quickest setup. To learn more about a Wireless Setup, see the Wireless Activation Tutorial . To create a CIRA Config: Select the CIRA Configs tab from the left-hand menu. In the top-right corner, click Add New. Figure 1: Create a new CIRA Config. Specify a Config Name of your choice. Select IPv4 , and provide your development system's IP Address. Cert Common Name (CN=) should auto-populate. If not, provide your development system's IP Address. Leave Port as the default, 4433. Leave the Username as admin or choose your own. These credentials will be used when constructing API calls. Leave the slider set on Auto-load . Click Save. Example CIRA Config Figure 2: Example CIRA Config. Next up \u00b6 Profiles provide configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Profiles also distinguish between activating in: Client Control Mode ( CCM ): This mode offers all manageability features including, but not limited to, power control, audit logs, and hardware info. Redirection features, such as KVM or SOL , require user consent . The managed device will display a 6-digit code that must be entered by the remote admin to access the remote device via redirection. Create a CCM Profile Admin Control Mode ( ACM ): ACM mode supports all manageability features without requiring user consent . This means it is not necessary to have a person on-site to remote in and manage an edge device. In most IoT use cases, edge devices such as digital signage or kiosks may not be easily accessible or have available employees nearby. ACM mode proves immensely helpful in these scenarios. Create an ACM Profile","title":"Create a CIRA Config"},{"location":"GetStarted/createCIRAConfig/#next-up","text":"Profiles provide configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Profiles also distinguish between activating in: Client Control Mode ( CCM ): This mode offers all manageability features including, but not limited to, power control, audit logs, and hardware info. Redirection features, such as KVM or SOL , require user consent . The managed device will display a 6-digit code that must be entered by the remote admin to access the remote device via redirection. Create a CCM Profile Admin Control Mode ( ACM ): ACM mode supports all manageability features without requiring user consent . This means it is not necessary to have a person on-site to remote in and manage an edge device. In most IoT use cases, edge devices such as digital signage or kiosks may not be easily accessible or have available employees nearby. ACM mode proves immensely helpful in these scenarios. Create an ACM Profile","title":"Next up"},{"location":"GetStarted/createProfileACM/","text":"Admin Control Mode ( ACM ) provides full access to Intel\u00ae Active Management Technology ( Intel\u00ae AMT ) functionality. User consent is optional for redirection features. Figure 1: Set up configuration and profiles for N number of clients. What You'll Need \u00b6 Provisioning Certificate \u00b6 By purchasing a certificate, you'll be able to remotely activate an Intel\u00ae AMT device in ACM . This feature enables you to disable User Consent. Provisioning Certificates are available from four different Certificate Authorities: Comodo DigiCert Entrust GoDaddy Important For ACM in Open Active Management Technology (Open AMT) Cloud Toolkit, use only certificate vendors that support Intel\u00ae AMT . DNS Suffix \u00b6 The DNS suffix encompasses the domain suffix (e.g., .com) and follows the hostname. Consider the following DNS Name example: Example DNS Name: cb-vending1.burgerbusiness.com In this example, the hostname is cb-vending1 and the DNS suffix is burgerbusiness.com. To set the DNS suffix : Manually set it using MEBX on the managed device. Find instructions here Alternately, change the DHCP Option 15 to DNS suffix within the Router settings. To find the the DNS suffix , use the following command: Linux ifconfig Windows ipconfig /all Create a Profile \u00b6 A Profile provides configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Production Environment In a production environment, devices are typically activated in ACM mode. ACM mode enables KVM access to devices without user consent. In most IoT use cases, edge devices such as digital signage or kiosks may not have immediate access to it or employees nearby. ACM mode proves immensely helpful in these scenarios. To create an ACM profile: Select the Profiles tab from the menu on the left. Under the Profiles tab, click Add New in the top-right corner to create a profile. Figure 1: Create a new profile. Specify a Profile Name of your choice. Under Activation , select Admin Control Mode from the dropdown menu. Provide or generate a strong AMT Password . AMT will verify this password when receiving a command from a MPS server. This password is also required for device deactivation. Tip The two buttons next to the password input are for toggling visibility and generating a new random password. Please note that if the Vault database is lost or corrupted, all credentials that aren't also stored somewhere else will be lost. There will be no way to login. The administrator will have to clear the CMOS battery on the managed devices! Provide or generate a strong MEBX Password . This password can be used to access Intel\u00ae Manageability Engine BIOS Extensions ( Intel\u00ae MEBX ) on the AMT device. Leave DHCP as the default for Network Configuration . Optionally, add Tags to help in organizing and querying devices as your list of managed devices grow. Select the name of the CIRA Configuration you created previously from the drop-down menu. This express setup assumes the managed device (i.e. AMT device) is on a wired connection for quickest setup. To learn more about a Wireless Setup, see the Wireless Activation Tutorial . Click Save. Example ACM Profile Figure 2: Example ACM profile. Create a Domain Profile \u00b6 In addition to a CIRA Config and an ACM Profile , ACM requires the creation of a Domain profile. Intel\u00ae AMT checks the network DNS suffix against the provisioning certificate as a security check. During provisioning, the trusted certificate chain is injected into the AMT firmware. AMT verifies that the certificate chain is complete and is signed by a trusted certificate authority. To create a domain: Select the Domains tab from the left-hand menu. In the top-right corner, click Add New. Figure 3: Create Domain. Specify a name of your choice for the Domain Profile for the Name field. This does not have to be the actual network Domain Name/Suffix. Provide your DNS suffix as the Domain Name . This is the actual DNS suffix of the network domain that is set in DHCP Option 15 or manually on the AMT device through MEBX. Click Choose File and select your purchased Provisioning Certificate. This certificate must contain the private key. Provide the Provisioning Certificate Password used to encrypt the .pfx file. Click Save. Example Domain Figure 4: Example Domain profile. Next Up \u00b6 Build & Run RPC","title":"Create a Profile with ACM"},{"location":"GetStarted/createProfileACM/#what-youll-need","text":"","title":"What You'll Need"},{"location":"GetStarted/createProfileACM/#provisioning-certificate","text":"By purchasing a certificate, you'll be able to remotely activate an Intel\u00ae AMT device in ACM . This feature enables you to disable User Consent. Provisioning Certificates are available from four different Certificate Authorities: Comodo DigiCert Entrust GoDaddy Important For ACM in Open Active Management Technology (Open AMT) Cloud Toolkit, use only certificate vendors that support Intel\u00ae AMT .","title":"Provisioning Certificate"},{"location":"GetStarted/createProfileACM/#dns-suffix","text":"The DNS suffix encompasses the domain suffix (e.g., .com) and follows the hostname. Consider the following DNS Name example: Example DNS Name: cb-vending1.burgerbusiness.com In this example, the hostname is cb-vending1 and the DNS suffix is burgerbusiness.com. To set the DNS suffix : Manually set it using MEBX on the managed device. Find instructions here Alternately, change the DHCP Option 15 to DNS suffix within the Router settings. To find the the DNS suffix , use the following command: Linux ifconfig Windows ipconfig /all","title":"DNS Suffix"},{"location":"GetStarted/createProfileACM/#create-a-profile","text":"A Profile provides configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Production Environment In a production environment, devices are typically activated in ACM mode. ACM mode enables KVM access to devices without user consent. In most IoT use cases, edge devices such as digital signage or kiosks may not have immediate access to it or employees nearby. ACM mode proves immensely helpful in these scenarios. To create an ACM profile: Select the Profiles tab from the menu on the left. Under the Profiles tab, click Add New in the top-right corner to create a profile. Figure 1: Create a new profile. Specify a Profile Name of your choice. Under Activation , select Admin Control Mode from the dropdown menu. Provide or generate a strong AMT Password . AMT will verify this password when receiving a command from a MPS server. This password is also required for device deactivation. Tip The two buttons next to the password input are for toggling visibility and generating a new random password. Please note that if the Vault database is lost or corrupted, all credentials that aren't also stored somewhere else will be lost. There will be no way to login. The administrator will have to clear the CMOS battery on the managed devices! Provide or generate a strong MEBX Password . This password can be used to access Intel\u00ae Manageability Engine BIOS Extensions ( Intel\u00ae MEBX ) on the AMT device. Leave DHCP as the default for Network Configuration . Optionally, add Tags to help in organizing and querying devices as your list of managed devices grow. Select the name of the CIRA Configuration you created previously from the drop-down menu. This express setup assumes the managed device (i.e. AMT device) is on a wired connection for quickest setup. To learn more about a Wireless Setup, see the Wireless Activation Tutorial . Click Save. Example ACM Profile Figure 2: Example ACM profile.","title":"Create a Profile"},{"location":"GetStarted/createProfileACM/#create-a-domain-profile","text":"In addition to a CIRA Config and an ACM Profile , ACM requires the creation of a Domain profile. Intel\u00ae AMT checks the network DNS suffix against the provisioning certificate as a security check. During provisioning, the trusted certificate chain is injected into the AMT firmware. AMT verifies that the certificate chain is complete and is signed by a trusted certificate authority. To create a domain: Select the Domains tab from the left-hand menu. In the top-right corner, click Add New. Figure 3: Create Domain. Specify a name of your choice for the Domain Profile for the Name field. This does not have to be the actual network Domain Name/Suffix. Provide your DNS suffix as the Domain Name . This is the actual DNS suffix of the network domain that is set in DHCP Option 15 or manually on the AMT device through MEBX. Click Choose File and select your purchased Provisioning Certificate. This certificate must contain the private key. Provide the Provisioning Certificate Password used to encrypt the .pfx file. Click Save. Example Domain Figure 4: Example Domain profile.","title":"Create a Domain Profile"},{"location":"GetStarted/createProfileACM/#next-up","text":"Build & Run RPC","title":"Next Up"},{"location":"GetStarted/createProfileCCM/","text":"Client Control Mode ( CCM ) provides full access to features of Intel\u00ae Active Management Technology ( Intel\u00ae AMT ), but it does require user consent for all redirection features. While Intel\u00ae AMT includes the ability to use the features listed below with user consent in CCM , the Open AMT Cloud Toolkit does not currently support it. These features require user consent: Keyboard, Video, Mouse ( KVM ) Control IDE-Redirection for sharing and mounting images remotely Serial-over-LAN ( SOL ) Figure 1: Set up configuration and profiles for N number of clients. Create a Profile \u00b6 Profiles provide configuration information to the firmware on platforms featuring Intel\u00ae AMT during the activation process with the Remote Provisioning Client ( RPC ). To create a CCM profile: Select the Profiles tab from the menu on the left. Under the Profiles tab, click New in the top-right corner to create a profile. Figure 1: Create a new profile. Specify a Profile Name of your choice. Under Activation Mode , select Client Control Mode from the dropdown menu. Provide or generate a strong AMT Password . AMT will verify this password when receiving a command from a MPS server. This password is also required for device deactivation. Tip The two buttons next to the password input are for toggling visibility and generating a new random password. Please note that if the Vault database is lost or corrupted, all credentials that aren't also stored somewhere else will be lost. There will be no way to login. The administrator will have to clear the CMOS battery on the managed devices! The MEBX Password field is disabled, as the password for Intel\u00ae Manageability Engine BIOS Extensions ( Intel\u00ae MEBX ) cannot be set when activating in CCM due to the lower level of trust when compared to ACM . Leave DHCP as the default for Network Configuration . Optionally, add Tags to help in organizing and querying devices as your list of managed devices grow. Select the name of the CIRA Configuration you created previously from the drop-down menu. This express setup assumes the managed device (i.e. AMT device) is on a wired connection for quickest setup. To learn more about a Wireless Setup, see the Wireless Activation Tutorial . Click Save. Example CCM Profile Figure 2: Example CCM profile. Next up \u00b6 Build & Run RPC","title":"Create a Profile with CCM"},{"location":"GetStarted/createProfileCCM/#create-a-profile","text":"Profiles provide configuration information to the firmware on platforms featuring Intel\u00ae AMT during the activation process with the Remote Provisioning Client ( RPC ). To create a CCM profile: Select the Profiles tab from the menu on the left. Under the Profiles tab, click New in the top-right corner to create a profile. Figure 1: Create a new profile. Specify a Profile Name of your choice. Under Activation Mode , select Client Control Mode from the dropdown menu. Provide or generate a strong AMT Password . AMT will verify this password when receiving a command from a MPS server. This password is also required for device deactivation. Tip The two buttons next to the password input are for toggling visibility and generating a new random password. Please note that if the Vault database is lost or corrupted, all credentials that aren't also stored somewhere else will be lost. There will be no way to login. The administrator will have to clear the CMOS battery on the managed devices! The MEBX Password field is disabled, as the password for Intel\u00ae Manageability Engine BIOS Extensions ( Intel\u00ae MEBX ) cannot be set when activating in CCM due to the lower level of trust when compared to ACM . Leave DHCP as the default for Network Configuration . Optionally, add Tags to help in organizing and querying devices as your list of managed devices grow. Select the name of the CIRA Configuration you created previously from the drop-down menu. This express setup assumes the managed device (i.e. AMT device) is on a wired connection for quickest setup. To learn more about a Wireless Setup, see the Wireless Activation Tutorial . Click Save. Example CCM Profile Figure 2: Example CCM profile.","title":"Create a Profile"},{"location":"GetStarted/createProfileCCM/#next-up","text":"Build & Run RPC","title":"Next up"},{"location":"GetStarted/loginToUI/","text":"The web portal is available for login after the deployment of the MPS , RPS , and Sample Web UI . Make sure all three are successfully running before attempting to login. Example Passwords Open AMT Cloud Toolkit increases security with multiple passwords. Find an explanation of toolkit passwords in Reference -> Architecture Overview . Log In \u00b6 Open any modern web browser and navigate to the following link. https://<Development-IP-Address> Important - URL of Sample Web UI You must use the development system's IP address in the URL. Localhost or 127.0.0.1 will NOT work . Read more about Kong API Gateway to find out why . The development system's IP address is where the Docker containers are running. A warning screen will prompt because the MPS Server is using self-signed certificates for testing. Click Advanced and then Proceed to continue to connect to the Sample Web UI . Example - Chrome* Browser Warning Screen Log in to the web portal with the login credentials set for the environment variables MPS_WEB_ADMIN_USER and MPS_WEB_ADMIN_PASSWORD in the .env file. The home page is shown below in Figure 1. Example - Sample Web UI Home Page Next up \u00b6 Create a CIRA Config","title":"Login to Sample Web UI"},{"location":"GetStarted/loginToUI/#log-in","text":"Open any modern web browser and navigate to the following link. https://<Development-IP-Address> Important - URL of Sample Web UI You must use the development system's IP address in the URL. Localhost or 127.0.0.1 will NOT work . Read more about Kong API Gateway to find out why . The development system's IP address is where the Docker containers are running. A warning screen will prompt because the MPS Server is using self-signed certificates for testing. Click Advanced and then Proceed to continue to connect to the Sample Web UI . Example - Chrome* Browser Warning Screen Log in to the web portal with the login credentials set for the environment variables MPS_WEB_ADMIN_USER and MPS_WEB_ADMIN_PASSWORD in the .env file. The home page is shown below in Figure 1. Example - Sample Web UI Home Page","title":"Log In"},{"location":"GetStarted/loginToUI/#next-up","text":"Create a CIRA Config","title":"Next up"},{"location":"GetStarted/manageDevice/","text":"Go back to the Sample Web UI on your development system. Click the Devices tab from the menu on the left. Troubleshooting If the activated device is not listed or if it is listed as unconnected, try restarting the AMT device. After successfully restarting the device, refresh the Sample Web UI to see if the Status changes to connected . Click on your connected device. Select an action to perform from the options in the top-right. Note If activated in Client Control Mode( CCM ), the KVM and SOL features require entering a user consent code, which will be displayed on the device. To use KVM / SOL without user consent, follow the ACM Activation Tutorial for how to configure a device into Admin Control Mode. Note Activated already? Try out the Keyboard, Video, Mouse ( KVM ) feature to remotely view and control the AMT device. Issue a Reset to BIOS command to view and make live changes to BIOS settings. When performing a KVM action, give the user consent code displayed on the client device. Next steps \u00b6 After successfully deploying the Open AMT Cloud Toolkit microservices and client, explore other tools and topics in the Open AMT Cloud Toolkit architecture: REST API Calls \u00b6 Learn how to send commands to AMT devices with the curl-based REST API tutorial. Generate a JWT token for Authorization and construct an API call to get a list of devices. Get Started with REST API Calls UI Toolkit \u00b6 Explore the Open AMT Cloud Toolkit reference implementation console by adding manageability features with prebuilt React components, such as Keyboard, Video, and Mouse ( KVM ). Get Started with the UI Toolkit Security \u00b6 Learn how to use the Open AMT Cloud Toolkit architecture to secure assets. Topics include credentials, allowlisting, best known security methods, and more. Learn More about Security and Hardening","title":"Manage AMT Device"},{"location":"GetStarted/manageDevice/#next-steps","text":"After successfully deploying the Open AMT Cloud Toolkit microservices and client, explore other tools and topics in the Open AMT Cloud Toolkit architecture:","title":"Next steps"},{"location":"GetStarted/manageDevice/#rest-api-calls","text":"Learn how to send commands to AMT devices with the curl-based REST API tutorial. Generate a JWT token for Authorization and construct an API call to get a list of devices. Get Started with REST API Calls","title":"REST API Calls"},{"location":"GetStarted/manageDevice/#ui-toolkit","text":"Explore the Open AMT Cloud Toolkit reference implementation console by adding manageability features with prebuilt React components, such as Keyboard, Video, and Mouse ( KVM ). Get Started with the UI Toolkit","title":"UI Toolkit"},{"location":"GetStarted/manageDevice/#security","text":"Learn how to use the Open AMT Cloud Toolkit architecture to secure assets. Topics include credentials, allowlisting, best known security methods, and more. Learn More about Security and Hardening","title":"Security"},{"location":"GetStarted/prerequisites/","text":"Prerequisites \u00b6 This section contains prerequisites for deploying Open AMT Cloud Toolkit 's MPS and RPS microservices on a local development system as Docker* containers. Figure 1: Deploy microservices on a local development system as Docker containers. What You'll Need \u00b6 Hardware \u00b6 Configure a network that includes: A development system At least one Intel vPro\u00ae Platform A flash drive or equivalent means to transfer files between Both systems must use a wired (i.e., cable) connection on the same network. Development System Software \u00b6 Before MPS and RPS installation, install the following software: Docker* Desktop for Windows or Linux Info Docker Configuration Details: (1) The Docker for Windows installer defaults to enable all the required settings for this tutorial. (2) After successful installation, the Docker icon (whale), will appear on the task bar. (3) To troubleshoot the installation, see the troubleshooting guide . git* What You'll Do \u00b6 To complete a deployment: Install the prerequisites. Run setup to build and deploy microservices with Docker. Login and configure RPS . Build RPC . Copy RPC to a managed device. To connect the managed device: Run RPC on a managed device. Manage the device with MPS . These sections include instructions for Windows and Linux* environments. Run instructions in a terminal window, the Windows Command Prompt in Administrator mode or the Linux shell/terminal. Why Docker*? \u00b6 A Docker container is the instantiation of a Docker image as a virtualized unit that separates the application from the environment. Docker containers start and run reliably, securely, and portably inside different environments, eliminating some of the problems that occur with software deployment on varying platforms. Docker streamlines installation to get you up and running faster. Get more information about Docker images and containers at Docker resources. Next up \u00b6 Setup - Build Docker* Images","title":"Prerequisites"},{"location":"GetStarted/prerequisites/#prerequisites","text":"This section contains prerequisites for deploying Open AMT Cloud Toolkit 's MPS and RPS microservices on a local development system as Docker* containers. Figure 1: Deploy microservices on a local development system as Docker containers.","title":"Prerequisites"},{"location":"GetStarted/prerequisites/#what-youll-need","text":"","title":"What You'll Need"},{"location":"GetStarted/prerequisites/#hardware","text":"Configure a network that includes: A development system At least one Intel vPro\u00ae Platform A flash drive or equivalent means to transfer files between Both systems must use a wired (i.e., cable) connection on the same network.","title":"Hardware"},{"location":"GetStarted/prerequisites/#development-system-software","text":"Before MPS and RPS installation, install the following software: Docker* Desktop for Windows or Linux Info Docker Configuration Details: (1) The Docker for Windows installer defaults to enable all the required settings for this tutorial. (2) After successful installation, the Docker icon (whale), will appear on the task bar. (3) To troubleshoot the installation, see the troubleshooting guide . git*","title":"Development System Software"},{"location":"GetStarted/prerequisites/#what-youll-do","text":"To complete a deployment: Install the prerequisites. Run setup to build and deploy microservices with Docker. Login and configure RPS . Build RPC . Copy RPC to a managed device. To connect the managed device: Run RPC on a managed device. Manage the device with MPS . These sections include instructions for Windows and Linux* environments. Run instructions in a terminal window, the Windows Command Prompt in Administrator mode or the Linux shell/terminal.","title":"What You'll Do"},{"location":"GetStarted/prerequisites/#why-docker","text":"A Docker container is the instantiation of a Docker image as a virtualized unit that separates the application from the environment. Docker containers start and run reliably, securely, and portably inside different environments, eliminating some of the problems that occur with software deployment on varying platforms. Docker streamlines installation to get you up and running faster. Get more information about Docker images and containers at Docker resources.","title":"Why Docker*?"},{"location":"GetStarted/prerequisites/#next-up","text":"Setup - Build Docker* Images","title":"Next up"},{"location":"GetStarted/setup/","text":"Express Setup \u00b6 This setup installs the MPS and RPS microservices as Docker* containers, standardized packages containing an application's source code, libraries, environment, and dependencies. Get the Toolkit \u00b6 To clone the repositories: Open a Terminal or Command Prompt and navigate to a directory of your choice for development: git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Change to the cloned open-amt-cloud-toolkit directory. cd open-amt-cloud-toolkit Set Environment Variables \u00b6 The .env.template file is used by docker to set environment variables. To set the environment variables: Copy the .env.template file to .env : Linux/Powershell cp .env.template .env Windows (Cmd Prompt) copy .env.template .env In a text editor or IDE of choice, open the new .env file to edit. Update the following fields for configuring the MPS , Sample Web UI , Vault and Postgres. Save and keep track of the values you choose. Field Name Required Usage MPS_COMMON_NAME Development System IP Address. For connecting to MPS server via UI or APIs. WARNING: Do not use localhost. Use the development system IP Address. MPS_WEB_ADMIN_USER Username of your choice For logging into the Sample Web UI MPS_WEB_ADMIN_PASSWORD Strong password of your choice For logging into the Sample Web UI MPS_JWT_SECRET A strong secret of your choice (Example: A unique, random 256bit string. See another example in code snippet below ). Used when generating a JSON Web Token for authentication. This example implementation uses a symmetrical key and HS256 to create the signature. Learn more about JWT . POSTGRES_USER Username of your choice For logging into the Postgres POSTGRES_PASSWORD Strong password of your choice For logging into the Postgres VAULT_TOKEN Strong token of your choice For logging into the vault Important - Using Strong Passwords The MPS_WEB_ADMIN_PASSWORD must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character Save the file. Set Kong JSON Web Token (JWT) \u00b6 Set the shared secret used in Kong for JWT authentication. Open the kong.yaml file. Update the secret field with your MPS_JWT_SECRET. jwt_secrets : - consumer : admin key : 9EmRJTbIiIb4bIeSsmgcWIjrR6HyETqc #sample key secret : \"Yq3t6w9z$C&E)H@McQfTjWnZr4u7x!A%\" #sample secret, DO NOT use for production Save and close the file. Build and Run the Docker Images \u00b6 Build the MPS , RPS , and Sample Web UI Docker images and launch the stack. Run docker-compose to start the containers from the ./open-amt-cloud-toolkit directory. Linux sudo docker-compose -f \"docker-compose.yml\" up -d --build Windows docker-compose -f \"docker-compose.yml\" up -d --build Important - For Windows* 10 While the docker-compose up command is running, you may see a number of pop-ups asking for permission for Docker Desktop Filesharing. You must select Share It for the docker-compose up command to execute successfully. If the pop-up expires, docker-compose up will fail. You must run docker-compose down -v and then rerun docker-compose up to successfully start the containers. Check that all of the containers are running. Linux sudo docker ps --format \"table {{.Image}}\\t{{.Status}}\\t{{.Names}}\" Windows docker ps --format \"table {{.Image}}\\t{{.Status}}\\t{{.Names}}\" Success IMAGE STATUS NAMES kong:2.3 Up 4 seconds ( health: starting ) open-amt-cloud-toolkit_kong_1 sslpostgres Up 9 seconds open-amt-cloud-toolkit_db_1 webui:latest Up 10 seconds open-amt-cloud-toolkit_webui_1 mpsrouter:latest Up 11 seconds open-amt-cloud-toolkit_mpsrouter_1 rps:latest Up 11 seconds open-amt-cloud-toolkit_rps_1 mps:latest Up 10 seconds open-amt-cloud-toolkit_mps_1 vault Up 10 seconds open-amt-cloud-toolkit_vault_1 Important Container Issues If any of the above containers are not running, walk through the steps again or file a GitHub issue here . If the kong container reloads repeatedly, verify kong.yaml edits. Misconfiguration of this file will cause the container to reload. Important Because the vault is running in a dev mode, stored secrets will be lost upon a restart, and profiles and configs must be recreated. They are not persistent in this mode. Be sure to run docker-compose down -v when bringing down the stack, which removes the volumes, and start fresh upon docker-compose up . To run vault in production mode, follow the guide here . Next up \u00b6 Login to Sample Web UI","title":"Set Up"},{"location":"GetStarted/setup/#express-setup","text":"This setup installs the MPS and RPS microservices as Docker* containers, standardized packages containing an application's source code, libraries, environment, and dependencies.","title":"Express Setup"},{"location":"GetStarted/setup/#get-the-toolkit","text":"To clone the repositories: Open a Terminal or Command Prompt and navigate to a directory of your choice for development: git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Change to the cloned open-amt-cloud-toolkit directory. cd open-amt-cloud-toolkit","title":"Get the Toolkit"},{"location":"GetStarted/setup/#set-environment-variables","text":"The .env.template file is used by docker to set environment variables. To set the environment variables: Copy the .env.template file to .env : Linux/Powershell cp .env.template .env Windows (Cmd Prompt) copy .env.template .env In a text editor or IDE of choice, open the new .env file to edit. Update the following fields for configuring the MPS , Sample Web UI , Vault and Postgres. Save and keep track of the values you choose. Field Name Required Usage MPS_COMMON_NAME Development System IP Address. For connecting to MPS server via UI or APIs. WARNING: Do not use localhost. Use the development system IP Address. MPS_WEB_ADMIN_USER Username of your choice For logging into the Sample Web UI MPS_WEB_ADMIN_PASSWORD Strong password of your choice For logging into the Sample Web UI MPS_JWT_SECRET A strong secret of your choice (Example: A unique, random 256bit string. See another example in code snippet below ). Used when generating a JSON Web Token for authentication. This example implementation uses a symmetrical key and HS256 to create the signature. Learn more about JWT . POSTGRES_USER Username of your choice For logging into the Postgres POSTGRES_PASSWORD Strong password of your choice For logging into the Postgres VAULT_TOKEN Strong token of your choice For logging into the vault Important - Using Strong Passwords The MPS_WEB_ADMIN_PASSWORD must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character Save the file.","title":"Set Environment Variables"},{"location":"GetStarted/setup/#set-kong-json-web-token-jwt","text":"Set the shared secret used in Kong for JWT authentication. Open the kong.yaml file. Update the secret field with your MPS_JWT_SECRET. jwt_secrets : - consumer : admin key : 9EmRJTbIiIb4bIeSsmgcWIjrR6HyETqc #sample key secret : \"Yq3t6w9z$C&E)H@McQfTjWnZr4u7x!A%\" #sample secret, DO NOT use for production Save and close the file.","title":"Set Kong JSON Web Token (JWT)"},{"location":"GetStarted/setup/#build-and-run-the-docker-images","text":"Build the MPS , RPS , and Sample Web UI Docker images and launch the stack. Run docker-compose to start the containers from the ./open-amt-cloud-toolkit directory. Linux sudo docker-compose -f \"docker-compose.yml\" up -d --build Windows docker-compose -f \"docker-compose.yml\" up -d --build Important - For Windows* 10 While the docker-compose up command is running, you may see a number of pop-ups asking for permission for Docker Desktop Filesharing. You must select Share It for the docker-compose up command to execute successfully. If the pop-up expires, docker-compose up will fail. You must run docker-compose down -v and then rerun docker-compose up to successfully start the containers. Check that all of the containers are running. Linux sudo docker ps --format \"table {{.Image}}\\t{{.Status}}\\t{{.Names}}\" Windows docker ps --format \"table {{.Image}}\\t{{.Status}}\\t{{.Names}}\" Success IMAGE STATUS NAMES kong:2.3 Up 4 seconds ( health: starting ) open-amt-cloud-toolkit_kong_1 sslpostgres Up 9 seconds open-amt-cloud-toolkit_db_1 webui:latest Up 10 seconds open-amt-cloud-toolkit_webui_1 mpsrouter:latest Up 11 seconds open-amt-cloud-toolkit_mpsrouter_1 rps:latest Up 11 seconds open-amt-cloud-toolkit_rps_1 mps:latest Up 10 seconds open-amt-cloud-toolkit_mps_1 vault Up 10 seconds open-amt-cloud-toolkit_vault_1 Important Container Issues If any of the above containers are not running, walk through the steps again or file a GitHub issue here . If the kong container reloads repeatedly, verify kong.yaml edits. Misconfiguration of this file will cause the container to reload. Important Because the vault is running in a dev mode, stored secrets will be lost upon a restart, and profiles and configs must be recreated. They are not persistent in this mode. Be sure to run docker-compose down -v when bringing down the stack, which removes the volumes, and start fresh upon docker-compose up . To run vault in production mode, follow the guide here .","title":"Build and Run the Docker Images"},{"location":"GetStarted/setup/#next-up","text":"Login to Sample Web UI","title":"Next up"},{"location":"Reference/architectureOverview/","text":"Figure 1 illustrates the high-level architecture of Open AMT Cloud Toolkit microservice architecture . Figure 1: Deploy Open AMT Cloud Toolkit Figure 1 illustrates the high-level steps for basic deployment: Deploy Microservices - Install the microservices on a development system as Docker* containers, which can run locally or on the cloud. Deploy RPC Architecture - Transfer the lightweight clients to managed devices. Configure AMT - Through the RPS , configure AMT by creating control mode profile(s). Connect AMT - Use the MPS to manage connectivity, as this microservice listens for the call home messaging of managed devices. Issue AMT Command - Send power commands (e.g., power off) through the MPS . Add AMT functionality - Explore the additional functionality provided by Open AMT Cloud Toolkit to develop your own web console or application. Out-of-band Management ( OOB Management ) \u00b6 Open AMT Cloud Toolkit uses remote management technology, also known as OOB Management , to allow administrators to perform actions on network assets or devices using a secure alternative to LAN-based communication protocols. Actions include reboot, power up, power down, system updates, and more. As long as the network device or asset is connected to power, Open AMT Cloud Toolkit software can perform remote management, including powering up as a system that is currently powered down. Remote management can offer potential cost-savings by decreasing the need for in-person technician visits to remote IT sites and reducing downtime. What's the difference between in-band and OOB Management ? \u00b6 Remote monitoring and management software solutions often require the managed devices to be in the powered on state. The IT administrator connects to and updates the managed device while it is in the powered on state. With out-of-band management, the administrator can connect to the device when it has been powered down or it is unresponsive. CIRA Configuration \u00b6 CIRA enables OOB connections between Intel\u00ae AMT platforms and administrative development systems running Open AMT on the same network. The following steps occur via a CIRA channel: A remote Intel vPro\u00ae Platform featuring Intel\u00ae AMT is activated and a CIRA configuration is applied. The remote platform is referred to as the managed device. The managed device connects to the MPS and establishes an encrypted connection using Transport Layer Security (TLS) The Intel vPro\u00ae Platform maintains a long standing connection with the MPS through the use of small keep-alive messages to the MPS . A management console sends a command to the MPS , via provided RESTful interfaces, with the command indicating the managed device should take some action. The MPS authenticates the RESTful command and proxies the command for the management console to the managed device. The MPS handles the authentication process with the managed device. Control Mode Profile \u00b6 Managed devices featuring Intel\u00ae AMT support two control modes: Admin Control Mode ( ACM ): In this mode, there are no limitations to Intel\u00ae AMT functionality. This reflects the higher level of trust associated with these setup methods. No user consent is required. Client Control Mode ( CCM ): This mode limits some of Intel\u00ae AMT functionality, reflecting the lower level of trust. Features requiring User Consent: Keyboard, Video, Mouse ( KVM ) Control IDE-Redirection for sharing and mounting images remotely Domains \u00b6 In addition to a CIRA Config and an ACM Profile , ACM requires the creation of a Domain Profile . Intel\u00ae AMT checks the network DNS suffix against the provisioning certificate as a security check. During provisioning, the trusted certificate chain is injected into the AMT firmware. Intel\u00ae AMT verifies that the certificate chain is complete and is signed by a trusted certificate authority. Power Control \u00b6 With the established CIRA channel, Open AMT Cloud Toolkit enables the administrator to manage remote devices and trigger power actions to: power up power down power up to BIOS reset reset to BIOS For more information about power states supported by the REST APIs, see Intel\u00ae AMT Implementation and Reference Guide for more details. Keyboard, Video, Mouse ( KVM ) Control \u00b6 Intel\u00ae AMT enables remote management of a device, even when the OS isn't running, through KVM over IP support. No additional equipment is needed for this feature. With KVM control, IT administrators can access and update PCs and devices as if they were onsite. It eliminates the need for remote KVM switches and other hardware. Passwords \u00b6 There are five levels of passwords: Intel\u00ae Manageability Engine BIOS Extensions (MEBX) Password: MEBX Password - Use this password to secure the local Intel\u00ae MEBX menu. This password is only used when physically accessing the managed device during system boot. Access the menu with Ctrl-P on most devices. Sample Web UI Password: MPS_WEB_ADMIN_PASSWORD - Use this password when logging into the Sample Web UI . The Sample Web UI Password uses this default MPS user authentication credential when it triggers MPS to issue a JWT (JSON Web Token). In most production environments, this default credential is replaced by a more rigorous authentication protocol. Examples include OAuth2, OpenID, or an authentication service that can issue an Auth Token to be validated by the API gateway. ACM & CCM Profiles: AMT Password - RPS uses this password to activate and configure Intel\u00ae AMT . When MPS requests an action of a managed device, such as a power action, it uses this password. Intel\u00ae AMT verifies this password when it gets a command from the MPS server. Provisioning Certificate Password - The AMT Provisioning certificate is a special certificate used by Intel\u00ae AMT devices to establish trust with the configuration service when activating in Admin Control Mode. RPS requires the .pfx version of this certificate along with the password used to export the .pfx certificate to perform ACM activation. MPS CIRA Credential: MPS_USER and MPS_PASSWORD - This CIRA credential is used by Intel\u00ae AMT managed devices to authenticate the MPS when establishing the CIRA connection. Multiple passwords enhance the security of Open AMT Cloud Toolkit . What Security Default Values Modify 1. Intel MEBX Password Prevention of Physical Security Violations admin In MEBX (Ctrl-P) 2. Sample Web UI Password Remote Role Management Username: standalone Password: G@ppm0ym .env file 3. ACM & CCM Profiles: AMT Password Authentication of MPS / RPS Access Not applicable. 1. Create a new profile. 2. Make an API call to update. 3. Update Vault. 4. Provisioning Certificate Password Signed Certificate Usage Not applicable. 1.Re-export certificate with another password. 2. Create a new profile. 3. Make an API call to update. 4. Update Vault. 5. MPS CIRA Credential MPS credential used by AMT Not applicable. 1. Create a new profile. 2. Make an API call to update. 3. Update Vault. Table 1: Summary of Open AMT Passwords Log Files \u00b6 Each microservice has an associated log file which can contain helpful debug information. Use docker logs to print log information to the terminal. Docker Logs \u00b6 To run docker log files in a terminal window as needed: Open a Terminal or Powershell/Command Prompt and run the command to list the containers: Linux sudo docker ps Windows (Powershell) docker ps Copy the first three digits of the container ID of interest. Run the docker logs command followed by the container ID: Linux sudo docker logs <container ID> Windows (Powershell) docker logs <container ID> See more help options for the docker logs command in Docker Documentation . Log Level \u00b6 Set the log levels in the .env file by altering the configuration levels, MPS_LOG_LEVEL and RPS_LOG_LEVEL . Find the log level descriptions in the tables contained in MPS Configuration and RPS Configuration .","title":"Architecture Overview"},{"location":"Reference/architectureOverview/#out-of-band-management-oob-management","text":"Open AMT Cloud Toolkit uses remote management technology, also known as OOB Management , to allow administrators to perform actions on network assets or devices using a secure alternative to LAN-based communication protocols. Actions include reboot, power up, power down, system updates, and more. As long as the network device or asset is connected to power, Open AMT Cloud Toolkit software can perform remote management, including powering up as a system that is currently powered down. Remote management can offer potential cost-savings by decreasing the need for in-person technician visits to remote IT sites and reducing downtime.","title":"Out-of-band Management (OOB Management)"},{"location":"Reference/architectureOverview/#whats-the-difference-between-in-band-and-oob-management","text":"Remote monitoring and management software solutions often require the managed devices to be in the powered on state. The IT administrator connects to and updates the managed device while it is in the powered on state. With out-of-band management, the administrator can connect to the device when it has been powered down or it is unresponsive.","title":"What's the difference between in-band and OOB Management?"},{"location":"Reference/architectureOverview/#cira-configuration","text":"CIRA enables OOB connections between Intel\u00ae AMT platforms and administrative development systems running Open AMT on the same network. The following steps occur via a CIRA channel: A remote Intel vPro\u00ae Platform featuring Intel\u00ae AMT is activated and a CIRA configuration is applied. The remote platform is referred to as the managed device. The managed device connects to the MPS and establishes an encrypted connection using Transport Layer Security (TLS) The Intel vPro\u00ae Platform maintains a long standing connection with the MPS through the use of small keep-alive messages to the MPS . A management console sends a command to the MPS , via provided RESTful interfaces, with the command indicating the managed device should take some action. The MPS authenticates the RESTful command and proxies the command for the management console to the managed device. The MPS handles the authentication process with the managed device.","title":"CIRA Configuration"},{"location":"Reference/architectureOverview/#control-mode-profile","text":"Managed devices featuring Intel\u00ae AMT support two control modes: Admin Control Mode ( ACM ): In this mode, there are no limitations to Intel\u00ae AMT functionality. This reflects the higher level of trust associated with these setup methods. No user consent is required. Client Control Mode ( CCM ): This mode limits some of Intel\u00ae AMT functionality, reflecting the lower level of trust. Features requiring User Consent: Keyboard, Video, Mouse ( KVM ) Control IDE-Redirection for sharing and mounting images remotely","title":"Control Mode Profile"},{"location":"Reference/architectureOverview/#domains","text":"In addition to a CIRA Config and an ACM Profile , ACM requires the creation of a Domain Profile . Intel\u00ae AMT checks the network DNS suffix against the provisioning certificate as a security check. During provisioning, the trusted certificate chain is injected into the AMT firmware. Intel\u00ae AMT verifies that the certificate chain is complete and is signed by a trusted certificate authority.","title":"Domains"},{"location":"Reference/architectureOverview/#power-control","text":"With the established CIRA channel, Open AMT Cloud Toolkit enables the administrator to manage remote devices and trigger power actions to: power up power down power up to BIOS reset reset to BIOS For more information about power states supported by the REST APIs, see Intel\u00ae AMT Implementation and Reference Guide for more details.","title":"Power Control"},{"location":"Reference/architectureOverview/#keyboard-video-mouse-kvm-control","text":"Intel\u00ae AMT enables remote management of a device, even when the OS isn't running, through KVM over IP support. No additional equipment is needed for this feature. With KVM control, IT administrators can access and update PCs and devices as if they were onsite. It eliminates the need for remote KVM switches and other hardware.","title":"Keyboard, Video, Mouse (KVM) Control"},{"location":"Reference/architectureOverview/#passwords","text":"There are five levels of passwords: Intel\u00ae Manageability Engine BIOS Extensions (MEBX) Password: MEBX Password - Use this password to secure the local Intel\u00ae MEBX menu. This password is only used when physically accessing the managed device during system boot. Access the menu with Ctrl-P on most devices. Sample Web UI Password: MPS_WEB_ADMIN_PASSWORD - Use this password when logging into the Sample Web UI . The Sample Web UI Password uses this default MPS user authentication credential when it triggers MPS to issue a JWT (JSON Web Token). In most production environments, this default credential is replaced by a more rigorous authentication protocol. Examples include OAuth2, OpenID, or an authentication service that can issue an Auth Token to be validated by the API gateway. ACM & CCM Profiles: AMT Password - RPS uses this password to activate and configure Intel\u00ae AMT . When MPS requests an action of a managed device, such as a power action, it uses this password. Intel\u00ae AMT verifies this password when it gets a command from the MPS server. Provisioning Certificate Password - The AMT Provisioning certificate is a special certificate used by Intel\u00ae AMT devices to establish trust with the configuration service when activating in Admin Control Mode. RPS requires the .pfx version of this certificate along with the password used to export the .pfx certificate to perform ACM activation. MPS CIRA Credential: MPS_USER and MPS_PASSWORD - This CIRA credential is used by Intel\u00ae AMT managed devices to authenticate the MPS when establishing the CIRA connection. Multiple passwords enhance the security of Open AMT Cloud Toolkit . What Security Default Values Modify 1. Intel MEBX Password Prevention of Physical Security Violations admin In MEBX (Ctrl-P) 2. Sample Web UI Password Remote Role Management Username: standalone Password: G@ppm0ym .env file 3. ACM & CCM Profiles: AMT Password Authentication of MPS / RPS Access Not applicable. 1. Create a new profile. 2. Make an API call to update. 3. Update Vault. 4. Provisioning Certificate Password Signed Certificate Usage Not applicable. 1.Re-export certificate with another password. 2. Create a new profile. 3. Make an API call to update. 4. Update Vault. 5. MPS CIRA Credential MPS credential used by AMT Not applicable. 1. Create a new profile. 2. Make an API call to update. 3. Update Vault. Table 1: Summary of Open AMT Passwords","title":"Passwords"},{"location":"Reference/architectureOverview/#log-files","text":"Each microservice has an associated log file which can contain helpful debug information. Use docker logs to print log information to the terminal.","title":"Log Files"},{"location":"Reference/architectureOverview/#docker-logs","text":"To run docker log files in a terminal window as needed: Open a Terminal or Powershell/Command Prompt and run the command to list the containers: Linux sudo docker ps Windows (Powershell) docker ps Copy the first three digits of the container ID of interest. Run the docker logs command followed by the container ID: Linux sudo docker logs <container ID> Windows (Powershell) docker logs <container ID> See more help options for the docker logs command in Docker Documentation .","title":"Docker Logs"},{"location":"Reference/architectureOverview/#log-level","text":"Set the log levels in the .env file by altering the configuration levels, MPS_LOG_LEVEL and RPS_LOG_LEVEL . Find the log level descriptions in the tables contained in MPS Configuration and RPS Configuration .","title":"Log Level"},{"location":"Reference/guids/","text":"GUIDs in Intel\u00ae AMT \u00b6 Each Intel\u00ae AMT device has a Global Unique Identifier (GUID) assigned to it by default. This GUID will be used as the reference to each device record. Typically, device GUIDs are required to perform power actions and other device-specific manageability features. There are a number of ways to obtain the GUID on the Intel\u00ae AMT device: Sample Web UI of the Open AMT Cloud Toolkit Devices API Method Via Sample Web UI \u00b6 Login to your Sample Web UI . Navigate to the Devices tab. Your AMT device's GUID is listed in the 2nd column. Via API Method \u00b6 A device's GUID can also be found via the AllDevices or ConnectedDevices MPS methods. Users can follow the Construct a Rest API Call tutorial on constructing and running the ConnectedDevices method as an example. Example ConnectedDevices Output: [{ \"host\" : \"d12428be-9fa1-4226-9784-54b2038beab6\" , \"amtuser\" : \"admin\" , \"mpsuser\" : \"standalone\" , \"conn\" : 1 , \"name\" : \"d12428be-9fa1-4226-9784-54b2038beab6\" }]","title":"GUIDs in Intel\u00ae AMT"},{"location":"Reference/guids/#guids-in-intel-amt","text":"Each Intel\u00ae AMT device has a Global Unique Identifier (GUID) assigned to it by default. This GUID will be used as the reference to each device record. Typically, device GUIDs are required to perform power actions and other device-specific manageability features. There are a number of ways to obtain the GUID on the Intel\u00ae AMT device: Sample Web UI of the Open AMT Cloud Toolkit Devices API Method","title":"GUIDs in Intel\u00ae AMT"},{"location":"Reference/guids/#via-sample-web-ui","text":"Login to your Sample Web UI . Navigate to the Devices tab. Your AMT device's GUID is listed in the 2nd column.","title":"Via Sample Web UI"},{"location":"Reference/guids/#via-api-method","text":"A device's GUID can also be found via the AllDevices or ConnectedDevices MPS methods. Users can follow the Construct a Rest API Call tutorial on constructing and running the ConnectedDevices method as an example. Example ConnectedDevices Output: [{ \"host\" : \"d12428be-9fa1-4226-9784-54b2038beab6\" , \"amtuser\" : \"admin\" , \"mpsuser\" : \"standalone\" , \"conn\" : 1 , \"name\" : \"d12428be-9fa1-4226-9784-54b2038beab6\" }]","title":"Via API Method"},{"location":"Reference/logging/","text":"Logging \u00b6 Introduction \u00b6 Microservices logging uses the Winston logging format. Log levels for both MPS and RPS microservices are controlled by the environmental variables MPS_LOG_LEVEL and RPS_LOG_LEVEL respectively. Logging levels are listed in the table below by increasing level of detail: error , warn , info , verbose , debug , and silly . Log levels \u00b6 Log level Description error only critical errors such as exceptions; 500 level api responses warn unexpected issue which don't affect service operation info service startup and shutdown messages (default level for MPS and RPS services) verbose database query messages; device heartbeat; 200 level api responses debug level useful for diagnosing issues with the services; 400 level api responses silly all logs","title":"Logging"},{"location":"Reference/logging/#logging","text":"","title":"Logging"},{"location":"Reference/logging/#introduction","text":"Microservices logging uses the Winston logging format. Log levels for both MPS and RPS microservices are controlled by the environmental variables MPS_LOG_LEVEL and RPS_LOG_LEVEL respectively. Logging levels are listed in the table below by increasing level of detail: error , warn , info , verbose , debug , and silly .","title":"Introduction"},{"location":"Reference/logging/#log-levels","text":"Log level Description error only critical errors such as exceptions; 500 level api responses warn unexpected issue which don't affect service operation info service startup and shutdown messages (default level for MPS and RPS services) verbose database query messages; device heartbeat; 200 level api responses debug level useful for diagnosing issues with the services; 400 level api responses silly all logs","title":"Log levels"},{"location":"Reference/powerstates/","text":"Actions are specified by number. Use the PowerCapabilities method to return the actions available for a specific device. Use the PowerState method to obtain the current power state. Possible actions are listed in the following table: Action # Resulting Action 2 Power up/on 4 Sleep 5 Power cycle 7 Hibernate 8 Power down/off 10 Reset 12 Soft power down/off 14 Soft reset 100 Power up to BIOS settings 101 Reset to BIOS settings 104 Reset to secure erase 200 Reset to IDE-R floppy disc 201 Power on to IDE-R floppy disc 202 Reset to IDE-R CD-ROM 203 Power on to IDE-R CD-ROM 400 Reset to PXE 401 Power on to PXE Consider the current state of the system when implementing a possible action. For example: Reset to BIOS implies that the current system state is on or powered up. Power up to BIOS implies that current system state is off or powered down. Hibernate implies that the current system state is powered up. If the system is already powered up, choosing to Power Up to BIOS will not have any effect on the system. A better choice is Reset to BIOS.","title":"AMT Power States"},{"location":"Reference/productionVault/","text":"Use Docker and Vault in Production Mode \u00b6 Introduction \u00b6 This document describes how to run MPS and RPS using vault in production server mode. The current local docker-compose file runs vault in development mode which makes experimenting with the services easier since static tokens can be used for access and unsealing vault is not required. The downside to this approach is all vault data is stored only in memory which is lost once the vault container is stopped. Running vault in production mode requires more steps but allows vault data to persist after container restarts. Update the vault section in the docker-compose file ( scripts\\docker-compose\\docker-compose.yaml ) with the section below: vault : image : vault container_name : prodvault environment : VAULT_ADDR : http://127.0.0.1:8200 ports : - \"8200:8200\" volumes : - private-volume:/vault/file:rw - ./vault:/vault/config:rw cap_add : - IPC_LOCK entrypoint : vault server -config=/vault/config/vault.json Create a folder named vault located in scripts\\docker-compose\\ and add a file named vault.json with the contents below: { \"backend\" :{ \"file\" :{ \"path\" : \"/vault/file\" } }, \"listener\" :{ \"tcp\" :{ \"address\" : \"0.0.0.0:8200\" , \"tls_disable\" : 1 } }, \"default_lease_ttl\" : \"168h\" , \"max_lease_ttl\" : \"0h\" , \"ui\" : true , \"log_level\" : \"Debug\" } Run docker command to start the stack: docker-compose up Run the following command to initialize the vault instance. docker exec -it prodvault vault operator init -n 1 -t 1 Make note of unseal key 1 and initial root token. Example Unseal Key 1: 0H8sK2QvVsqBKnUz6okBtDOqTVFSgJpdSKVe+colgXM= Initial Root Token: s.1glIfXnANPSnEmKLCzk4PQCO 5. Run the unseal command to decrypt the contents of the vault. Note: this step has to be performed each time the vault container is restarted. docker exec -it prodvault vault operator unseal [unseal key 1] Example docker exec -it prodvault vault operator unseal 0H8sK2QvVsqBKnUz6okBtDOqTVFSgJpdSKVe+colgXM= The response to the command should look similar to this: Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 1 Threshold 1 Version 1.6.0 Storage Type file Cluster Name vault-cluster-a39d7ef8 Cluster ID d1bc85f9-f405-44b3-0553-50f5e10b140e HA Enabled false 6. Login to vault with the following command using the initial root token: docker exec -it prodvault vault login [Initial Root Token] Example docker exec -it prodvault vault login s.1glIfXnANPSnEmKLCzk4PQCO 7. Enable the kv secrets engine docker exec -it prodvault vault secrets enable -version=2 kv 8. Update env variables located in scripts\\docker-compose\\.env a) Update vault tokens used in each service RPS_VAULT_TOKEN=[initial root token] MPS_VAULT_TOKEN=[initial root token] Example RPS_VAULT_TOKEN=s.1glIfXnANPSnEmKLCzk4PQCO MPS_VAULT_TOKEN=s.1glIfXnANPSnEmKLCzk4PQCO b) update secrets path MPS_SECRETS_PATH=kv/data/ RPS_SECRETS_PATH=kv/data/ 9. Press ctrl-c to stop the stack 10. Restart the stack using the command docker-compose up . 11. Rerun command in step 5 to unseal the vault.","title":"productionVault"},{"location":"Reference/productionVault/#use-docker-and-vault-in-production-mode","text":"","title":"Use Docker and Vault in Production Mode"},{"location":"Reference/productionVault/#introduction","text":"This document describes how to run MPS and RPS using vault in production server mode. The current local docker-compose file runs vault in development mode which makes experimenting with the services easier since static tokens can be used for access and unsealing vault is not required. The downside to this approach is all vault data is stored only in memory which is lost once the vault container is stopped. Running vault in production mode requires more steps but allows vault data to persist after container restarts. Update the vault section in the docker-compose file ( scripts\\docker-compose\\docker-compose.yaml ) with the section below: vault : image : vault container_name : prodvault environment : VAULT_ADDR : http://127.0.0.1:8200 ports : - \"8200:8200\" volumes : - private-volume:/vault/file:rw - ./vault:/vault/config:rw cap_add : - IPC_LOCK entrypoint : vault server -config=/vault/config/vault.json Create a folder named vault located in scripts\\docker-compose\\ and add a file named vault.json with the contents below: { \"backend\" :{ \"file\" :{ \"path\" : \"/vault/file\" } }, \"listener\" :{ \"tcp\" :{ \"address\" : \"0.0.0.0:8200\" , \"tls_disable\" : 1 } }, \"default_lease_ttl\" : \"168h\" , \"max_lease_ttl\" : \"0h\" , \"ui\" : true , \"log_level\" : \"Debug\" } Run docker command to start the stack: docker-compose up Run the following command to initialize the vault instance. docker exec -it prodvault vault operator init -n 1 -t 1 Make note of unseal key 1 and initial root token. Example Unseal Key 1: 0H8sK2QvVsqBKnUz6okBtDOqTVFSgJpdSKVe+colgXM= Initial Root Token: s.1glIfXnANPSnEmKLCzk4PQCO 5. Run the unseal command to decrypt the contents of the vault. Note: this step has to be performed each time the vault container is restarted. docker exec -it prodvault vault operator unseal [unseal key 1] Example docker exec -it prodvault vault operator unseal 0H8sK2QvVsqBKnUz6okBtDOqTVFSgJpdSKVe+colgXM= The response to the command should look similar to this: Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 1 Threshold 1 Version 1.6.0 Storage Type file Cluster Name vault-cluster-a39d7ef8 Cluster ID d1bc85f9-f405-44b3-0553-50f5e10b140e HA Enabled false 6. Login to vault with the following command using the initial root token: docker exec -it prodvault vault login [Initial Root Token] Example docker exec -it prodvault vault login s.1glIfXnANPSnEmKLCzk4PQCO 7. Enable the kv secrets engine docker exec -it prodvault vault secrets enable -version=2 kv 8. Update env variables located in scripts\\docker-compose\\.env a) Update vault tokens used in each service RPS_VAULT_TOKEN=[initial root token] MPS_VAULT_TOKEN=[initial root token] Example RPS_VAULT_TOKEN=s.1glIfXnANPSnEmKLCzk4PQCO MPS_VAULT_TOKEN=s.1glIfXnANPSnEmKLCzk4PQCO b) update secrets path MPS_SECRETS_PATH=kv/data/ RPS_SECRETS_PATH=kv/data/ 9. Press ctrl-c to stop the stack 10. Restart the stack using the command docker-compose up . 11. Rerun command in step 5 to unseal the vault.","title":"Introduction"},{"location":"Reference/troubleshooting/","text":"The sections below detail possible errors that may occur when activating or de-activating managed devices along with some potential solutions. Intel\u00ae AMT Device \u00b6 Error Issue or Message Possible Solutions Intel\u00ae AMT device fails to reconnect after MPS is down for 2 or more days Update to latest firmware. Workarounds include: a) Reboot device b) unplug and re-plug network cable MPS \u00b6 Error Issue or Message Possible Solutions Vault is empty in dev mode. Profiles and configs are not persistent in this mode. To run vault in production mode, follow the Use Docker and Vault in Production Mode . MPS is missing from list of running services. (1) Check for error messages in the logs. (2) Verify that the .env file contains correct values in each field. RPS \u00b6 Error Issue or Message Possible Solutions Create a profile fails or information cannot be read from vault. Make sure Vault and PostGres are running. For details, see the docker ps command in Build and Run Docker Images . An error occurred during provisioning. (1) Verify that the correct certificate is being used. (2) Verify the Domain suffix. RPC \u00b6 Error Issue or Message Possible Solutions \"Decrypting provisioning certificate failed\" Double check the password is correct on the certificate loaded into the \"domains\" on the UI \"Exception reading from device\" If MPS and RPS are running in Docker, check to ensure Vault has been unsealed. \"Unable to connect to Local Management Service (LMS). Please ensure LMS is running\" Check to ensure no application has bound to port 16992 \"Unable to launch MicroLMS.\" Check that Intel ME is present, MEI Driver installed and run this executable as administrator Check to ensure no application has bound to port 16992 \"Device xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx activation failed. Error while adding the certificates to AMT.\" Unplug the device, from both network and power, let it sit for a while. If that doesn't work, file a github issue Device xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx activation failed. Missing DNS suffix . Run ./rpc --amtinfo all and ensure there is a DNS suffix . If it is blank, double check your router settings for DHCP. Alternatively, you can override the DNS suffix with --dns mycompany.com Error: amt password DOES NOT match stored version for Device 6c4243ba-334d-11ea-94b5-caba2a773d00 Ensure you have provided the --password flag for the --cmd/-c you are trying to execute, and that it is the password you used when provisioning the device. Unable to connect to websocket server. Please check url. After ensuring you can reach your server. Ensure that the certificate common name on the server matches the FQDN/IP of your host address. Error while activating the AMT in admin mode. Check the logs on the RPS server. The rpc.exe fails to connect. If a device has already been provisioned, unprovision it and then reprovision. To deactivate and reactivate devices, see the Mircoservices section for RPC , RPC Activate/Deactivate Examples UI Toolkit \u00b6 If you encounter an error during the installation, verify the prerequisites and version numbers, such as Node.js* LTS, by consulting the tutorial Add MPS UI Toolkit Controls to a WebUI . If adding a control results in an error, double-check the device ID, mpsServer IP address value, and authToken. General Troubleshooting Tips \u00b6 If a configuration becomes unworkable, it may be necessary to clean up the environment by: unprovisioning, also known as deactivating, the managed device stopping all Docker services Do all the above if it becomes necessary to reset your environment completely. See instructions below. Unprovision the Managed Device: Use rpc.exe to dectivate the managed device as described in RPC Activate/Deactivate Examples . The deactivate parameter executes a full unprovision of the managed device. It is also possible to implement a full unprovision via MEBX. See Unprovisioning . Shut down Docker Services: Use docker image prune and docker image rm to stop or remove all images, containers, and volumes, as described in Build and Run Docker Images . The best practice example below stops Docker and then prunes all volumes. Example: Stop Docker services. Linux sudo docker-compose down -v Windows docker-compose down -v Prune the volumes. Linux sudo docker system prune -a --volumes Windows docker system prune -a --volumes","title":"Troubleshooting"},{"location":"Reference/troubleshooting/#intel-amt-device","text":"Error Issue or Message Possible Solutions Intel\u00ae AMT device fails to reconnect after MPS is down for 2 or more days Update to latest firmware. Workarounds include: a) Reboot device b) unplug and re-plug network cable","title":"Intel&reg; AMT Device"},{"location":"Reference/troubleshooting/#mps","text":"Error Issue or Message Possible Solutions Vault is empty in dev mode. Profiles and configs are not persistent in this mode. To run vault in production mode, follow the Use Docker and Vault in Production Mode . MPS is missing from list of running services. (1) Check for error messages in the logs. (2) Verify that the .env file contains correct values in each field.","title":"MPS"},{"location":"Reference/troubleshooting/#rps","text":"Error Issue or Message Possible Solutions Create a profile fails or information cannot be read from vault. Make sure Vault and PostGres are running. For details, see the docker ps command in Build and Run Docker Images . An error occurred during provisioning. (1) Verify that the correct certificate is being used. (2) Verify the Domain suffix.","title":"RPS"},{"location":"Reference/troubleshooting/#rpc","text":"Error Issue or Message Possible Solutions \"Decrypting provisioning certificate failed\" Double check the password is correct on the certificate loaded into the \"domains\" on the UI \"Exception reading from device\" If MPS and RPS are running in Docker, check to ensure Vault has been unsealed. \"Unable to connect to Local Management Service (LMS). Please ensure LMS is running\" Check to ensure no application has bound to port 16992 \"Unable to launch MicroLMS.\" Check that Intel ME is present, MEI Driver installed and run this executable as administrator Check to ensure no application has bound to port 16992 \"Device xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx activation failed. Error while adding the certificates to AMT.\" Unplug the device, from both network and power, let it sit for a while. If that doesn't work, file a github issue Device xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx activation failed. Missing DNS suffix . Run ./rpc --amtinfo all and ensure there is a DNS suffix . If it is blank, double check your router settings for DHCP. Alternatively, you can override the DNS suffix with --dns mycompany.com Error: amt password DOES NOT match stored version for Device 6c4243ba-334d-11ea-94b5-caba2a773d00 Ensure you have provided the --password flag for the --cmd/-c you are trying to execute, and that it is the password you used when provisioning the device. Unable to connect to websocket server. Please check url. After ensuring you can reach your server. Ensure that the certificate common name on the server matches the FQDN/IP of your host address. Error while activating the AMT in admin mode. Check the logs on the RPS server. The rpc.exe fails to connect. If a device has already been provisioned, unprovision it and then reprovision. To deactivate and reactivate devices, see the Mircoservices section for RPC , RPC Activate/Deactivate Examples","title":"RPC"},{"location":"Reference/troubleshooting/#ui-toolkit","text":"If you encounter an error during the installation, verify the prerequisites and version numbers, such as Node.js* LTS, by consulting the tutorial Add MPS UI Toolkit Controls to a WebUI . If adding a control results in an error, double-check the device ID, mpsServer IP address value, and authToken.","title":"UI Toolkit"},{"location":"Reference/troubleshooting/#general-troubleshooting-tips","text":"If a configuration becomes unworkable, it may be necessary to clean up the environment by: unprovisioning, also known as deactivating, the managed device stopping all Docker services Do all the above if it becomes necessary to reset your environment completely. See instructions below. Unprovision the Managed Device: Use rpc.exe to dectivate the managed device as described in RPC Activate/Deactivate Examples . The deactivate parameter executes a full unprovision of the managed device. It is also possible to implement a full unprovision via MEBX. See Unprovisioning . Shut down Docker Services: Use docker image prune and docker image rm to stop or remove all images, containers, and volumes, as described in Build and Run Docker Images . The best practice example below stops Docker and then prunes all volumes. Example: Stop Docker services. Linux sudo docker-compose down -v Windows docker-compose down -v Prune the volumes. Linux sudo docker system prune -a --volumes Windows docker system prune -a --volumes","title":"General Troubleshooting Tips"},{"location":"Reference/MEBX/dnsSuffix/","text":"Manageability Engine BIOS Extensions (MEBX) \u00b6 Intel\u00ae MEBX allows for configuration of the Intel Manageability Engine (ME) platform. Through this interface, you can provision AMT and customize a variety of settings manually. Set a DNS Suffix through MEBX \u00b6 If DHCP option15 is not set, the following needs to be set manually through MEBX if you want to re-activate the device remotely at a later time. 1. Restart or power on the device 2. While the device is booting up, press Ctrl+P to reach the MEBX login screen Important In the example above, Ctrl+P reaches the MEBX login screen. BIOS screen activation may vary among manufacturers. Check your system documentation. 3. Enter the AMT password Note If it is the first time entering MEBX and the device has not been provisioned previously, the default password is admin . It will prompt you to create a new password. 4. Select \u2018Remote Setup and Configuration\u2019 5. Select \u2018TLS PKI\u2019 6. Select \u2018PKI DNS Suffix\u2019 7. Provide a DNS suffix name and press enter 8. Press Esc three times to reach the main menu 9. Select \u2018MEBX Exit\u2019, and then press 'y' to confirm the exit","title":"DNS Suffix"},{"location":"Reference/MEBX/dnsSuffix/#manageability-engine-bios-extensions-mebx","text":"Intel\u00ae MEBX allows for configuration of the Intel Manageability Engine (ME) platform. Through this interface, you can provision AMT and customize a variety of settings manually.","title":"Manageability Engine BIOS Extensions (MEBX)"},{"location":"Reference/MEBX/dnsSuffix/#set-a-dns-suffix-through-mebx","text":"If DHCP option15 is not set, the following needs to be set manually through MEBX if you want to re-activate the device remotely at a later time. 1. Restart or power on the device 2. While the device is booting up, press Ctrl+P to reach the MEBX login screen Important In the example above, Ctrl+P reaches the MEBX login screen. BIOS screen activation may vary among manufacturers. Check your system documentation. 3. Enter the AMT password Note If it is the first time entering MEBX and the device has not been provisioned previously, the default password is admin . It will prompt you to create a new password. 4. Select \u2018Remote Setup and Configuration\u2019 5. Select \u2018TLS PKI\u2019 6. Select \u2018PKI DNS Suffix\u2019 7. Provide a DNS suffix name and press enter 8. Press Esc three times to reach the main menu 9. Select \u2018MEBX Exit\u2019, and then press 'y' to confirm the exit","title":"Set a DNS Suffix through MEBX"},{"location":"Reference/MEBX/unprovision/","text":"Manageability Engine BIOS Extensions (MEBX) \u00b6 Intel\u00ae MEBX allows for configuration of the Intel Manageability Engine (ME) platform. Through this interface, you can provision AMT and customize a variety of settings manually. Unprovision an AMT Device Through MEBX \u00b6 1. Restart or power on the device 2. While the device is booting up, press Ctrl+P to reach the MEBX login screen Important In the example above, Ctrl+P reaches the MEBX login screen. BIOS screen activation may vary among manufacturers. Check your system documentation. 3. Enter the AMT password Note If it is the first time entering MEBX, the default password is admin . It will prompt you to create a new password. 4. Select \u2018Intel AMT configuration\u2019 5. Select \u2018Unconfigure Network access\u2019 6. Select \u2018Full unprovision\u2019, and then press 'y' to continue 7. It takes 30 seconds to a minute to unprovision the device. While it is unprovisioning, the up/down arrow keys will not work.","title":"Unprovisioning"},{"location":"Reference/MEBX/unprovision/#manageability-engine-bios-extensions-mebx","text":"Intel\u00ae MEBX allows for configuration of the Intel Manageability Engine (ME) platform. Through this interface, you can provision AMT and customize a variety of settings manually.","title":"Manageability Engine BIOS Extensions (MEBX)"},{"location":"Reference/MEBX/unprovision/#unprovision-an-amt-device-through-mebx","text":"1. Restart or power on the device 2. While the device is booting up, press Ctrl+P to reach the MEBX login screen Important In the example above, Ctrl+P reaches the MEBX login screen. BIOS screen activation may vary among manufacturers. Check your system documentation. 3. Enter the AMT password Note If it is the first time entering MEBX, the default password is admin . It will prompt you to create a new password. 4. Select \u2018Intel AMT configuration\u2019 5. Select \u2018Unconfigure Network access\u2019 6. Select \u2018Full unprovision\u2019, and then press 'y' to continue 7. It takes 30 seconds to a minute to unprovision the device. While it is unprovisioning, the up/down arrow keys will not work.","title":"Unprovision an AMT Device Through MEBX"},{"location":"Reference/MPS/configuration/","text":"MPS Configuration Options \u00b6 Environment Variable Default Description MPS_IMAGE mps-microservice:v1 Only used when using docker-compose.yml. Specifies image to use for MPS MPS_USE_VAULT true Whether or not the vault should be used MPS_VAULT_ADDRESS http://vault:8200 Address of where the vault is hosted MPS_VAULT_TOKEN myroot Token used to access the vault MPS_SECRETS_PATH secret/data/ Path to where secrets are stored in the vault MPS_GENERATE_CERTS true Enables/Disables generation of self signed certificates based on MPS_COMMON_NAME MPS_COMMON_NAME localhost Development system's IP address. Note: For this guide, you cannot use localhost because the managed device would be unable to reach the MPS and RPS servers. MPS_PORT 4433 MPS_WEB_PORT 3000 MPS_WEB_ADMIN_USER n/a Specifies the username for API authentication MPS_WEB_ADMIN_PASSWORD n/a Specifies the password for API authentication MPS_HTTPS true Specifies whether or not to enable https MPS_TLS_OFFLOAD false MPS_LOG_LEVEL info Controls the level of logging provided in the service. Options are (in order of increasing detail): error , warn , info , verbose , debug , and silly . MPS_JWT_SECRET n/a Secret used for generating a JWT Token. IMPORTANT: This must match the secret in your Kong.yaml file for the jwt plugin configuration. MPS_JWT_ISSUER 9EmRJTbIiIb4bIeSsmgcWIjrR6HyETqc The issuer that will be populated in the token. This is a not considered a secret. IMPORTANT: This must match the key: property in the Kong.yaml file for the jwt plugin configuration. MPS_JWT_EXPIRATION 1440 The default expiration in minutes for the JWT Token. Default is 24 hours. MPS_MQTT_ADDRESS No Value Address of where the mqtt broker is hosted. Mqtt container is named mosquitto and is open to port 8883 . Thus unless setting are changed the value should be either empty (off) or mqtt://mosquitto:8883 (on) MPS_CONNECTION_STRING postgresql://postgresadmin@localhost:5432/mpsdb?sslmode=no-verify The database connection string","title":"Configuration"},{"location":"Reference/MPS/configuration/#mps-configuration-options","text":"Environment Variable Default Description MPS_IMAGE mps-microservice:v1 Only used when using docker-compose.yml. Specifies image to use for MPS MPS_USE_VAULT true Whether or not the vault should be used MPS_VAULT_ADDRESS http://vault:8200 Address of where the vault is hosted MPS_VAULT_TOKEN myroot Token used to access the vault MPS_SECRETS_PATH secret/data/ Path to where secrets are stored in the vault MPS_GENERATE_CERTS true Enables/Disables generation of self signed certificates based on MPS_COMMON_NAME MPS_COMMON_NAME localhost Development system's IP address. Note: For this guide, you cannot use localhost because the managed device would be unable to reach the MPS and RPS servers. MPS_PORT 4433 MPS_WEB_PORT 3000 MPS_WEB_ADMIN_USER n/a Specifies the username for API authentication MPS_WEB_ADMIN_PASSWORD n/a Specifies the password for API authentication MPS_HTTPS true Specifies whether or not to enable https MPS_TLS_OFFLOAD false MPS_LOG_LEVEL info Controls the level of logging provided in the service. Options are (in order of increasing detail): error , warn , info , verbose , debug , and silly . MPS_JWT_SECRET n/a Secret used for generating a JWT Token. IMPORTANT: This must match the secret in your Kong.yaml file for the jwt plugin configuration. MPS_JWT_ISSUER 9EmRJTbIiIb4bIeSsmgcWIjrR6HyETqc The issuer that will be populated in the token. This is a not considered a secret. IMPORTANT: This must match the key: property in the Kong.yaml file for the jwt plugin configuration. MPS_JWT_EXPIRATION 1440 The default expiration in minutes for the JWT Token. Default is 24 hours. MPS_MQTT_ADDRESS No Value Address of where the mqtt broker is hosted. Mqtt container is named mosquitto and is open to port 8883 . Thus unless setting are changed the value should be either empty (off) or mqtt://mosquitto:8883 (on) MPS_CONNECTION_STRING postgresql://postgresadmin@localhost:5432/mpsdb?sslmode=no-verify The database connection string","title":"MPS Configuration Options"},{"location":"Reference/MPS/securityMPS/","text":"MPS Security Considerations \u00b6 The cloud agnostic microservice Management Presence Server ( MPS ) enables platforms featuring Intel\u00ae AMT to connect over the internet securely to manageability consoles. Secrets are used to ensure the security of the MPS REST APIs. In a deployment environment, consider these security assets: Intel\u00ae AMT remote admin credentials Intel\u00ae AMT CIRA credentials Authorize API end point Server Configuration Web User Credentials In addition to the above assets, there are best practices that are recommended to help secure these assets as they are used within the system. The following sections will cover each asset and the recommended practices to use to protect the assets. Security Assets \u00b6 1. Intel\u00ae AMT remote admin credentials \u00b6 Intel\u00ae AMT remote admin credentials enable a user to remotely control a device featuring Intel\u00ae AMT. These credentials are configured in AMT Firmware by a configuration server (e.g., RPS ). When an administrator performs a REST API call, such as a power off action to the managed device, MPS fetches the corresponding credentials of that device from the configured secrets store (e.g., Vault). MPS uses the fetched secret as part of digest authentication with Intel\u00ae AMT. Intel discourages reuse of passwords among managed devices. Use a strong, unique password for each device to enhance security. 2. Intel\u00ae AMT CIRA credentials \u00b6 When a managed device attempts to establish a connection to the MPS , the MPS performs two checks prior to allowing the connection: 1. The Intel\u00ae AMT device's GUID: This GUID must be stored in the MPS database and is typically added by using the devices POST API. 2. MPS CIRA Credential: The Intel\u00ae AMT device needs to supply the correct credentials to MPS . These credentials are checked against the username, stored in the database, and password, stored in Vault. Use a strong, unique password for each device to enhance security. 3. Authorize API end point \u00b6 MPS supports basic user authentication to the REST APIs with an Authorize API endpoint for issuing a JSON Web Token (JWT). This eliminates the need to set up a full user authentication service before evaluating the software and enables developers to use the microservices right away. However, in a production deployment, use a robust user authentication service (e.g., OAuth2, OpenID, LDAP) and disable the Authorize API endpoint by leaving the MPS Web User credentials blank in the MPS configuration file. 4. Server Configuration \u00b6 To use secure protocols, MPS requires configured certificates and securely stored certificate keys. If the keys are compromised, an attacker will be able to decrypt messages that are encrypted with these certificates. For evaluation purposes, MPS will generate self-signed certificates used for encryption. For production deployment, purchase CA-signed certificates whose signatures can be independently verified. 5. Web User Credentials \u00b6 The Open AMT Cloud Toolkit is designed to operate behind an API gateway, such as Kong API Gateway. The API Gateway validates the Auth Tokens provided by an administrator who is requesting access to an API end point. Once verified, the API Gateway will forward the request to the appropriate microservice, MPS or RPS . To make evaluation easy, MPS has implemented an Authorize API end point that will issue a JWT when the proper web user credentials are provided. The Web User credentials are global credentials that are configured in the MPS configuration file and do not provide any fine-grain permissions. Integration with other user authentication models and fine-grain endpoint permissions are supported through Kong plug-ins and modification of the Kong API Gateway configuration file, respectively. Best Known Security Methods \u00b6 1. Enable TLS on Network Connections \u00b6 There are three potential places where TLS could be enabled to protect the security assets: HTTPS/WSS connection between Web UI and MPS (recommended) Connection between MPS and Vault - If communication between MPS and Vault is outside a secure container environment (not recommended deployment, see item 2 below) Connection between MPS and Intel\u00ae AMT device (required and done automatically by MPS ) Securing these communication routes will help prevent security assets being exposed through network based attacks intercepting messages between components. It is recommended that the most modern version of TLS be used when encrypting communication. 2. Secure and Isolate Execution Environment \u00b6 MPS holds several security assets in memory during execution. To protect these assets while in the memory of MPS , run MPS in a secure execution environment such as a dedicated container. Deploying into a secure container environment eases the burden of individually securing the assets while in memory or in transit between Open AMT Cloud Toolkit services. Running MPS , RPS , API Gateway, MPS Router, Vault, and Database all within the same secure container instance will help ensure that the communication between these services remains secure. 3. Use Vault for Storing Credentials \u00b6 Vault is a tool used to secure, store, and tightly control access to secrets. Utilizing Vault to store passwords used by MPS will greatly increase the security of these assets. 4. Use Kubernetes Secrets for Storing Dynamic Configuration Values \u00b6 Kubernetes Secrets help you to store and manage sensitive information like Tokens. Use Kubernetes secrets for storing environment variables required for configuring MPS rather than putting them in the image/pod. Vault token, Session secret key, and Server configuration assets required for MPS should be stored in Kubernetes secrets.","title":"Security Information"},{"location":"Reference/MPS/securityMPS/#mps-security-considerations","text":"The cloud agnostic microservice Management Presence Server ( MPS ) enables platforms featuring Intel\u00ae AMT to connect over the internet securely to manageability consoles. Secrets are used to ensure the security of the MPS REST APIs. In a deployment environment, consider these security assets: Intel\u00ae AMT remote admin credentials Intel\u00ae AMT CIRA credentials Authorize API end point Server Configuration Web User Credentials In addition to the above assets, there are best practices that are recommended to help secure these assets as they are used within the system. The following sections will cover each asset and the recommended practices to use to protect the assets.","title":"MPS Security Considerations"},{"location":"Reference/MPS/securityMPS/#security-assets","text":"","title":"Security Assets"},{"location":"Reference/MPS/securityMPS/#1-intel-amt-remote-admin-credentials","text":"Intel\u00ae AMT remote admin credentials enable a user to remotely control a device featuring Intel\u00ae AMT. These credentials are configured in AMT Firmware by a configuration server (e.g., RPS ). When an administrator performs a REST API call, such as a power off action to the managed device, MPS fetches the corresponding credentials of that device from the configured secrets store (e.g., Vault). MPS uses the fetched secret as part of digest authentication with Intel\u00ae AMT. Intel discourages reuse of passwords among managed devices. Use a strong, unique password for each device to enhance security.","title":"1. Intel&reg; AMT remote admin credentials"},{"location":"Reference/MPS/securityMPS/#2-intel-amt-cira-credentials","text":"When a managed device attempts to establish a connection to the MPS , the MPS performs two checks prior to allowing the connection: 1. The Intel\u00ae AMT device's GUID: This GUID must be stored in the MPS database and is typically added by using the devices POST API. 2. MPS CIRA Credential: The Intel\u00ae AMT device needs to supply the correct credentials to MPS . These credentials are checked against the username, stored in the database, and password, stored in Vault. Use a strong, unique password for each device to enhance security.","title":"2. Intel&reg; AMT CIRA credentials"},{"location":"Reference/MPS/securityMPS/#3-authorize-api-end-point","text":"MPS supports basic user authentication to the REST APIs with an Authorize API endpoint for issuing a JSON Web Token (JWT). This eliminates the need to set up a full user authentication service before evaluating the software and enables developers to use the microservices right away. However, in a production deployment, use a robust user authentication service (e.g., OAuth2, OpenID, LDAP) and disable the Authorize API endpoint by leaving the MPS Web User credentials blank in the MPS configuration file.","title":"3. Authorize API end point"},{"location":"Reference/MPS/securityMPS/#4-server-configuration","text":"To use secure protocols, MPS requires configured certificates and securely stored certificate keys. If the keys are compromised, an attacker will be able to decrypt messages that are encrypted with these certificates. For evaluation purposes, MPS will generate self-signed certificates used for encryption. For production deployment, purchase CA-signed certificates whose signatures can be independently verified.","title":"4. Server Configuration"},{"location":"Reference/MPS/securityMPS/#5-web-user-credentials","text":"The Open AMT Cloud Toolkit is designed to operate behind an API gateway, such as Kong API Gateway. The API Gateway validates the Auth Tokens provided by an administrator who is requesting access to an API end point. Once verified, the API Gateway will forward the request to the appropriate microservice, MPS or RPS . To make evaluation easy, MPS has implemented an Authorize API end point that will issue a JWT when the proper web user credentials are provided. The Web User credentials are global credentials that are configured in the MPS configuration file and do not provide any fine-grain permissions. Integration with other user authentication models and fine-grain endpoint permissions are supported through Kong plug-ins and modification of the Kong API Gateway configuration file, respectively.","title":"5. Web User Credentials"},{"location":"Reference/MPS/securityMPS/#best-known-security-methods","text":"","title":"Best Known Security Methods"},{"location":"Reference/MPS/securityMPS/#1-enable-tls-on-network-connections","text":"There are three potential places where TLS could be enabled to protect the security assets: HTTPS/WSS connection between Web UI and MPS (recommended) Connection between MPS and Vault - If communication between MPS and Vault is outside a secure container environment (not recommended deployment, see item 2 below) Connection between MPS and Intel\u00ae AMT device (required and done automatically by MPS ) Securing these communication routes will help prevent security assets being exposed through network based attacks intercepting messages between components. It is recommended that the most modern version of TLS be used when encrypting communication.","title":"1. Enable TLS on Network Connections"},{"location":"Reference/MPS/securityMPS/#2-secure-and-isolate-execution-environment","text":"MPS holds several security assets in memory during execution. To protect these assets while in the memory of MPS , run MPS in a secure execution environment such as a dedicated container. Deploying into a secure container environment eases the burden of individually securing the assets while in memory or in transit between Open AMT Cloud Toolkit services. Running MPS , RPS , API Gateway, MPS Router, Vault, and Database all within the same secure container instance will help ensure that the communication between these services remains secure.","title":"2. Secure and Isolate Execution Environment"},{"location":"Reference/MPS/securityMPS/#3-use-vault-for-storing-credentials","text":"Vault is a tool used to secure, store, and tightly control access to secrets. Utilizing Vault to store passwords used by MPS will greatly increase the security of these assets.","title":"3. Use Vault for Storing Credentials"},{"location":"Reference/MPS/securityMPS/#4-use-kubernetes-secrets-for-storing-dynamic-configuration-values","text":"Kubernetes Secrets help you to store and manage sensitive information like Tokens. Use Kubernetes secrets for storing environment variables required for configuring MPS rather than putting them in the image/pod. Vault token, Session secret key, and Server configuration assets required for MPS should be stored in Kubernetes secrets.","title":"4. Use Kubernetes Secrets for Storing Dynamic Configuration Values"},{"location":"Reference/MQTT/customMqttEvents/","text":"RPS and MPS microservices can publish event messages through an MQTT Broker. The following instructions demonstrate how to add, remove, or edit the events published by the server. To learn more about subscribing to these events, see Viewing MQTT Events . Three main components can be manipulated within the MQTT event flow: Individual events throughout MPS and RPS MqttProvider class MQTT broker Individual Events \u00b6 Add Events \u00b6 To add an event: Import MqttProvider class. Use the publishEvent method to add RPS or MPS events. Example: import { MqttProvider } from '../../utils/mqttProvider' MqttProvider . publishEvent ( 'success' , [ 'Example' ], 'Hello World' , guid ) The publishEvent method parameters: Parameter Description message type string designating the message type array of methods methods associated with the message message string message to be published by the event broker GUID device GUID (optional) Note Learn more about publishEvent in the MqttProvider Class . Edit or Delete Events \u00b6 A number of default events have been added to RPS and MPS , such as API calls and action events. Edit or delete any events that are unnecessary or irrelevant for your deployment. Note Event publishing operates independently of the microservices. It will function normally with the addition, adaptation, or deletion of any individual events. MqttProvider Class \u00b6 Connect \u00b6 The MqttProvider class handles the interactions with the MQTT Broker. To establish a connection with the broker: Open the index.ts file of RPS or MPS . Add the following: const mqtt : MqttProvider = new MqttProvider ( config ) mqtt . connectBroker () The connectBroker method creates the connection between a client, stored in the class, and the mosquitto docker container, which acts as the MQTT Broker. The instance of the class, after it has been created and connected, is stored as a static object within the class. This storage enables access to the methods in the class with a simple import rather than passing the instance to MPS or RPS . The config parameter contains the config types of MPS and RPS . MqttProvider uses the MQTT_ADDRESS environment variable to establish a connection. Important The MQTT_ADDRESS environment variables for MPS and RPS are left blank in the .env.template file. This corresponds to the OFF state. To turn event logging with mosquitto ON provide the address of the MQTT Broker, mqtt://mosquitto:8883 , to the MPS_MQTT_ADDRESS and RPS_MQTT_ADDRESS environment variables. Usage \u00b6 The publishEvent method publishes events to the MQTT Broker where subscribers can access event data. The method accepts information about an event, organizes it, adds a timestamp, and sends it to the MQTT Broker. Expand the setup by changing the parameters and the elements within OpenAMTEvent , the interface used to organize the message, or by adding new methods. Indicate information you'd like to receive by subscribing to Topics, which are organized in a directory-like structure. Topics enable administrators to narrow eventing to subjects of interest. Example message type 'success' message: 'CarStarted' topic: cars/ford Subscribers of # , cars or cars/ford receive the above message while subscribers of trucks or cars/ferrari will not. Use publish to send a message to the MQTT Broker and supply a topic as the first argument. Currently, the topic is hard-coded to a default value. Alter this value by adding a parameter, tying the topic to existing parameters, or create different publishEvent methods that correspond to different topics. MQTT Broker \u00b6 The Broker for MQTT messages runs as the Docker* container mosquitto with the image eclipse-mosquitto:latest . Make changes to the functionality of the Broker through mosquitto.conf . Most of the Broker setup has been left in its default state but more information about customizing the broker can be found here .","title":"Customizing MQTT Events"},{"location":"Reference/MQTT/customMqttEvents/#individual-events","text":"","title":"Individual Events"},{"location":"Reference/MQTT/customMqttEvents/#add-events","text":"To add an event: Import MqttProvider class. Use the publishEvent method to add RPS or MPS events. Example: import { MqttProvider } from '../../utils/mqttProvider' MqttProvider . publishEvent ( 'success' , [ 'Example' ], 'Hello World' , guid ) The publishEvent method parameters: Parameter Description message type string designating the message type array of methods methods associated with the message message string message to be published by the event broker GUID device GUID (optional) Note Learn more about publishEvent in the MqttProvider Class .","title":"Add Events"},{"location":"Reference/MQTT/customMqttEvents/#edit-or-delete-events","text":"A number of default events have been added to RPS and MPS , such as API calls and action events. Edit or delete any events that are unnecessary or irrelevant for your deployment. Note Event publishing operates independently of the microservices. It will function normally with the addition, adaptation, or deletion of any individual events.","title":"Edit or Delete Events"},{"location":"Reference/MQTT/customMqttEvents/#mqttprovider-class","text":"","title":"MqttProvider Class"},{"location":"Reference/MQTT/customMqttEvents/#connect","text":"The MqttProvider class handles the interactions with the MQTT Broker. To establish a connection with the broker: Open the index.ts file of RPS or MPS . Add the following: const mqtt : MqttProvider = new MqttProvider ( config ) mqtt . connectBroker () The connectBroker method creates the connection between a client, stored in the class, and the mosquitto docker container, which acts as the MQTT Broker. The instance of the class, after it has been created and connected, is stored as a static object within the class. This storage enables access to the methods in the class with a simple import rather than passing the instance to MPS or RPS . The config parameter contains the config types of MPS and RPS . MqttProvider uses the MQTT_ADDRESS environment variable to establish a connection. Important The MQTT_ADDRESS environment variables for MPS and RPS are left blank in the .env.template file. This corresponds to the OFF state. To turn event logging with mosquitto ON provide the address of the MQTT Broker, mqtt://mosquitto:8883 , to the MPS_MQTT_ADDRESS and RPS_MQTT_ADDRESS environment variables.","title":"Connect"},{"location":"Reference/MQTT/customMqttEvents/#usage","text":"The publishEvent method publishes events to the MQTT Broker where subscribers can access event data. The method accepts information about an event, organizes it, adds a timestamp, and sends it to the MQTT Broker. Expand the setup by changing the parameters and the elements within OpenAMTEvent , the interface used to organize the message, or by adding new methods. Indicate information you'd like to receive by subscribing to Topics, which are organized in a directory-like structure. Topics enable administrators to narrow eventing to subjects of interest. Example message type 'success' message: 'CarStarted' topic: cars/ford Subscribers of # , cars or cars/ford receive the above message while subscribers of trucks or cars/ferrari will not. Use publish to send a message to the MQTT Broker and supply a topic as the first argument. Currently, the topic is hard-coded to a default value. Alter this value by adding a parameter, tying the topic to existing parameters, or create different publishEvent methods that correspond to different topics.","title":"Usage "},{"location":"Reference/MQTT/customMqttEvents/#mqtt-broker","text":"The Broker for MQTT messages runs as the Docker* container mosquitto with the image eclipse-mosquitto:latest . Make changes to the functionality of the Broker through mosquitto.conf . Most of the Broker setup has been left in its default state but more information about customizing the broker can be found here .","title":"MQTT Broker"},{"location":"Reference/MQTT/viewMqttEvents/","text":"Event Monitoring with MQTT ( MQTT Eventing) \u00b6 Open AMT Cloud Toolkit supports Eventing using Message Queuing Telemetry Transport ( MQTT ), an IoT publish-and-subscribe network protocol. With MQTT Eventing, administrators can subscribe to specific topics, categories of events, for server event monitoring. This eliminates the need to query or poll MPS to determine network events, such as a device's activation or deactivation. Administrators can subscribe to events and respond proactively. Important Currently, the implementation publishes all MPS REST API call events to the MQTT Broker. Figure 1: MQTT Eventing Examples An Open AMT Cloud Toolkit sends JSON events to a Mosquitto* broker deployed as a Docker container. Administrators subscribe to the broker. As shown in Figure 1, proactive notifications are published in the MQTT Broker container. What You'll Need \u00b6 Obtain MQTT Explorer: Choose the MQTT tool of your choice. In the example, below we use is MQTT Explorer. Go to the Microsoft Store. See other supported OS installation packages . Type MQTT-Explorer in Search . Choose Get and then Install . Set Up MQTT Support \u00b6 To enable support: In a text editor or IDE of choice, open the .env file to edit. Update the field MPS_MQTT_ADDRESS with mqtt://mosquitto:8883 . The mqtt: prefix indicates an MQTT broker is being used. Kong* will now route event messages to port 8883. Save and close the file. Rebuild the MPS image and start the container. If your stack was deployed locally using Docker: docker-compose up -d --build mps Open MQTT Explorer to see the events: Choose + Connections to create a new connection. Add a Name (suggested: MPS ). Verify Validate certificate and Encryption (tls) are disabled . Choose the mqtt:// option from the dropdown protocol . In the Host field, add the IP address of the system where Kong is installed. In the Port field, add 8883. Choose Connect. Example In the Sample Web UI , click on a managed device from Devices list or make an API call to see an event appear in MQTT Explorer.","title":"Viewing MQTT Events"},{"location":"Reference/MQTT/viewMqttEvents/#event-monitoring-with-mqtt-mqtt-eventing","text":"Open AMT Cloud Toolkit supports Eventing using Message Queuing Telemetry Transport ( MQTT ), an IoT publish-and-subscribe network protocol. With MQTT Eventing, administrators can subscribe to specific topics, categories of events, for server event monitoring. This eliminates the need to query or poll MPS to determine network events, such as a device's activation or deactivation. Administrators can subscribe to events and respond proactively. Important Currently, the implementation publishes all MPS REST API call events to the MQTT Broker. Figure 1: MQTT Eventing Examples An Open AMT Cloud Toolkit sends JSON events to a Mosquitto* broker deployed as a Docker container. Administrators subscribe to the broker. As shown in Figure 1, proactive notifications are published in the MQTT Broker container.","title":"Event Monitoring with MQTT (MQTT Eventing)"},{"location":"Reference/MQTT/viewMqttEvents/#what-youll-need","text":"Obtain MQTT Explorer: Choose the MQTT tool of your choice. In the example, below we use is MQTT Explorer. Go to the Microsoft Store. See other supported OS installation packages . Type MQTT-Explorer in Search . Choose Get and then Install .","title":"What You'll Need"},{"location":"Reference/MQTT/viewMqttEvents/#set-up-mqtt-support","text":"To enable support: In a text editor or IDE of choice, open the .env file to edit. Update the field MPS_MQTT_ADDRESS with mqtt://mosquitto:8883 . The mqtt: prefix indicates an MQTT broker is being used. Kong* will now route event messages to port 8883. Save and close the file. Rebuild the MPS image and start the container. If your stack was deployed locally using Docker: docker-compose up -d --build mps Open MQTT Explorer to see the events: Choose + Connections to create a new connection. Add a Name (suggested: MPS ). Verify Validate certificate and Encryption (tls) are disabled . Choose the mqtt:// option from the dropdown protocol . In the Host field, add the IP address of the system where Kong is installed. In the Port field, add 8883. Choose Connect. Example In the Sample Web UI , click on a managed device from Devices list or make an API call to see an event appear in MQTT Explorer.","title":"Set Up MQTT Support"},{"location":"Reference/RPC/buildRPC_Manual/","text":"In addition to using GitHub Actions to obtain a binary, the RPC binary can also be manually built. The steps below walk through how to build RPC on Windows\u00ae 10, Ubuntu* (18.04 or 20.04), and CentOS 7/8. Required Software \u00b6 git Additionally, if using Windows\u00ae 10: Microsoft Visual Studio* : 2019 or newer version of Visual Studio Community/Professional Make sure to install the Desktop development with C++ package at time of installation or via the 'Get tools and extensions' menu within Microsoft Visual Studio*. The steps below assume the following directory structure where rpc is the clone of the rpc repository , vcpkg is a clone of the VCPKG tool source and build is the RPC build directory. Both vcpkg and build directories will be created in later steps. \\rpc |__vcpkg |__build Clone the Repository \u00b6 On your development system, navigate to a directory of your choice to clone and build RPC . Clone the RPC repository. git clone --branch v2.0.0 https://github.com/open-amt-cloud-toolkit/rpc.git && cd rpc Install Prerequisites and Build RPC \u00b6 Windows Open 'x64 Native Tools Command Prompt for VS 20XX' on your development system. This is NOT a regular Windows Command Prompt. This specific tool is used for compiling the RPC executable. Build VCPKG and C++ REST SDK In the rpc directory, clone the VCPKG repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. bootstrap-vcpkg.bat Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. vcpkg install cpprestsdk [ websockets ] :x64-windows-static Build RPC Return to the rpc directory and create a new build directory. cd .. && mkdir build && cd build Generate the CMake config. cmake -DVCPKG_TARGET_TRIPLET = x64-windows-static -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake .. Build the RPC executable. cmake --build . --config Release Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake --build . --config Debug Change to Release directory. cd Release Ubuntu/CentOS 8 The following steps are for Ubuntu 18.04, Ubuntu 20.04, or CentOS8. Build VCPKG and C++ REST SDK To install the required dependencies; enter the following command. Ubuntu sudo apt install git cmake build-essential curl zip unzip tar pkg-config CentOS8 sudo yum install cmake In the rpc directory, clone the Vcpkg repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. ./bootstrap-vcpkg.sh Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. ./vcpkg install cpprestsdk [ websockets ] Build RPC Return to the rpc directory and create a new 'build' directory. cd .. && mkdir build && cd build Generate the CMake config. cmake -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE = Release .. Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake -DCMAKE_TOOLCHAIN_FILE=../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE=Debug .. Build the RPC executable. cmake --build . CentOS 7 Important All commands should be executed in the same Terminal. The \"export PATH=...\" (for CMake and Git), and \"scl enable devtoolset-7 bash\" (for GCC) are temporary changes which only affect the current Terminal session. Install Dependencies Download CMake. CMake 3.10.2 is recommended and can be downloaded from here . Other CMake binary versions are available here . ./cmake-3.10.2-Linux-x86_64.sh export PATH = /home/user/Downloads/cmake-3.10.2-Linux-x86_64/bin: $PATH Update GCC toolchain. sudo yum install centos-release-scl sudo yum install devtoolset-7 scl enable devtoolset-7 bash Build Git source control system. sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develperl-CPAN perl-devel git clone https://github.com/git/git.git make configure make export PATH = /home/user/Downloads/git: $PATH Build VCPKG and C++ REST SDK In the rpc directory, clone the VCPKG repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. ./bootstrap-vcpkg.sh Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. ./vcpkg install cpprestsdk [ websockets ] Build RPC Return to the rpc directory and create a new 'build' directory. cd .. && mkdir build && cd build Generate the CMake config cmake -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE = Release -DNO_SELECT = ON .. Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake -DCMAKE_TOOLCHAIN_FILE=../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE=Debug -DNO_SELECT=ON .. Build the RPC executable cmake --build . Run RPC \u00b6 For additional information on possible arguments when invoking RPC , see Command Examples . The following example command shows how to activate and configure an Intel\u00ae AMT device using a pre-defined profile on your local network. After building the RPC , copy the executable to the managed device. Run the RPC . Windows Important On a Windows\u00ae 10 system, the Command Prompt must be run as Adminstrator. rpc --url wss://localhost/activate --nocertcheck --cmd \"-t activate --profile profile1\" Linux sudo ./rpc --url wss://localhost/activate --nocertcheck --cmd \"-t activate --profile profile1\" Note The --nocertcheck flag allows for the use of self-signed certificates for development purposes. Find more information here Example Success Output:","title":"Build & Run RPC (Manual)"},{"location":"Reference/RPC/buildRPC_Manual/#required-software","text":"git Additionally, if using Windows\u00ae 10: Microsoft Visual Studio* : 2019 or newer version of Visual Studio Community/Professional Make sure to install the Desktop development with C++ package at time of installation or via the 'Get tools and extensions' menu within Microsoft Visual Studio*. The steps below assume the following directory structure where rpc is the clone of the rpc repository , vcpkg is a clone of the VCPKG tool source and build is the RPC build directory. Both vcpkg and build directories will be created in later steps. \\rpc |__vcpkg |__build","title":"Required Software"},{"location":"Reference/RPC/buildRPC_Manual/#clone-the-repository","text":"On your development system, navigate to a directory of your choice to clone and build RPC . Clone the RPC repository. git clone --branch v2.0.0 https://github.com/open-amt-cloud-toolkit/rpc.git && cd rpc","title":"Clone the Repository"},{"location":"Reference/RPC/buildRPC_Manual/#install-prerequisites-and-build-rpc","text":"Windows Open 'x64 Native Tools Command Prompt for VS 20XX' on your development system. This is NOT a regular Windows Command Prompt. This specific tool is used for compiling the RPC executable. Build VCPKG and C++ REST SDK In the rpc directory, clone the VCPKG repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. bootstrap-vcpkg.bat Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. vcpkg install cpprestsdk [ websockets ] :x64-windows-static Build RPC Return to the rpc directory and create a new build directory. cd .. && mkdir build && cd build Generate the CMake config. cmake -DVCPKG_TARGET_TRIPLET = x64-windows-static -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake .. Build the RPC executable. cmake --build . --config Release Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake --build . --config Debug Change to Release directory. cd Release Ubuntu/CentOS 8 The following steps are for Ubuntu 18.04, Ubuntu 20.04, or CentOS8. Build VCPKG and C++ REST SDK To install the required dependencies; enter the following command. Ubuntu sudo apt install git cmake build-essential curl zip unzip tar pkg-config CentOS8 sudo yum install cmake In the rpc directory, clone the Vcpkg repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. ./bootstrap-vcpkg.sh Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. ./vcpkg install cpprestsdk [ websockets ] Build RPC Return to the rpc directory and create a new 'build' directory. cd .. && mkdir build && cd build Generate the CMake config. cmake -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE = Release .. Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake -DCMAKE_TOOLCHAIN_FILE=../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE=Debug .. Build the RPC executable. cmake --build . CentOS 7 Important All commands should be executed in the same Terminal. The \"export PATH=...\" (for CMake and Git), and \"scl enable devtoolset-7 bash\" (for GCC) are temporary changes which only affect the current Terminal session. Install Dependencies Download CMake. CMake 3.10.2 is recommended and can be downloaded from here . Other CMake binary versions are available here . ./cmake-3.10.2-Linux-x86_64.sh export PATH = /home/user/Downloads/cmake-3.10.2-Linux-x86_64/bin: $PATH Update GCC toolchain. sudo yum install centos-release-scl sudo yum install devtoolset-7 scl enable devtoolset-7 bash Build Git source control system. sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develperl-CPAN perl-devel git clone https://github.com/git/git.git make configure make export PATH = /home/user/Downloads/git: $PATH Build VCPKG and C++ REST SDK In the rpc directory, clone the VCPKG repository. Vcpkg is a C/C++ Library Manager for Windows that was created by Microsoft. Find out more about it here . git clone --branch 2020 .11-1 https://github.com/microsoft/vcpkg.git && cd vcpkg Build vcpkg.exe using the following command. ./bootstrap-vcpkg.sh Install C++ REST SDK. This can take anywhere from 8 - 15 minutes depending on download speeds and installation times. ./vcpkg install cpprestsdk [ websockets ] Build RPC Return to the rpc directory and create a new 'build' directory. cd .. && mkdir build && cd build Generate the CMake config cmake -DCMAKE_TOOLCHAIN_FILE = ../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE = Release -DNO_SELECT = ON .. Note RPC can also be built in a non-production debug mode rather than release using the following command. The debug mode includes debug symbols. cmake -DCMAKE_TOOLCHAIN_FILE=../vcpkg/scripts/buildsystems/vcpkg.cmake -DCMAKE_BUILD_TYPE=Debug -DNO_SELECT=ON .. Build the RPC executable cmake --build .","title":"Install Prerequisites and Build RPC"},{"location":"Reference/RPC/buildRPC_Manual/#run-rpc","text":"For additional information on possible arguments when invoking RPC , see Command Examples . The following example command shows how to activate and configure an Intel\u00ae AMT device using a pre-defined profile on your local network. After building the RPC , copy the executable to the managed device. Run the RPC . Windows Important On a Windows\u00ae 10 system, the Command Prompt must be run as Adminstrator. rpc --url wss://localhost/activate --nocertcheck --cmd \"-t activate --profile profile1\" Linux sudo ./rpc --url wss://localhost/activate --nocertcheck --cmd \"-t activate --profile profile1\" Note The --nocertcheck flag allows for the use of self-signed certificates for development purposes. Find more information here Example Success Output:","title":"Run RPC"},{"location":"Reference/RPC/commandsRPC/","text":"RPC is primarily used for communicating with the Remote Provision Server ( RPS ) for activating and/or deactivating AMT devices. Optional arguments allow for things such as easier development testing or for use in network environments utilizing proxies. All currently available arguments and their definitions are listed below along with example commands. RPC Usage \u00b6 On Windows: rpc <required> [ optional ] rpc <informational> On Linux: sudo ./rpc <required> [ optional ] sudo ./rpc <informational> On Docker: sudo docker run --device = /dev/mei0 rpc:latest <required> [ optional ] sudo docker run --device = /dev/mei0 rpc:latest <informational> RPC Arguments \u00b6 Required \u00b6 Argument\u2003\u2003\u2003\u2003\u2003\u2003 Name \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 Description -c, --cmd <command> Server Command Activate or Deactivate command for AMT device. See example commands below. -u, --url <url> Websocket Server Address and Port of the RPS server, wss://localhost:8080. By default, RPS runs on port 8080. RPC Activate/Deactivate Examples \u00b6 Activate a Device: rpc --url wss://localhost/activate --cmd \"activate --profile profile1\" Deactivate a Device: rpc -u wss://localhost/activate -c \"deactivate --password P@ssw0rd\" Note The --password nested argument uses the AMT password set at the time of provisioning of the device based on the RPS Profile . This password should be able to be retrieved from Vault, if unknown. Deactivate a Device if Unknown by RPS (or Vault): rpc -u wss://localhost/activate -c \"deactivate --password [AMT-Password] -f\" Optional \u00b6 Argument\u2003\u2003\u2003\u2003 Name\u2003\u2003\u2003\u2003\u2003\u2003 Description -d, --dns <dns> DNS Suffix Override -n, --nocertcheck Certificate Verification Disable certificate verification. Allows for the use of self-signed certificates during development testing. Not valid for production. Otherwise, a TLS Certificate from a trusted Certificate Authority provider is required. -p, --proxy <addr> Proxy Address and Port Allow for connection through a network proxy, http://proxy.com:1000 -v, --verbose Verbose Output Display WSMan communication with RPS when executing RPC Examples \u00b6 Override DNS detection and Activate device: rpc --url wss://localhost/activate --cmd \"activate --profile profile1\" --dns corp.com Connect through proxy and Deactivate device: rpc -u wss://localhost/activate -c \"deactivate --password P@ssw0rd\" -p http://proxy.com:1000 Informational \u00b6 Argument Name Description --help Help text Display help menu in-line --version Version Current version of RPC --amtinfo <item> AMT info View available information Possible <item> Parameters: all - View all items ver - BIOS version bld - Build number sku - Product SKU uuid - Device's Unique Identifier mode - Current Control Mode, ACM or CCM dns - Domain Name Suffix from AMT and from OS fqdn - Fully aualified domain name and device hostname from OS cert - Certificate hashes ras - Remote access status lan - LAN settings, i.e. DHCP Enabled, Link Status, and IP/MAC Addresses Examples \u00b6 View All Information Items: rpc --amtinfo all Find Current Device's GUID: rpc --amtinfo uuid","title":"Command Examples"},{"location":"Reference/RPC/commandsRPC/#rpc-usage","text":"On Windows: rpc <required> [ optional ] rpc <informational> On Linux: sudo ./rpc <required> [ optional ] sudo ./rpc <informational> On Docker: sudo docker run --device = /dev/mei0 rpc:latest <required> [ optional ] sudo docker run --device = /dev/mei0 rpc:latest <informational>","title":"RPC Usage"},{"location":"Reference/RPC/commandsRPC/#rpc-arguments","text":"","title":"RPC Arguments"},{"location":"Reference/RPC/commandsRPC/#required","text":"Argument\u2003\u2003\u2003\u2003\u2003\u2003 Name \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 Description -c, --cmd <command> Server Command Activate or Deactivate command for AMT device. See example commands below. -u, --url <url> Websocket Server Address and Port of the RPS server, wss://localhost:8080. By default, RPS runs on port 8080.","title":"Required"},{"location":"Reference/RPC/commandsRPC/#rpc-activatedeactivate-examples","text":"Activate a Device: rpc --url wss://localhost/activate --cmd \"activate --profile profile1\" Deactivate a Device: rpc -u wss://localhost/activate -c \"deactivate --password P@ssw0rd\" Note The --password nested argument uses the AMT password set at the time of provisioning of the device based on the RPS Profile . This password should be able to be retrieved from Vault, if unknown. Deactivate a Device if Unknown by RPS (or Vault): rpc -u wss://localhost/activate -c \"deactivate --password [AMT-Password] -f\"","title":"RPC Activate/Deactivate Examples"},{"location":"Reference/RPC/commandsRPC/#optional","text":"Argument\u2003\u2003\u2003\u2003 Name\u2003\u2003\u2003\u2003\u2003\u2003 Description -d, --dns <dns> DNS Suffix Override -n, --nocertcheck Certificate Verification Disable certificate verification. Allows for the use of self-signed certificates during development testing. Not valid for production. Otherwise, a TLS Certificate from a trusted Certificate Authority provider is required. -p, --proxy <addr> Proxy Address and Port Allow for connection through a network proxy, http://proxy.com:1000 -v, --verbose Verbose Output Display WSMan communication with RPS when executing RPC","title":"Optional "},{"location":"Reference/RPC/commandsRPC/#examples","text":"Override DNS detection and Activate device: rpc --url wss://localhost/activate --cmd \"activate --profile profile1\" --dns corp.com Connect through proxy and Deactivate device: rpc -u wss://localhost/activate -c \"deactivate --password P@ssw0rd\" -p http://proxy.com:1000","title":"Examples"},{"location":"Reference/RPC/commandsRPC/#informational","text":"Argument Name Description --help Help text Display help menu in-line --version Version Current version of RPC --amtinfo <item> AMT info View available information Possible <item> Parameters: all - View all items ver - BIOS version bld - Build number sku - Product SKU uuid - Device's Unique Identifier mode - Current Control Mode, ACM or CCM dns - Domain Name Suffix from AMT and from OS fqdn - Fully aualified domain name and device hostname from OS cert - Certificate hashes ras - Remote access status lan - LAN settings, i.e. DHCP Enabled, Link Status, and IP/MAC Addresses","title":"Informational"},{"location":"Reference/RPC/commandsRPC/#examples_1","text":"View All Information Items: rpc --amtinfo all Find Current Device's GUID: rpc --amtinfo uuid","title":"Examples"},{"location":"Reference/RPS/configuration/","text":"RPS Configuration \u00b6 Environment Variable Default Description RPS_IMAGE rps-microservice:v1 Only used when using docker-compose.yml. Specifies image to use for RPS RPS_CONNECTION_STRING postgresql://postgresadmin@localhost:5432/rpsdb?sslmode=no-verify The database connection string RPS_WEB_PORT 8081 Specifies the Web API port to listen on RPS_WEBSOCKETPORT 8080 Specifies the Websocket port to listen on RPS_VAULT_ADDRESS http://vault:8200 Address of where the vault is hosted RPS_VAULT_TOKEN myroot Token used to access the vault RPS_SECRETS_PATH secret/data/ Specifies the path for where secrets are stored in the vault RPS_LOG_LEVEL info Controls the level of logging provided in the service. Options are (in order of increasing detail): error , warn , info , verbose , debug , and silly RPS_MPS_SERVER http://localhost:3000 Specifies where the MPS is hosted -- required for metadata registration (i.e. hostname, and tags) RPS_DELAY_TIMER 12 Sets the number of seconds to wait after activation but before proceeding with final steps. By default it is set to 12 seconds. During this waiting period, RPS sends heartbeats to RPC to keep the connection alive. RPS_MQTT_ADDRESS No Value Address of where the mqtt broker is hosted. Mqtt container is named mosquitto and is open to port 8883 . Thus unless setting are changed the value should be either empty (off) or mqtt://mosquitto:8883 (on)","title":"Configuration"},{"location":"Reference/RPS/configuration/#rps-configuration","text":"Environment Variable Default Description RPS_IMAGE rps-microservice:v1 Only used when using docker-compose.yml. Specifies image to use for RPS RPS_CONNECTION_STRING postgresql://postgresadmin@localhost:5432/rpsdb?sslmode=no-verify The database connection string RPS_WEB_PORT 8081 Specifies the Web API port to listen on RPS_WEBSOCKETPORT 8080 Specifies the Websocket port to listen on RPS_VAULT_ADDRESS http://vault:8200 Address of where the vault is hosted RPS_VAULT_TOKEN myroot Token used to access the vault RPS_SECRETS_PATH secret/data/ Specifies the path for where secrets are stored in the vault RPS_LOG_LEVEL info Controls the level of logging provided in the service. Options are (in order of increasing detail): error , warn , info , verbose , debug , and silly RPS_MPS_SERVER http://localhost:3000 Specifies where the MPS is hosted -- required for metadata registration (i.e. hostname, and tags) RPS_DELAY_TIMER 12 Sets the number of seconds to wait after activation but before proceeding with final steps. By default it is set to 12 seconds. During this waiting period, RPS sends heartbeats to RPC to keep the connection alive. RPS_MQTT_ADDRESS No Value Address of where the mqtt broker is hosted. Mqtt container is named mosquitto and is open to port 8883 . Thus unless setting are changed the value should be either empty (off) or mqtt://mosquitto:8883 (on)","title":"RPS Configuration"},{"location":"Reference/RPS/networkConfig/","text":"Network Configuration profiles on the RPS server help to set the desired network on the AMT device. The AMT Ethernet Port Setting is the AMT API used to set the network settings in AMT by the RPS . RPS network profiles currently contain three boolean settings. DHCPEnabled - is a boolean. Indicates whether DHCP is in use. SharedStaticIp - is a boolean. Indicates whether the static host IP is shared with ME. IpSyncEnabled - is a boolean. Indicates whether the IP synchronization between host and ME is enabled. Predefined Profiles \u00b6 RPS currently supports two predefined network configurations, DHCP_Enabled and DHCP_Disabled, with the following settings. DHCP_Enabled Network Config: { \"ProfileName\" : \"dhcp_enabled\" , \"DHCPEnabled\" : true , \"StaticIPShared\" : false , \"IPSyncEnabled\" : true } DHCP_Disabled Network Config: { \"ProfileName\" : \"dhcp_disabled\" , \"DHCPEnabled\" : false , \"StaticIPShared\" : true , \"IPSyncEnabled\" : true } Example Scenarios \u00b6 The following are scenarios depicting the result of RPS attempting to set network settings in comparison to the set Host OS settings. Host OS RPS Network Profile Used Network Settings on Device \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 Result Static IP DHCP_Enabled \u2716 DHCP in Use \u2714 Shared Static IP \u2716 IP Sync RPS update the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. Static IP DHCP_Disabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS update the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. Note: Sets the same static IP address as host. Static IP DHCP_Disabled \u2716 DHCP in Use \u2714 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Note: Sets the same static IP address as host as IP Sync is enabled. DHCP DHCP_Enabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. DHCP DHCP_Disabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Set SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS.","title":"Network Profiles"},{"location":"Reference/RPS/networkConfig/#predefined-profiles","text":"RPS currently supports two predefined network configurations, DHCP_Enabled and DHCP_Disabled, with the following settings. DHCP_Enabled Network Config: { \"ProfileName\" : \"dhcp_enabled\" , \"DHCPEnabled\" : true , \"StaticIPShared\" : false , \"IPSyncEnabled\" : true } DHCP_Disabled Network Config: { \"ProfileName\" : \"dhcp_disabled\" , \"DHCPEnabled\" : false , \"StaticIPShared\" : true , \"IPSyncEnabled\" : true }","title":"Predefined Profiles"},{"location":"Reference/RPS/networkConfig/#example-scenarios","text":"The following are scenarios depicting the result of RPS attempting to set network settings in comparison to the set Host OS settings. Host OS RPS Network Profile Used Network Settings on Device \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 Result Static IP DHCP_Enabled \u2716 DHCP in Use \u2714 Shared Static IP \u2716 IP Sync RPS update the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. Static IP DHCP_Disabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS update the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. Note: Sets the same static IP address as host. Static IP DHCP_Disabled \u2716 DHCP in Use \u2714 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Note: Sets the same static IP address as host as IP Sync is enabled. DHCP DHCP_Enabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Deletes SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS. DHCP DHCP_Disabled \u2714 DHCP in Use \u2716 Shared Static IP \u2716 IP Sync RPS updates the device settings as per the profile. Set SubnetMask, DefaultGateway, IPAddress, PrimaryDNS, and SecondaryDNS.","title":"Example Scenarios"},{"location":"Reference/RPS/securityRPS/","text":"RPS Security Considerations \u00b6 The microservice Remote Provision Service ( RPS ) plays a component role in a larger set of services that makes up the device management software suite. In this role, RPS uses and creates secrets that are required to be able to successfully activate and use Intel\u00ae AMT . There are six key assets that must be protected: Remote admin password for Intel\u00ae AMT MEBX password for Intel\u00ae AMT Provisioning Certificate for each supported domain Password used to encrypt each Provisioning Certificate Device configuration information sent to Intel\u00ae AMT device MPS CIRA login credentials In addition to the above assets, there are best practices that are recommended to help secure these assets as they are used within the system. The following sections will cover each asset and the recommended practices to use to protect the assets. Security Assets \u00b6 Remote Admin Password for Intel\u00ae AMT \u00b6 This password is what is configured in the Intel\u00ae AMT firmware that allows a remote user to remotely control the Intel\u00ae AMT device (power actions, remote desktop, remote terminal, etc). When RPS activates an Intel\u00ae AMT device, it sets this password in the Intel\u00ae AMT firmware. This password can either be statically set or can be randomly generated based on the profile defined by the user. It is highly recommended to use randomly generated passwords as this will make each Intel\u00ae AMT device more secure by using unique passwords per device. In a default docker or Kubernetes deployment, RPS will save the Remote Admin Password to the deployed Vault instance. MEBX Password for Intel\u00ae AMT \u00b6 The Management Engine BIOS Extension (MEBX) password is the password that protects the pre-boot menu option that provides access to Intel\u00ae AMT settings. To use this password a user needs to have physical access to the device. It is highly recommended to change this password from the factory default settings upon receiving a new Intel\u00ae AMT device. A RPS profile provides an option for either specifying a static password that is used for all devices configured with a given profile or a randomly generated password can be assigned uniquely per device. The MEBX password set in each device is saved in Vault. While a randomly generated password is more secure, in this case there is risk that if the Vault database is lost, access to the Intel\u00ae AMT device could be very difficult to recover. It is recommended to use the high availability and backup options provided by the Vault solution to ensure that these secrets are not lost. Provisioning Certificate for each supported domain \u00b6 This certificate is unique per owned domain where RPS needs to provision Intel\u00ae AMT devices. This certificate must be derived from a root certificate whose hash matches one of the trusted provisioning root certificate hashes that is listed in the Intel\u00ae AMT device firmware. Generally, the provisioning certificate is purchased from a trusted certificate authority (VeriSign, GoDaddy, Comodo, etc). The full list of supported CAs based on Intel\u00ae AMT version are listed here . This certificate must contain the leaf certificate, root certificate, and all of the intermediate certificates to form a complete certificate chain. Additionally, the certificate file must also include the private key for the certificate (.pfx format). The leaf certificate for the provisioning certificate must match the domain suffix that the Intel\u00ae AMT device is connected as specified by DHCP option 15 or the Trusted DNS suffix in the Management Engine BIOS Extensions (MEBX). Matching this is one of the ways in which the Intel\u00ae AMT firmware establishes trust with RPS . The provisioning certificate is provided by the user when defining an Intel\u00ae AMT profile. RPS fetches the Provisioning Certificate from Vault when it is needed to activate an Intel\u00ae AMT device. If users have provisioning certificates, they will need to understand which profile to use when configuring an Intel\u00ae AMT device based on the network to which the device is currently connected. Password used to encrypt Provisioning Certificate \u00b6 This is the password that is used to encrypt the provisioning certificate .pfx file that is discussed above. RPS uses this password to decrypt the provisioning certificate so that it can use the certificate components and the private key to activate Intel\u00ae AMT devices. RPS fetches the password from Vault and will use it when it is needed to decrypt a provisioning certificate. Device configuration information sent to Intel\u00ae AMT device \u00b6 Intel\u00ae AMT firmware uses configuration information to establish trust and then activate the Intel\u00ae AMT device. The information contains the hashed remote admin password and MEBX password. Protect this information while it is being used by RPS and while in transit to the Intel\u00ae AMT device. Ensure that a secure (TLS-encrypted) WebSocket is used when RPS is communicating with the client device. This will protect data in transit. The configuration information uses nonces to prevent replay of this data. MPS CIRA Login Credentials \u00b6 To connect to the MPS over a CIRA connection, the Intel\u00ae AMT device needs to provide the correct login credentials for MPS . These credentials are specified as part of the AMT Profile created in RPS . When a device is configured by RPS , the MPS CIRA credentials will be sent to MPS using the Devices POST API call where MPS will then store the credentials. These credentials are verfied by the MPS when the CIRA connection is established. Best Known Security Methods \u00b6 1 Enable TLS on network connections \u00b6 There are two potential places where TLS could be enable to protect the security assets: * WebSocket connection between RPS and Intel\u00ae AMT client (recommended) * Connection between RPS and Vault - If communication between RPS and Vault is outside a secure container environment (not recommended deployment, see item 2 below) Securing these communication routes will help prevent security assets being exposed through network based attacks intercepting messages between components. It is recommended that the most modern version of TLS be used when encrypting communication. 2 Secure and isolate execution environment \u00b6 RPS holds several of the described security assets in memory during execution. In order to protect these assets while in the memory of RPS , it is recommended that RPS be run in a secure execution environment such as a dedicated container. Deploying into a secure container environment eases the burden of individually securing the assets while in memory or in transit between Open AMT Cloud Toolkit services. Running MPS , RPS , API Gateway, MPS Router, Vault, and Database all within the same secure container instance will help ensure that the communication between these services remains secure. 3 Utilize a Hashicorp Vault implementation to store security assets \u00b6 Utilizing Hashicorp Vault to store security assets either created by or used by RPS will greatly increase the security of these assets. Not only does Vault encrypt the data at rest, but it also manages access to the data itself. As the Vault owner, you decide who gets access to the security assets stored there, not RPS .","title":"Security Information"},{"location":"Reference/RPS/securityRPS/#rps-security-considerations","text":"The microservice Remote Provision Service ( RPS ) plays a component role in a larger set of services that makes up the device management software suite. In this role, RPS uses and creates secrets that are required to be able to successfully activate and use Intel\u00ae AMT . There are six key assets that must be protected: Remote admin password for Intel\u00ae AMT MEBX password for Intel\u00ae AMT Provisioning Certificate for each supported domain Password used to encrypt each Provisioning Certificate Device configuration information sent to Intel\u00ae AMT device MPS CIRA login credentials In addition to the above assets, there are best practices that are recommended to help secure these assets as they are used within the system. The following sections will cover each asset and the recommended practices to use to protect the assets.","title":"RPS Security Considerations"},{"location":"Reference/RPS/securityRPS/#security-assets","text":"","title":"Security Assets"},{"location":"Reference/RPS/securityRPS/#remote-admin-password-for-intel-amt","text":"This password is what is configured in the Intel\u00ae AMT firmware that allows a remote user to remotely control the Intel\u00ae AMT device (power actions, remote desktop, remote terminal, etc). When RPS activates an Intel\u00ae AMT device, it sets this password in the Intel\u00ae AMT firmware. This password can either be statically set or can be randomly generated based on the profile defined by the user. It is highly recommended to use randomly generated passwords as this will make each Intel\u00ae AMT device more secure by using unique passwords per device. In a default docker or Kubernetes deployment, RPS will save the Remote Admin Password to the deployed Vault instance.","title":"Remote Admin Password for Intel&reg; AMT"},{"location":"Reference/RPS/securityRPS/#mebx-password-for-intel-amt","text":"The Management Engine BIOS Extension (MEBX) password is the password that protects the pre-boot menu option that provides access to Intel\u00ae AMT settings. To use this password a user needs to have physical access to the device. It is highly recommended to change this password from the factory default settings upon receiving a new Intel\u00ae AMT device. A RPS profile provides an option for either specifying a static password that is used for all devices configured with a given profile or a randomly generated password can be assigned uniquely per device. The MEBX password set in each device is saved in Vault. While a randomly generated password is more secure, in this case there is risk that if the Vault database is lost, access to the Intel\u00ae AMT device could be very difficult to recover. It is recommended to use the high availability and backup options provided by the Vault solution to ensure that these secrets are not lost.","title":"MEBX Password for Intel&reg; AMT"},{"location":"Reference/RPS/securityRPS/#provisioning-certificate-for-each-supported-domain","text":"This certificate is unique per owned domain where RPS needs to provision Intel\u00ae AMT devices. This certificate must be derived from a root certificate whose hash matches one of the trusted provisioning root certificate hashes that is listed in the Intel\u00ae AMT device firmware. Generally, the provisioning certificate is purchased from a trusted certificate authority (VeriSign, GoDaddy, Comodo, etc). The full list of supported CAs based on Intel\u00ae AMT version are listed here . This certificate must contain the leaf certificate, root certificate, and all of the intermediate certificates to form a complete certificate chain. Additionally, the certificate file must also include the private key for the certificate (.pfx format). The leaf certificate for the provisioning certificate must match the domain suffix that the Intel\u00ae AMT device is connected as specified by DHCP option 15 or the Trusted DNS suffix in the Management Engine BIOS Extensions (MEBX). Matching this is one of the ways in which the Intel\u00ae AMT firmware establishes trust with RPS . The provisioning certificate is provided by the user when defining an Intel\u00ae AMT profile. RPS fetches the Provisioning Certificate from Vault when it is needed to activate an Intel\u00ae AMT device. If users have provisioning certificates, they will need to understand which profile to use when configuring an Intel\u00ae AMT device based on the network to which the device is currently connected.","title":"Provisioning Certificate for each supported domain"},{"location":"Reference/RPS/securityRPS/#password-used-to-encrypt-provisioning-certificate","text":"This is the password that is used to encrypt the provisioning certificate .pfx file that is discussed above. RPS uses this password to decrypt the provisioning certificate so that it can use the certificate components and the private key to activate Intel\u00ae AMT devices. RPS fetches the password from Vault and will use it when it is needed to decrypt a provisioning certificate.","title":"Password used to encrypt Provisioning Certificate"},{"location":"Reference/RPS/securityRPS/#device-configuration-information-sent-to-intel-amt-device","text":"Intel\u00ae AMT firmware uses configuration information to establish trust and then activate the Intel\u00ae AMT device. The information contains the hashed remote admin password and MEBX password. Protect this information while it is being used by RPS and while in transit to the Intel\u00ae AMT device. Ensure that a secure (TLS-encrypted) WebSocket is used when RPS is communicating with the client device. This will protect data in transit. The configuration information uses nonces to prevent replay of this data.","title":"Device configuration information sent to Intel\u00ae AMT device"},{"location":"Reference/RPS/securityRPS/#mps-cira-login-credentials","text":"To connect to the MPS over a CIRA connection, the Intel\u00ae AMT device needs to provide the correct login credentials for MPS . These credentials are specified as part of the AMT Profile created in RPS . When a device is configured by RPS , the MPS CIRA credentials will be sent to MPS using the Devices POST API call where MPS will then store the credentials. These credentials are verfied by the MPS when the CIRA connection is established.","title":"MPS CIRA Login Credentials"},{"location":"Reference/RPS/securityRPS/#best-known-security-methods","text":"","title":"Best Known Security Methods"},{"location":"Reference/RPS/securityRPS/#1-enable-tls-on-network-connections","text":"There are two potential places where TLS could be enable to protect the security assets: * WebSocket connection between RPS and Intel\u00ae AMT client (recommended) * Connection between RPS and Vault - If communication between RPS and Vault is outside a secure container environment (not recommended deployment, see item 2 below) Securing these communication routes will help prevent security assets being exposed through network based attacks intercepting messages between components. It is recommended that the most modern version of TLS be used when encrypting communication.","title":"1 Enable TLS on network connections"},{"location":"Reference/RPS/securityRPS/#2-secure-and-isolate-execution-environment","text":"RPS holds several of the described security assets in memory during execution. In order to protect these assets while in the memory of RPS , it is recommended that RPS be run in a secure execution environment such as a dedicated container. Deploying into a secure container environment eases the burden of individually securing the assets while in memory or in transit between Open AMT Cloud Toolkit services. Running MPS , RPS , API Gateway, MPS Router, Vault, and Database all within the same secure container instance will help ensure that the communication between these services remains secure.","title":"2 Secure and isolate execution environment"},{"location":"Reference/RPS/securityRPS/#3-utilize-a-hashicorp-vault-implementation-to-store-security-assets","text":"Utilizing Hashicorp Vault to store security assets either created by or used by RPS will greatly increase the security of these assets. Not only does Vault encrypt the data at rest, but it also manages access to the data itself. As the Vault owner, you decide who gets access to the security assets stored there, not RPS .","title":"3 Utilize a Hashicorp Vault implementation to store security assets"},{"location":"Reference/UIToolkit/localization/","text":"Localize Strings \u00b6 Create a new directory in the ui-toolkit/public/locales/ directory. The directory name must match one of the codes listed . Copy the translation.json file in the public/locales/en/ directory to the new language directory. Customize the required fields in the translation.json file. Example To support Kannada language: Create a new directory kn in /public/locales/ Copy translation.json from /locales/en/ to /locales/kn/ directory Update key-values in /kn/translation.json according to Kannada language Open the i18n.ts file in the ui-toolkit directory. Modify the file to import the newly added public/locales/Language/translation.json file and update the 'resources' constant to include the new translation. Example To support Kannada language: Create new import statement as 'translationKN' Edit resources constant to include new translation import translationEN from './public/locales/en/translation.json' import translationKN from './public/locales/kn/translation.json'; const resources = { en: { translations: translationEN }, kn: { translations: translationKN } }; Rebuild and generate a new bundle before testing the changes. Language can be changed in the browser under language section of the browser settings. English is the default if no customized translation file provided for the language. Get Localized Strings for Web Consoles with Localization Enabled \u00b6 If your web console already has localization enabled, make sure to add the translations of the UI-controls into your web console's translations file.","title":"Localization"},{"location":"Reference/UIToolkit/localization/#localize-strings","text":"Create a new directory in the ui-toolkit/public/locales/ directory. The directory name must match one of the codes listed . Copy the translation.json file in the public/locales/en/ directory to the new language directory. Customize the required fields in the translation.json file. Example To support Kannada language: Create a new directory kn in /public/locales/ Copy translation.json from /locales/en/ to /locales/kn/ directory Update key-values in /kn/translation.json according to Kannada language Open the i18n.ts file in the ui-toolkit directory. Modify the file to import the newly added public/locales/Language/translation.json file and update the 'resources' constant to include the new translation. Example To support Kannada language: Create new import statement as 'translationKN' Edit resources constant to include new translation import translationEN from './public/locales/en/translation.json' import translationKN from './public/locales/kn/translation.json'; const resources = { en: { translations: translationEN }, kn: { translations: translationKN } }; Rebuild and generate a new bundle before testing the changes. Language can be changed in the browser under language section of the browser settings. English is the default if no customized translation file provided for the language.","title":"Localize Strings"},{"location":"Reference/UIToolkit/localization/#get-localized-strings-for-web-consoles-with-localization-enabled","text":"If your web console already has localization enabled, make sure to add the translations of the UI-controls into your web console's translations file.","title":"Get Localized Strings for Web Consoles with Localization Enabled"},{"location":"Reference/UIToolkit/webpackConfig/","text":"To use Webpack *, understand its Core Concepts: Entry: The entry point such as /src/index.js , which is the default for Webpack 4 is what Webpack will use to start building out/resolving its dependencies. Output: The output property, such as ./dist , the default for Webpack 4, tells Webpack where to output the bundles it creates and how to name them. Loaders: Because Webpack only understands native Javascript code, these loaders enable Webpack to process different types of imported files and convert them into valid modules when it encounters a specific type of file. Loaders have two properties in the configuration file: The test property identifies the file or files that should be transformed The use property indicates the loader that can be used to do the transforming Plugins: The plugins enable the extension of Webpack capabilities to perform a wider range of tasks like bundle optimization, asset management, and injection of environment variables. Install Webpack \u00b6 Install both webpack and webpack cli as dev dependencies: npm i webpack webpack-cli -D webpack-dev-server . Configure Webpack for the Development Environment \u00b6 To configure: Create a Webpack config file webpack.config.dev.js in the root of the project folder. Add the development environment to the webpack.config.dev.js file:** const path = require ( 'path' ); module . exports = { mode : \"development\" , entry : './src/reactjs/components/KVM/index.tsx' , // entry points can be multiple } Add Typescript \u00b6 The example code below resolves the file extensions, .tsx, .ts and .js. Files with the extensions .tsx or .ts are processed by awesome-typescript-loader. To add Typescript support: Install the Typescript dependency, awesome-typescript-loader: npm i awesome-typescript-loader -D 2. Add the configuration to the webpack.config.dev.js file: Example: const path = require ( 'path' ); module . exports = { .... resolve : { extensions : [ \".tsx\" , \".ts\" , \".js\" ] }, module : { rules : [ { test : /\\.tsx?$/ , loader : 'awesome-typescript-loader' } ] } } Add Styles \u00b6 To Add Styles support: Use npm to install css-loader and sass-loader: npm i style-loader css-loader sass-loader -D Add the configuration to the webpack.config.dev.js file: module . exports = { .... module : { rules : [ ... { test : /\\.(sc|sa|c)ss$/ , use : [ 'style-loader' , 'css-loader' , 'sass-loader' ], } ] } } Add HTML \u00b6 To add HTML support: Use the Webpack plugin html-webpack-plugin, which helps simplify the creation of HTML files to help serve our Webpack bundles: npm i html-webpack-plugin -D. Add the configuration to the webpack.config.dev.js file: const path = require ( 'path' ); const HtmlWebpackPlugin = require ( 'html-webpack-plugin' ); module . exports = { .... plugins : [ new HtmlWebpackPlugin ({ filename : \"kvm.htm\" , template : \"./src/sample/sampleKVM.htm\" , inject : true , chunks : [ \"kvm\" ], }), ] } Development Server \u00b6 Set up a development server using the webpack-dev-server. This server opens a default browser upon npm start and provide us with live reloading. npm i webpack-dev-server --D Update Package.json \u00b6 Add webpack-dev-server to the Package.json file: \"scripts\" : { \"start\" : \"webpack-dev-server --config webpack.config.dev.js\" } Example Sample usage: Open command prompt. Run npm start command. Configure Webpack for Production Environment \u00b6 To add production environment support: Create a Webpack config file webpack.config.prod.js in the root of our project folder. Add the configuration to the webpack.config.prod.js file: const path = require ( 'path' ); module . exports = { mode : \"production\" , entry : './src/reactjs/components/KVM/index.tsx' , // entry points can be multiple output : { filename : \"[name].min.js\" , path : path . resolve ( __dirname , \"./dist\" ) }, .... } 3. Update Package.json: \"scripts\" : { \"build\" : \"webpack --config webpack.config.prod.js\" , } Example Sample usage: Open command prompt. Run npm run build. Configure Webpack for External Environment \u00b6 Create a Webpack config file webpack.config.externals.js in the root of our project folder. Add webpack-node-externals: Install webpack-node-externals dependencies: npm install webpack-node-externals -D The webpack-node-externals library creates an externals function that ignores node_modules when bundling in Webpack . Add the following to webpack.config.externals.js : const path = require ( \"path\" ); //No ES6 in webpack config const nodeExternals = require ( 'webpack-node-externals' ); module . exports = { .... externals : [ nodeExternals ()], }; 3. Update Package.json: \"scripts\" : { \"build-ext\" : \"webpack --config webpack.config.externals.js\" , } Example Sample usage: Open command prompt. Run npm run build-ext command.","title":"Webpack Configuration"},{"location":"Reference/UIToolkit/webpackConfig/#install-webpack","text":"Install both webpack and webpack cli as dev dependencies: npm i webpack webpack-cli -D webpack-dev-server .","title":"Install Webpack"},{"location":"Reference/UIToolkit/webpackConfig/#configure-webpack-for-the-development-environment","text":"To configure: Create a Webpack config file webpack.config.dev.js in the root of the project folder. Add the development environment to the webpack.config.dev.js file:** const path = require ( 'path' ); module . exports = { mode : \"development\" , entry : './src/reactjs/components/KVM/index.tsx' , // entry points can be multiple }","title":"Configure Webpack for the Development Environment"},{"location":"Reference/UIToolkit/webpackConfig/#add-typescript","text":"The example code below resolves the file extensions, .tsx, .ts and .js. Files with the extensions .tsx or .ts are processed by awesome-typescript-loader. To add Typescript support: Install the Typescript dependency, awesome-typescript-loader: npm i awesome-typescript-loader -D 2. Add the configuration to the webpack.config.dev.js file: Example: const path = require ( 'path' ); module . exports = { .... resolve : { extensions : [ \".tsx\" , \".ts\" , \".js\" ] }, module : { rules : [ { test : /\\.tsx?$/ , loader : 'awesome-typescript-loader' } ] } }","title":"Add Typescript"},{"location":"Reference/UIToolkit/webpackConfig/#add-styles","text":"To Add Styles support: Use npm to install css-loader and sass-loader: npm i style-loader css-loader sass-loader -D Add the configuration to the webpack.config.dev.js file: module . exports = { .... module : { rules : [ ... { test : /\\.(sc|sa|c)ss$/ , use : [ 'style-loader' , 'css-loader' , 'sass-loader' ], } ] } }","title":"Add Styles"},{"location":"Reference/UIToolkit/webpackConfig/#add-html","text":"To add HTML support: Use the Webpack plugin html-webpack-plugin, which helps simplify the creation of HTML files to help serve our Webpack bundles: npm i html-webpack-plugin -D. Add the configuration to the webpack.config.dev.js file: const path = require ( 'path' ); const HtmlWebpackPlugin = require ( 'html-webpack-plugin' ); module . exports = { .... plugins : [ new HtmlWebpackPlugin ({ filename : \"kvm.htm\" , template : \"./src/sample/sampleKVM.htm\" , inject : true , chunks : [ \"kvm\" ], }), ] }","title":"Add HTML"},{"location":"Reference/UIToolkit/webpackConfig/#development-server","text":"Set up a development server using the webpack-dev-server. This server opens a default browser upon npm start and provide us with live reloading. npm i webpack-dev-server --D","title":"Development Server"},{"location":"Reference/UIToolkit/webpackConfig/#update-packagejson","text":"Add webpack-dev-server to the Package.json file: \"scripts\" : { \"start\" : \"webpack-dev-server --config webpack.config.dev.js\" } Example Sample usage: Open command prompt. Run npm start command.","title":"Update Package.json"},{"location":"Reference/UIToolkit/webpackConfig/#configure-webpack-for-production-environment","text":"To add production environment support: Create a Webpack config file webpack.config.prod.js in the root of our project folder. Add the configuration to the webpack.config.prod.js file: const path = require ( 'path' ); module . exports = { mode : \"production\" , entry : './src/reactjs/components/KVM/index.tsx' , // entry points can be multiple output : { filename : \"[name].min.js\" , path : path . resolve ( __dirname , \"./dist\" ) }, .... } 3. Update Package.json: \"scripts\" : { \"build\" : \"webpack --config webpack.config.prod.js\" , } Example Sample usage: Open command prompt. Run npm run build.","title":"Configure Webpack for Production Environment"},{"location":"Reference/UIToolkit/webpackConfig/#configure-webpack-for-external-environment","text":"Create a Webpack config file webpack.config.externals.js in the root of our project folder. Add webpack-node-externals: Install webpack-node-externals dependencies: npm install webpack-node-externals -D The webpack-node-externals library creates an externals function that ignores node_modules when bundling in Webpack . Add the following to webpack.config.externals.js : const path = require ( \"path\" ); //No ES6 in webpack config const nodeExternals = require ( 'webpack-node-externals' ); module . exports = { .... externals : [ nodeExternals ()], }; 3. Update Package.json: \"scripts\" : { \"build-ext\" : \"webpack --config webpack.config.externals.js\" , } Example Sample usage: Open command prompt. Run npm run build-ext command.","title":"Configure Webpack for External Environment"},{"location":"Reference/UIToolkit/Bundles/kvmReact/","text":"Quickstart - Bundle Keyboard Video Mouse ( KVM ) Control \u00b6 Use these instructions to: Run the KVM control in development environment Create a bundle for KVM control Add bundle to a sample HTML file Prerequisites \u00b6 In order to deploy and make changes, the following tools and application has to be installed on your development machine: Git Visual Studio Code or any other IDE Node.js Chrome* Browser MPS Server with an AMT Device Connected Download and Install UI Toolkit \u00b6 Open a Terminal (Linux) or Command Prompt (Windows) and navigate to a directory of your choice for development. Clone the UI Toolkit Repository: git clone https://github.com/open-amt-cloud-toolkit/ui-toolkit --branch v2.0.0 Change to the ui-toolkit directory: cd ui_toolkit Install the dependencies: npm install Run in Development Environment \u00b6 To add and test new changes before bundling the control, use a webpack dev server: Start the server: npm start Open a Chrome* browser and navigate to the following link to see changes: http://localhost:8080/kvm.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Note By default, the webpack dev server runs on port 8080. If port 8080 is already in use, webpack automatically runs on the next immediate available port. Create Bundle \u00b6 To bundle, navigate to the ui-toolkit directory in a Terminal (Linux) or Command Prompt (Windows). Remove or rename the existing kvm.min.js in the ui-toolkit/dist/ directory before building. Build the bundle: npm run build A new kvm.min.js will be created in the ui-toolkit/dist/ directory. Note To bundle the KVM control without node_modules, run the following build command instead. npm run built-ext The bundle generated using the build-ext command can be used in react apps as an independent control Add to Sample HTML Page \u00b6 Add the following code snippet to sampleKVM.htm in the ui-toolkit/src/reactjs/sample/ directory using an editor of your choice: <body> <div id=\"kvm\"></div> <script src=\"../../dist/kvm.min.js\" crossorigin></script> </body> In a Terminal (Linux) or Command Prompt (Windows), navigate to the ui-toolkit directory. Serve the HTML page: npx serve Open a new Chrome* browser and navigate to the following URL: http://localhost:5000/src/sample/sampleKVM.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Errors may occur in the following scenarios: UI-toolkit was not downloaded and installed into your react app MPS Server is not running MPS Server is running but the device is not connected","title":"Keyboard, Video, Mouse"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#quickstart-bundle-keyboard-video-mouse-kvm-control","text":"Use these instructions to: Run the KVM control in development environment Create a bundle for KVM control Add bundle to a sample HTML file","title":"Quickstart - Bundle Keyboard Video Mouse (KVM) Control"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#prerequisites","text":"In order to deploy and make changes, the following tools and application has to be installed on your development machine: Git Visual Studio Code or any other IDE Node.js Chrome* Browser MPS Server with an AMT Device Connected","title":"Prerequisites"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#download-and-install-ui-toolkit","text":"Open a Terminal (Linux) or Command Prompt (Windows) and navigate to a directory of your choice for development. Clone the UI Toolkit Repository: git clone https://github.com/open-amt-cloud-toolkit/ui-toolkit --branch v2.0.0 Change to the ui-toolkit directory: cd ui_toolkit Install the dependencies: npm install","title":"Download and Install UI Toolkit"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#run-in-development-environment","text":"To add and test new changes before bundling the control, use a webpack dev server: Start the server: npm start Open a Chrome* browser and navigate to the following link to see changes: http://localhost:8080/kvm.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Note By default, the webpack dev server runs on port 8080. If port 8080 is already in use, webpack automatically runs on the next immediate available port.","title":"Run in Development Environment"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#create-bundle","text":"To bundle, navigate to the ui-toolkit directory in a Terminal (Linux) or Command Prompt (Windows). Remove or rename the existing kvm.min.js in the ui-toolkit/dist/ directory before building. Build the bundle: npm run build A new kvm.min.js will be created in the ui-toolkit/dist/ directory. Note To bundle the KVM control without node_modules, run the following build command instead. npm run built-ext The bundle generated using the build-ext command can be used in react apps as an independent control","title":"Create Bundle"},{"location":"Reference/UIToolkit/Bundles/kvmReact/#add-to-sample-html-page","text":"Add the following code snippet to sampleKVM.htm in the ui-toolkit/src/reactjs/sample/ directory using an editor of your choice: <body> <div id=\"kvm\"></div> <script src=\"../../dist/kvm.min.js\" crossorigin></script> </body> In a Terminal (Linux) or Command Prompt (Windows), navigate to the ui-toolkit directory. Serve the HTML page: npx serve Open a new Chrome* browser and navigate to the following URL: http://localhost:5000/src/sample/sampleKVM.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Errors may occur in the following scenarios: UI-toolkit was not downloaded and installed into your react app MPS Server is not running MPS Server is running but the device is not connected","title":"Add to Sample HTML Page"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/","text":"Quickstart - Bundle Serial Over LAN ( SOL ) Control \u00b6 Use these instructions to: Run the SOL control in development environment Create a bundle for SOL control Add bundle to a sample HTML file Prerequisites \u00b6 In order to deploy and make changes, the following tools and application have to be installed on your development system: Git Visual Studio Code or any other IDE Node.js Chrome* Browser MPS Server with an AMT Device Connected Download and Install UI Toolkit \u00b6 Open a Terminal (Linux) or Command Prompt (Windows) and navigate to a directory of your choice for development. Clone the UI-Toolkit Repository: git clone https://github.com/open-amt-cloud-toolkit/ui-toolkit --branch v2.0.0 Change to the ui-toolkit directory: cd ui_toolkit Install the dependencies: npm install Run in Development Environment \u00b6 To add and test new changes before bundling the control, use a webpack dev server. Start the server: npm start Open a Chrome* browser and navigate to the following link to see changes: http://localhost:8080/sol.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Note By default, the webpack dev server runs on port 8080. If port 8080 is already in use, webpack automatically runs on the next immediate available port. Create Bundle \u00b6 To bundle, navigate to the ui-toolkit directory in a Terminal (Linux) or Command Prompt (Windows). Remove or rename the existing sol.min.js in the ui-toolkit/dist/ directory before building: Build the bundle: npm run build A new kvm.core.min.js will be created in the ui-toolkit/dist/ directory. Note To bundle the Serial-Over-LAN control without node_modules, run the following build command instead. npm run built-ext The bundle generated using the build-ext command can be used in react apps as an independent control Add to Sample HTML Page \u00b6 Add the following code snippet to sampleSOL.htm in the ui-toolkit/src/sample/ directory using an editor of your choice: <body> <div id= \"sol\" ></div> <script src= \"../../dist/sol.min.js\" crossorigin ></script> </body> In a Terminal (Linux) or Command Prompt (Windows), navigate to the ui-toolkit directory: Serve the HTML page. npx serve Open a new Chrome* browser and navigate to the following URL: http://localhost:5000/src/sample/sampleSOL.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Errors may occur in the following scenarios: UI-toolkit was not downloaded and installed into your react app MPS Server is not running MPS Server is running but the device is not connected","title":"Serial Over LAN"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#quickstart-bundle-serial-over-lan-sol-control","text":"Use these instructions to: Run the SOL control in development environment Create a bundle for SOL control Add bundle to a sample HTML file","title":"Quickstart  - Bundle Serial Over LAN (SOL) Control"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#prerequisites","text":"In order to deploy and make changes, the following tools and application have to be installed on your development system: Git Visual Studio Code or any other IDE Node.js Chrome* Browser MPS Server with an AMT Device Connected","title":"Prerequisites"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#download-and-install-ui-toolkit","text":"Open a Terminal (Linux) or Command Prompt (Windows) and navigate to a directory of your choice for development. Clone the UI-Toolkit Repository: git clone https://github.com/open-amt-cloud-toolkit/ui-toolkit --branch v2.0.0 Change to the ui-toolkit directory: cd ui_toolkit Install the dependencies: npm install","title":"Download and Install UI Toolkit"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#run-in-development-environment","text":"To add and test new changes before bundling the control, use a webpack dev server. Start the server: npm start Open a Chrome* browser and navigate to the following link to see changes: http://localhost:8080/sol.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Note By default, the webpack dev server runs on port 8080. If port 8080 is already in use, webpack automatically runs on the next immediate available port.","title":"Run in Development Environment"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#create-bundle","text":"To bundle, navigate to the ui-toolkit directory in a Terminal (Linux) or Command Prompt (Windows). Remove or rename the existing sol.min.js in the ui-toolkit/dist/ directory before building: Build the bundle: npm run build A new kvm.core.min.js will be created in the ui-toolkit/dist/ directory. Note To bundle the Serial-Over-LAN control without node_modules, run the following build command instead. npm run built-ext The bundle generated using the build-ext command can be used in react apps as an independent control","title":"Create Bundle"},{"location":"Reference/UIToolkit/Bundles/serialOverLANReact/#add-to-sample-html-page","text":"Add the following code snippet to sampleSOL.htm in the ui-toolkit/src/sample/ directory using an editor of your choice: <body> <div id= \"sol\" ></div> <script src= \"../../dist/sol.min.js\" crossorigin ></script> </body> In a Terminal (Linux) or Command Prompt (Windows), navigate to the ui-toolkit directory: Serve the HTML page. npx serve Open a new Chrome* browser and navigate to the following URL: http://localhost:5000/src/sample/sampleSOL.htm?deviceId=[AMT-Device-GUID]&mpsServer=https://[MPS-Server-IP-Address]:3000 Errors may occur in the following scenarios: UI-toolkit was not downloaded and installed into your react app MPS Server is not running MPS Server is running but the device is not connected","title":"Add to Sample HTML Page"},{"location":"Reference/UIToolkit/Controls/kvmControl/","text":"Not sure how to implement Keyboard, Video Mouse ( KVM )? View the UI Toolkit KVM Module Tutorial for a step-by-step walkthrough prerequisites and instructions for implementing a React Control using the UI Toolkit . Add KVM Control \u00b6 Use the following code snippet to add the KVM control to the React Application. Open src/App.js and add the code shown below: Note Change deviceId value to your device GUID, mpsServer value to your MPS server address, and pass in a valid JWT for authToken . import React from \"react\" ; import \"./App.css\" ; import { KVM } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/KVM\" ; function App () { return ( < div className = \"App\" > < KVM deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws/relay\" //Replace 'localhost' with Development System or MPS Server IP Address mouseDebounceTime = \"200\" authToken = \"\" // Replace with a valid JWT provided during login of MPS canvasHeight = \"100%\" canvasWidth = \"100%\" >< /KVM> < /div> ); } export default App ;","title":"Keyboard, Video, Mouse"},{"location":"Reference/UIToolkit/Controls/kvmControl/#add-kvm-control","text":"Use the following code snippet to add the KVM control to the React Application. Open src/App.js and add the code shown below: Note Change deviceId value to your device GUID, mpsServer value to your MPS server address, and pass in a valid JWT for authToken . import React from \"react\" ; import \"./App.css\" ; import { KVM } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/KVM\" ; function App () { return ( < div className = \"App\" > < KVM deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws/relay\" //Replace 'localhost' with Development System or MPS Server IP Address mouseDebounceTime = \"200\" authToken = \"\" // Replace with a valid JWT provided during login of MPS canvasHeight = \"100%\" canvasWidth = \"100%\" >< /KVM> < /div> ); } export default App ;","title":"Add KVM Control"},{"location":"Reference/UIToolkit/Controls/serialOverLANControl/","text":"Not sure how to implement Serial Over LAN ( SOL )? View the UI Toolkit KVM Module Tutorial for a step-by-step walkthrough of the prerequisites and instructions for implementing a React Control using the UI Toolkit . Add Serial Over LAN ( SOL ) Control \u00b6 Use the following code snippet to add the SOL control to the React Application. Open src/App.js and add the code shown below: Note Change deviceId value to your device GUID, mpsServer value to your MPS server address, and pass in a valid JWT for authToken . import React from \"react\" ; import { Sol } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/SerialOverLAN\" ; function App () { return ( < div > < Sol deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws\" //Replace 'localhost' with Development System or MPS Server IP Address authToken = \"\" > // Replace with a valid JWT provided during login of MPS < /Sol> < /div> ); } \u200b export default App ;","title":"Serial Over LAN"},{"location":"Reference/UIToolkit/Controls/serialOverLANControl/#add-serial-over-lan-sol-control","text":"Use the following code snippet to add the SOL control to the React Application. Open src/App.js and add the code shown below: Note Change deviceId value to your device GUID, mpsServer value to your MPS server address, and pass in a valid JWT for authToken . import React from \"react\" ; import { Sol } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/SerialOverLAN\" ; function App () { return ( < div > < Sol deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws\" //Replace 'localhost' with Development System or MPS Server IP Address authToken = \"\" > // Replace with a valid JWT provided during login of MPS < /Sol> < /div> ); } \u200b export default App ;","title":"Add Serial Over LAN (SOL) Control"},{"location":"Tutorials/apiTutorial/","text":"This tutorial demonstrates how to generate a JWT token for Authorization and construct a API call for Getting Devices using curl . This method will retrieve information about all devices, including device GUIDs. Figure 1: API Call to Get All Devices Important Successfully deploy the Management Presence Server ( MPS ) and Remote Provisioning Server ( RPS ) and connect an Intel\u00ae vPro device to MPS before constructing the API call. Start here * to install microservices locally with Docker . What You'll Need \u00b6 Hardware A minimum network configuration must include: A Development system with Windows\u00ae 10 or Ubuntu 18.04 or newer An Activated and Configured Intel\u00ae vPro device as the managed device Software on the Development System MPS curl Any Text Editor What You'll Do \u00b6 The following sections describe how to: Generate a new JWT for Authorization Run an API Call to MPS for Devices See Other Example GET/POST Commands Generate a Token for Authorization \u00b6 See the Authorize Method in the API Documentation for more information. Open a Terminal or Command Prompt. Copy and paste the example code below into a text editor. Update the values of the [IP-Address or FQDN] , [MPS_WEB_ADMIN_USER] , and [MPS_WEB_ADMIN_PASSWORD] fields. Linux curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/login/api/v1/authorize \\ -H \"Content-Type:application/json\" \\ -d \"{\\\"username\\\":\\\"[MPS_WEB_ADMIN_USER]\\\", \\\"password\\\":\\\" [MPS_WEB_ADMIN_PASSWORD]\\\"}\" Windows curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/login/api/v1/authorize ^ -H \"Content-Type:application/json\" ^ -d \"{\\\"username\\\":\\\"[MPS_WEB_ADMIN_USER]\\\", \\\"password\\\":\\\" [MPS_WEB_ADMIN_PASSWORD]\\\"}\" Info - Using the --insecure Flag Because we are using self-signed certificates for MPS for development and testing purposes, we must supply this flag to bypass SSL certificate verification. Run the command. Example - Response of Authorize Method { \"token\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5RW1SSlRiSWlJYjRiSWVTc21nY1dJanJSNkh5RVRxYyIsImV4cCI6MTYyMDE2OTg2NH0.GUib9sq0RWRLqJ7JpNNlj2AluuROLICCfdZaQzyWy90\" } This token will be used when making any other API call as part of the Authorization header. Run API Call for Get Devices \u00b6 See the GetDevices Method in the API Documentation for more information. Open a Terminal or Command Prompt. Copy and paste the example code below into a text editor. Update the values of the [IP-Address or FQDN] and [JWT-Token] fields. Linux curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/devices \\ -H \"Authorization: Bearer [JWT-Token]\" Windows curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/devices ^ -H \"Authorization: Bearer [JWT-Token]\" Run the command. Example - Response of Devices Method Example Terminal Output: [{ \"guid\" : \"3beae094-34f8-11ea-b6f5-ffed08129200\" , \"hostname\" : \"vpro3-NUC8v5PNK\" , \"tags\" :[], \"mpsInstance\" : \"mps\" , \"connectionStatus\" : true , \"mpsusername\" : \"admin\" }] Example JSON Pretty Print: [ { \"guid\" : \"3beae094-34f8-11ea-b6f5-ffed08129200\" , \"hostname\" : \"vpro3-NUC8v5PNK\" , \"tags\" : [], \"mpsInstance\" : \"mps\" , \"connectionStatus\" : true , \"mpsusername\" : \"admin\" } ] Important This is one way to retrieve a device's GUID in the host field. For amt path methods (i.e., Power Actions , Audit Logs, etc), the device GUID is required as part of the GET path. Save this value if you want to try other MPS methods. Other ways to retrieve a GUID can be found here . Example GET/POST Templates \u00b6 The sample GET and POST curl commands below can be adapted for other MPS and RPS methods by changing the URL path and modifying the request body data, if applicable . Power Capabilities (GET Template) Linux curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/amt/powercapabilities/ [ AMT-Device-GUID ] \\ -H \"Authorization: Bearer [JWT-Token]\" Windows curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/amt/powercapabilities/ [ AMT-Device-GUID ] ^ -H \"Authorization: Bearer [JWT-Token]\" See Power Capabilities API Docs for more information and expected responses. Power Action (POST Template) Linux curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/api/v1/amt/power/action/ [ AMT-Device-GUID ] \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer [JWT-Token]\" \\ -d \"{\\\"action\\\": [Power-Action], \\\"useSOL\\\": false}\" Windows curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/api/v1/amt/power/action/ [ AMT-Device-GUID ] ^ -H \"Content-Type: application/json\" ^ -H \"Authorization: Bearer [JWT-Token]\" ^ -d \"{\\\"action\\\": [Power-Action], \\\"useSOL\\\": false}\" See Power Action API Docs for more information and expected responses. Other Methods \u00b6 For all available methods, see: MPS Methods to manage a device: MPS API Docs RPS Methods for server configuration and provisioning: RPS API Docs Explore the UI Toolkit \u00b6 In addition to REST API calls, the Open AMT Cloud Toolkit provides a reference implementation console. Add manageability features to the console with prebuilt React components, such as Keyboard, Video, and Mouse ( KVM ). Get Started with the UI Toolkit","title":"REST API Call"},{"location":"Tutorials/apiTutorial/#what-youll-need","text":"Hardware A minimum network configuration must include: A Development system with Windows\u00ae 10 or Ubuntu 18.04 or newer An Activated and Configured Intel\u00ae vPro device as the managed device Software on the Development System MPS curl Any Text Editor","title":"What You'll Need"},{"location":"Tutorials/apiTutorial/#what-youll-do","text":"The following sections describe how to: Generate a new JWT for Authorization Run an API Call to MPS for Devices See Other Example GET/POST Commands","title":"What You'll Do"},{"location":"Tutorials/apiTutorial/#generate-a-token-for-authorization","text":"See the Authorize Method in the API Documentation for more information. Open a Terminal or Command Prompt. Copy and paste the example code below into a text editor. Update the values of the [IP-Address or FQDN] , [MPS_WEB_ADMIN_USER] , and [MPS_WEB_ADMIN_PASSWORD] fields. Linux curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/login/api/v1/authorize \\ -H \"Content-Type:application/json\" \\ -d \"{\\\"username\\\":\\\"[MPS_WEB_ADMIN_USER]\\\", \\\"password\\\":\\\" [MPS_WEB_ADMIN_PASSWORD]\\\"}\" Windows curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/login/api/v1/authorize ^ -H \"Content-Type:application/json\" ^ -d \"{\\\"username\\\":\\\"[MPS_WEB_ADMIN_USER]\\\", \\\"password\\\":\\\" [MPS_WEB_ADMIN_PASSWORD]\\\"}\" Info - Using the --insecure Flag Because we are using self-signed certificates for MPS for development and testing purposes, we must supply this flag to bypass SSL certificate verification. Run the command. Example - Response of Authorize Method { \"token\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5RW1SSlRiSWlJYjRiSWVTc21nY1dJanJSNkh5RVRxYyIsImV4cCI6MTYyMDE2OTg2NH0.GUib9sq0RWRLqJ7JpNNlj2AluuROLICCfdZaQzyWy90\" } This token will be used when making any other API call as part of the Authorization header.","title":"Generate a Token for Authorization"},{"location":"Tutorials/apiTutorial/#run-api-call-for-get-devices","text":"See the GetDevices Method in the API Documentation for more information. Open a Terminal or Command Prompt. Copy and paste the example code below into a text editor. Update the values of the [IP-Address or FQDN] and [JWT-Token] fields. Linux curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/devices \\ -H \"Authorization: Bearer [JWT-Token]\" Windows curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/devices ^ -H \"Authorization: Bearer [JWT-Token]\" Run the command. Example - Response of Devices Method Example Terminal Output: [{ \"guid\" : \"3beae094-34f8-11ea-b6f5-ffed08129200\" , \"hostname\" : \"vpro3-NUC8v5PNK\" , \"tags\" :[], \"mpsInstance\" : \"mps\" , \"connectionStatus\" : true , \"mpsusername\" : \"admin\" }] Example JSON Pretty Print: [ { \"guid\" : \"3beae094-34f8-11ea-b6f5-ffed08129200\" , \"hostname\" : \"vpro3-NUC8v5PNK\" , \"tags\" : [], \"mpsInstance\" : \"mps\" , \"connectionStatus\" : true , \"mpsusername\" : \"admin\" } ] Important This is one way to retrieve a device's GUID in the host field. For amt path methods (i.e., Power Actions , Audit Logs, etc), the device GUID is required as part of the GET path. Save this value if you want to try other MPS methods. Other ways to retrieve a GUID can be found here .","title":"Run API Call for Get Devices"},{"location":"Tutorials/apiTutorial/#example-getpost-templates","text":"The sample GET and POST curl commands below can be adapted for other MPS and RPS methods by changing the URL path and modifying the request body data, if applicable . Power Capabilities (GET Template) Linux curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/amt/powercapabilities/ [ AMT-Device-GUID ] \\ -H \"Authorization: Bearer [JWT-Token]\" Windows curl --insecure https:// [ IP-Address or FQDN ] /mps/api/v1/amt/powercapabilities/ [ AMT-Device-GUID ] ^ -H \"Authorization: Bearer [JWT-Token]\" See Power Capabilities API Docs for more information and expected responses. Power Action (POST Template) Linux curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/api/v1/amt/power/action/ [ AMT-Device-GUID ] \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer [JWT-Token]\" \\ -d \"{\\\"action\\\": [Power-Action], \\\"useSOL\\\": false}\" Windows curl --insecure -X POST https:// [ IP-Address or FQDN ] /mps/api/v1/amt/power/action/ [ AMT-Device-GUID ] ^ -H \"Content-Type: application/json\" ^ -H \"Authorization: Bearer [JWT-Token]\" ^ -d \"{\\\"action\\\": [Power-Action], \\\"useSOL\\\": false}\" See Power Action API Docs for more information and expected responses.","title":"Example GET/POST Templates"},{"location":"Tutorials/apiTutorial/#other-methods","text":"For all available methods, see: MPS Methods to manage a device: MPS API Docs RPS Methods for server configuration and provisioning: RPS API Docs","title":"Other Methods"},{"location":"Tutorials/apiTutorial/#explore-the-ui-toolkit","text":"In addition to REST API calls, the Open AMT Cloud Toolkit provides a reference implementation console. Add manageability features to the console with prebuilt React components, such as Keyboard, Video, and Mouse ( KVM ). Get Started with the UI Toolkit","title":"Explore the UI Toolkit"},{"location":"Tutorials/createWiFiConfig/","text":"Important - Windows 10 Supported Only This feature is currently only supported for systems on Windows 10 operating systems. After activation and configuration of an AMT device with a wireless profile, remote devices can be managed wirelessly. For devices to be activated in Client Control Mode ( CCM ) : The managed, AMT device can be activated and configured on a wireless connection. For devices to be activated in Admin Control Mode ( ACM ) : The managed, AMT device MUST have a wired connection during the activation of AMT. After activation, devices are then able to be managed over the wireless network rather than a wired connection. Find if a Device Support Wireless \u00b6 RPC can pull information to help determine if your current device supports wireless functionality. See Build RPC for steps on how to obtain the binary. Run RPC with the --amtinfo all argument. Linux sudo ./rpc --amtinfo all \" Windows .\\rpc.exe --amtinfo all\" Look at the output for the LAN Interface section as highlighted below. If RPC does NOT return a section for wireless , then the AMT device does not support wireless functionality. Version : 15.0.10 Build Number : 1447 SKU : 16392 UUID : 4c4b4568-195a-4260-8097-a4c14f566733 Control Mode : pre-provisioning state DNS Suffix : vprodemo.com DNS Suffix (OS) : FQDN : Hostname (OS) : DESKTOP-3YM6MPN RAS Network : outside enterprise RAS Remote Status : not connected RAS Trigger : user initiated RAS MPS Hostname : LAN Inteface : wired DHCP Enabled : true DHCP Mode : passive Link Status : up IP Address : 0.0.0.0 MAC Address : 80:c4:a8:58:df:e9 LAN Inteface : wireless DHCP Enabled : true DHCP Mode : passive Link Status : down IP Address : 0.0.0.0 MAC Address : 00:00:00:00:00:00 Certificate Hashes : ... Create a WiFi Config \u00b6 Select the Wireless tab from the left-hand menu. In the top-right corner, click Add New. Figure 1: Create a new WiFi Config. Specify a Wireless Profile Name of your choice. Under Authentication Method , select WPA PSK or WPA2 PSK . Under Encryption Method , select TKIP or CCMP . Specify a SSID . This is the name of your wireless network. Provide a strong PSK Passphrase . This is the password to the WiFi Network. Click Save. Example Wireless Profile Figure 2: Example Wireless Profile . Important : After saving, continue on to create either a CCM or ACM profile. When prompted, search for and select your new Wireless Profile from the drop-down menu. The selected Wi-Fi Profiles will be shown under Associated Wireless Profiles and can be re-ordered by dragging them to give priority. Example - Select Wireless Profile Figure 3: Selection of Wireless Profile in CCM / ACM Profile Next up \u00b6 Profiles provide configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Profiles also distinguish between activating in: Client Control Mode ( CCM ): This mode offers all manageability features including, but not limited to, power control, audit logs, and hardware info. Redirection features, such as KVM or SOL , require user consent . The managed device will display a 6-digit code that must be entered by the remote admin to access the remote device via redirection. Create a CCM Profile Admin Control Mode ( ACM ): ACM mode supports all manageability features without requiring user consent . This means it is not necessary to have a person on-site to remote in and manage an edge device. In most IoT use cases, edge devices such as digital signage or kiosks may not be easily accessible or have available employees nearby. ACM mode proves immensely helpful in these scenarios. Create an ACM Profile","title":"Wireless Activation"},{"location":"Tutorials/createWiFiConfig/#find-if-a-device-support-wireless","text":"RPC can pull information to help determine if your current device supports wireless functionality. See Build RPC for steps on how to obtain the binary. Run RPC with the --amtinfo all argument. Linux sudo ./rpc --amtinfo all \" Windows .\\rpc.exe --amtinfo all\" Look at the output for the LAN Interface section as highlighted below. If RPC does NOT return a section for wireless , then the AMT device does not support wireless functionality. Version : 15.0.10 Build Number : 1447 SKU : 16392 UUID : 4c4b4568-195a-4260-8097-a4c14f566733 Control Mode : pre-provisioning state DNS Suffix : vprodemo.com DNS Suffix (OS) : FQDN : Hostname (OS) : DESKTOP-3YM6MPN RAS Network : outside enterprise RAS Remote Status : not connected RAS Trigger : user initiated RAS MPS Hostname : LAN Inteface : wired DHCP Enabled : true DHCP Mode : passive Link Status : up IP Address : 0.0.0.0 MAC Address : 80:c4:a8:58:df:e9 LAN Inteface : wireless DHCP Enabled : true DHCP Mode : passive Link Status : down IP Address : 0.0.0.0 MAC Address : 00:00:00:00:00:00 Certificate Hashes : ...","title":"Find if a Device Support Wireless"},{"location":"Tutorials/createWiFiConfig/#create-a-wifi-config","text":"Select the Wireless tab from the left-hand menu. In the top-right corner, click Add New. Figure 1: Create a new WiFi Config. Specify a Wireless Profile Name of your choice. Under Authentication Method , select WPA PSK or WPA2 PSK . Under Encryption Method , select TKIP or CCMP . Specify a SSID . This is the name of your wireless network. Provide a strong PSK Passphrase . This is the password to the WiFi Network. Click Save. Example Wireless Profile Figure 2: Example Wireless Profile . Important : After saving, continue on to create either a CCM or ACM profile. When prompted, search for and select your new Wireless Profile from the drop-down menu. The selected Wi-Fi Profiles will be shown under Associated Wireless Profiles and can be re-ordered by dragging them to give priority. Example - Select Wireless Profile Figure 3: Selection of Wireless Profile in CCM / ACM Profile","title":"Create a WiFi Config"},{"location":"Tutorials/createWiFiConfig/#next-up","text":"Profiles provide configuration information to the AMT Firmware during the activation process with the Remote Provisioning Client ( RPC ). Profiles also distinguish between activating in: Client Control Mode ( CCM ): This mode offers all manageability features including, but not limited to, power control, audit logs, and hardware info. Redirection features, such as KVM or SOL , require user consent . The managed device will display a 6-digit code that must be entered by the remote admin to access the remote device via redirection. Create a CCM Profile Admin Control Mode ( ACM ): ACM mode supports all manageability features without requiring user consent . This means it is not necessary to have a person on-site to remote in and manage an edge device. In most IoT use cases, edge devices such as digital signage or kiosks may not be easily accessible or have available employees nearby. ACM mode proves immensely helpful in these scenarios. Create an ACM Profile","title":"Next up"},{"location":"Tutorials/uitoolkitReact/","text":"Add MPS UI Toolkit Controls to a WebUI \u00b6 The UI Toolkit allows developers to add manageability features to a console with prebuilt React components. The code snippets simplify the task of adding complex manageability UI controls, such as the Keyboard, Video, Mouse ( KVM ). A sample web application, based on React.js, is provided for test and development. The tutorial outlines how to add various controls to the sample React web application provided. Developers can use the sample code below as a springboard for developing their own consoles. What You'll Need \u00b6 Hardware \u00b6 Configure a network that includes: A development system running Windows\u00ae 10 or Ubuntu* 18.04 or newer At least one Intel vPro\u00ae Platform to manage Software \u00b6 MPS , the Management Presence Server RPS , the Remote Provisioning Server Intel\u00ae vPro device, configured and connected to MPS Note For instructions to setup the MPS and RPS servers to connect a managed device, see the Get Started Guide The development system requires the following software: git Visual Studio Code or any other IDE Node.js* LTS 12.x.x or newer What You'll Do \u00b6 Follow the steps in these sections sequentially: Create a new React app Add UI controls to the React app Create a New React App \u00b6 The React app can be created in any preferred development directory. The MPS can continue to run while creating and running the app. In a Terminal or Command Prompt, go to your preferred development directory. Run the following commands to create sample React app named my-app . npx create-react-app my-app 3. Change to the my-app directory: cd my-app Add UI Toolkit \u00b6 Run the following command to add the UI Toolkit and install the required dependencies: npm install @open-amt-cloud-toolkit/ui-toolkit-react@2.0.0 Run the following commands to start the web UI locally: npm start By default, React apps run on port 3000 . If port 3000 is already used by the MPS server or any other application, you'll be prompted to use another port. If this happens, enter 'Y'. Success Figure 2: React reports successful deployment. Note - Using Chromium Browser and Refreshing By default, React launches in your machine's default browser. However for best experience, navigate to the page using a Chromium based web browser. When you make changes, you do not need to stop the application and restart. It will update and refresh automatically as you make code changes. Add a Sample Control \u00b6 The following sections outline how to add controls. To use the code snippets provided, replace what is in the App.js file with the provided code snippet. Refresh the web browser after adding a control if it does not update automatically after a few seconds. Add Keyboard, Video, Mouse ( KVM ) Redirection \u00b6 The code snippet below adds KVM control to the React application. Open ./my-app/src/App.js in a text editor or IDE of choice, such as Visual Studio Code or Notepad. Delete the current code and replace with the code snippet below. Change the following values: Field Value deviceId Replace the example deviceId value with the GUID of the Intel\u00ae AMT device. See How to Find GUIDs in Intel\u00ae AMT . mpsServer Replace the localhost with the IP Address or FQDN of your Development Device or MPS Server. When using KONG, /mps/ws/relay must be appeneded to the IP or FQDN. authToken Provide valid JWT. See instructions on Generating a JWT by using an Authorize API call . import React from \"react\" ; import \"./App.css\" ; import { KVM } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/KVM\" ; function App () { return ( < div className = \"App\" > < KVM deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws/relay\" //Replace 'localhost' with Development System or MPS Server IP Address mouseDebounceTime = \"200\" authToken = \"\" // Replace with a valid JWT token from 'Authorize' API Method canvasHeight = \"100%\" canvasWidth = \"100%\" >< /KVM> < /div> ); } export default App ; Save and close the file. If the React app hasn't updated automatically, refresh the page. You are now able to remotely control your Intel\u00ae AMT device using Keyboard, Video, Mouse control. You will see the errors in the following scenarios: Compilation errors if the ui-toolkit was not downloaded and installed to your react app. MPS / RPS server not running, appropriate controls will fail to work. MPS server running and device not connected. If your browser is IE/Edge, there might be compatibility issues. Incorrect or invalid JWT for authToken, see instructions on Generating a JWT by using an Authorize API call . Example authToken Format { \"token\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5RW1SSlRiSWlJYjRiSWVTc21nY1dJanJSNkh5RVRxYyIsImV4cCI6MTYyMDE2OTg2NH0.GUib9sq0RWRLqJ7JpNNlj2AluuROLICCfdZaQzyWy90\" } Next Steps \u00b6 Try Other Controls \u00b6 Try out other React controls such as Serial Over LAN . Customize and Create Bundles \u00b6 Try out creating and customizing React bundles for things such as Serial Over LAN or KVM here . License Note \u00b6 If you are distributing the FortAwesome Icons, please provide attribution to the source per the CC-by 4.0 license obligations.","title":"UI Toolkit KVM Module"},{"location":"Tutorials/uitoolkitReact/#add-mps-ui-toolkit-controls-to-a-webui","text":"The UI Toolkit allows developers to add manageability features to a console with prebuilt React components. The code snippets simplify the task of adding complex manageability UI controls, such as the Keyboard, Video, Mouse ( KVM ). A sample web application, based on React.js, is provided for test and development. The tutorial outlines how to add various controls to the sample React web application provided. Developers can use the sample code below as a springboard for developing their own consoles.","title":"Add MPS UI Toolkit Controls to a WebUI"},{"location":"Tutorials/uitoolkitReact/#what-youll-need","text":"","title":"What You'll Need"},{"location":"Tutorials/uitoolkitReact/#hardware","text":"Configure a network that includes: A development system running Windows\u00ae 10 or Ubuntu* 18.04 or newer At least one Intel vPro\u00ae Platform to manage","title":"Hardware"},{"location":"Tutorials/uitoolkitReact/#software","text":"MPS , the Management Presence Server RPS , the Remote Provisioning Server Intel\u00ae vPro device, configured and connected to MPS Note For instructions to setup the MPS and RPS servers to connect a managed device, see the Get Started Guide The development system requires the following software: git Visual Studio Code or any other IDE Node.js* LTS 12.x.x or newer","title":"Software"},{"location":"Tutorials/uitoolkitReact/#what-youll-do","text":"Follow the steps in these sections sequentially: Create a new React app Add UI controls to the React app","title":"What You'll Do"},{"location":"Tutorials/uitoolkitReact/#create-a-new-react-app","text":"The React app can be created in any preferred development directory. The MPS can continue to run while creating and running the app. In a Terminal or Command Prompt, go to your preferred development directory. Run the following commands to create sample React app named my-app . npx create-react-app my-app 3. Change to the my-app directory: cd my-app","title":"Create a New React App"},{"location":"Tutorials/uitoolkitReact/#add-ui-toolkit","text":"Run the following command to add the UI Toolkit and install the required dependencies: npm install @open-amt-cloud-toolkit/ui-toolkit-react@2.0.0 Run the following commands to start the web UI locally: npm start By default, React apps run on port 3000 . If port 3000 is already used by the MPS server or any other application, you'll be prompted to use another port. If this happens, enter 'Y'. Success Figure 2: React reports successful deployment. Note - Using Chromium Browser and Refreshing By default, React launches in your machine's default browser. However for best experience, navigate to the page using a Chromium based web browser. When you make changes, you do not need to stop the application and restart. It will update and refresh automatically as you make code changes.","title":"Add UI Toolkit"},{"location":"Tutorials/uitoolkitReact/#add-a-sample-control","text":"The following sections outline how to add controls. To use the code snippets provided, replace what is in the App.js file with the provided code snippet. Refresh the web browser after adding a control if it does not update automatically after a few seconds.","title":"Add a Sample Control"},{"location":"Tutorials/uitoolkitReact/#add-keyboard-video-mouse-kvm-redirection","text":"The code snippet below adds KVM control to the React application. Open ./my-app/src/App.js in a text editor or IDE of choice, such as Visual Studio Code or Notepad. Delete the current code and replace with the code snippet below. Change the following values: Field Value deviceId Replace the example deviceId value with the GUID of the Intel\u00ae AMT device. See How to Find GUIDs in Intel\u00ae AMT . mpsServer Replace the localhost with the IP Address or FQDN of your Development Device or MPS Server. When using KONG, /mps/ws/relay must be appeneded to the IP or FQDN. authToken Provide valid JWT. See instructions on Generating a JWT by using an Authorize API call . import React from \"react\" ; import \"./App.css\" ; import { KVM } from \"@open-amt-cloud-toolkit/ui-toolkit/reactjs/KVM\" ; function App () { return ( < div className = \"App\" > < KVM deviceId = \"038d0240-045c-05f4-7706-980700080009\" //Replace with AMT Device GUID mpsServer = \"https://localhost/mps/ws/relay\" //Replace 'localhost' with Development System or MPS Server IP Address mouseDebounceTime = \"200\" authToken = \"\" // Replace with a valid JWT token from 'Authorize' API Method canvasHeight = \"100%\" canvasWidth = \"100%\" >< /KVM> < /div> ); } export default App ; Save and close the file. If the React app hasn't updated automatically, refresh the page. You are now able to remotely control your Intel\u00ae AMT device using Keyboard, Video, Mouse control. You will see the errors in the following scenarios: Compilation errors if the ui-toolkit was not downloaded and installed to your react app. MPS / RPS server not running, appropriate controls will fail to work. MPS server running and device not connected. If your browser is IE/Edge, there might be compatibility issues. Incorrect or invalid JWT for authToken, see instructions on Generating a JWT by using an Authorize API call . Example authToken Format { \"token\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiI5RW1SSlRiSWlJYjRiSWVTc21nY1dJanJSNkh5RVRxYyIsImV4cCI6MTYyMDE2OTg2NH0.GUib9sq0RWRLqJ7JpNNlj2AluuROLICCfdZaQzyWy90\" }","title":"Add Keyboard, Video, Mouse (KVM) Redirection"},{"location":"Tutorials/uitoolkitReact/#next-steps","text":"","title":"Next Steps"},{"location":"Tutorials/uitoolkitReact/#try-other-controls","text":"Try out other React controls such as Serial Over LAN .","title":"Try Other Controls"},{"location":"Tutorials/uitoolkitReact/#customize-and-create-bundles","text":"Try out creating and customizing React bundles for things such as Serial Over LAN or KVM here .","title":"Customize and Create Bundles"},{"location":"Tutorials/uitoolkitReact/#license-note","text":"If you are distributing the FortAwesome Icons, please provide attribution to the source per the CC-by 4.0 license obligations.","title":"License Note"},{"location":"Tutorials/Scaling/docker-swarm/","text":"Introduction \u00b6 This sample deployment demonstrates the use of Docker* in swarm mode. The following conditions apply: All images are built and tested with docker-compose. To learn more about building the images with docker-compose, refer to Express Setup . Push images to the registry to make them available for deployment on other systems. Run the commands below from the open-amt-cloud-toolkit install directory. Important Not for production use. Deploy the stack to the swarm \u00b6 Important - For Linux Before running the following commands on Linux, confirm that the user has been added to the docker group. For instructions, refer to Add docker group . Otherwise, prefix each command with sudo . Initialize a swarm. docker swarm init Copy docker compose config to temporary swarm.yml file. docker-compose -f .\\docker-compose.yml config > swarm.yml Set the network driver to overlay in the swarm.yml file. Linux sed -i \"s|driver: bridge|driver: overlay|g\" swarm.yml Windows ( Get-Content -Path './swarm.yml' ) -replace 'driver: bridge' , 'driver: overlay' | Set-Content -Path './swarm.yml' Important Open the swarm.yml file to check that driver: bridge was replaced with driver: overlay . If the result is incorrect or corrupted, delete the swarm.yml file, rerun Step 2, and manually replace the string. If you've run docker-compose previously, as in the instructions in Express Setup , run docker-compose down to stop the open-amt-cloud-toolkit services: docker-compose down -v Create the stack. docker stack deploy -c swarm.yml scalingdemo Check all of the services are running. docker stack services scalingdemo Success The table below is an example of a services list: ID NAME MODE REPLICAS IMAGE PORTS 6dye78yg66zp scalingdemo_db replicated 1/1 postgres:latest *:5432->5432/tcp nahbub6fxrvu scalingdemo_kong replicated 1/1 kong:2.3 :443->8443/tcp, :8001->8001/tcp nltp54asb8kz scalingdemo_mps replicated 1/1 mps:latest *:4433->4433/tcp uc9jsf5554cv scalingdemo_mpsrouter replicated 1/1 mpsrouter:latest ojtcs8qjxct3 scalingdemo_rps replicated 1/1 rps:latest wbk4of70do63 scalingdemo_vault replicated 1/1 vault:latest *:8200->8200/tcp pc143h8ml4ua scalingdemo_webui replicated 1/1 webui:latest Scale the mps service. docker service scale scalingdemo_mps=2 Success The table below is an example of a services list after scaling the mps: ID NAME MODE REPLICAS IMAGE PORTS 6dye78yg66zp scalingdemo_db replicated 1/1 postgres:latest *:5432->5432/tcp nahbub6fxrvu scalingdemo_kong replicated 1/1 kong:2.3 :443->8443/tcp, :8001->8001/tcp nltp54asb8kz scalingdemo_mps replicated 2/2 mps:latest *:4433->4433/tcp uc9jsf5554cv scalingdemo_mpsrouter replicated 1/1 mpsrouter:latest ojtcs8qjxct3 scalingdemo_rps replicated 1/1 rps:latest wbk4of70do63 scalingdemo_vault replicated 1/1 vault:latest *:8200->8200/tcp pc143h8ml4ua scalingdemo_webui replicated 1/1 webui:latest Remove the stack: docker stack rm scalingdemo","title":"Docker Swarm*"},{"location":"Tutorials/Scaling/docker-swarm/#introduction","text":"This sample deployment demonstrates the use of Docker* in swarm mode. The following conditions apply: All images are built and tested with docker-compose. To learn more about building the images with docker-compose, refer to Express Setup . Push images to the registry to make them available for deployment on other systems. Run the commands below from the open-amt-cloud-toolkit install directory. Important Not for production use.","title":"Introduction"},{"location":"Tutorials/Scaling/docker-swarm/#deploy-the-stack-to-the-swarm","text":"Important - For Linux Before running the following commands on Linux, confirm that the user has been added to the docker group. For instructions, refer to Add docker group . Otherwise, prefix each command with sudo . Initialize a swarm. docker swarm init Copy docker compose config to temporary swarm.yml file. docker-compose -f .\\docker-compose.yml config > swarm.yml Set the network driver to overlay in the swarm.yml file. Linux sed -i \"s|driver: bridge|driver: overlay|g\" swarm.yml Windows ( Get-Content -Path './swarm.yml' ) -replace 'driver: bridge' , 'driver: overlay' | Set-Content -Path './swarm.yml' Important Open the swarm.yml file to check that driver: bridge was replaced with driver: overlay . If the result is incorrect or corrupted, delete the swarm.yml file, rerun Step 2, and manually replace the string. If you've run docker-compose previously, as in the instructions in Express Setup , run docker-compose down to stop the open-amt-cloud-toolkit services: docker-compose down -v Create the stack. docker stack deploy -c swarm.yml scalingdemo Check all of the services are running. docker stack services scalingdemo Success The table below is an example of a services list: ID NAME MODE REPLICAS IMAGE PORTS 6dye78yg66zp scalingdemo_db replicated 1/1 postgres:latest *:5432->5432/tcp nahbub6fxrvu scalingdemo_kong replicated 1/1 kong:2.3 :443->8443/tcp, :8001->8001/tcp nltp54asb8kz scalingdemo_mps replicated 1/1 mps:latest *:4433->4433/tcp uc9jsf5554cv scalingdemo_mpsrouter replicated 1/1 mpsrouter:latest ojtcs8qjxct3 scalingdemo_rps replicated 1/1 rps:latest wbk4of70do63 scalingdemo_vault replicated 1/1 vault:latest *:8200->8200/tcp pc143h8ml4ua scalingdemo_webui replicated 1/1 webui:latest Scale the mps service. docker service scale scalingdemo_mps=2 Success The table below is an example of a services list after scaling the mps: ID NAME MODE REPLICAS IMAGE PORTS 6dye78yg66zp scalingdemo_db replicated 1/1 postgres:latest *:5432->5432/tcp nahbub6fxrvu scalingdemo_kong replicated 1/1 kong:2.3 :443->8443/tcp, :8001->8001/tcp nltp54asb8kz scalingdemo_mps replicated 2/2 mps:latest *:4433->4433/tcp uc9jsf5554cv scalingdemo_mpsrouter replicated 1/1 mpsrouter:latest ojtcs8qjxct3 scalingdemo_rps replicated 1/1 rps:latest wbk4of70do63 scalingdemo_vault replicated 1/1 vault:latest *:8200->8200/tcp pc143h8ml4ua scalingdemo_webui replicated 1/1 webui:latest Remove the stack: docker stack rm scalingdemo","title":"Deploy the stack to the swarm"},{"location":"Tutorials/Scaling/overview/","text":"Scaling Overview \u00b6 Scaling functionality in MPS enables Open AMT Cloud Toolkit to support a greater number of managed devices. The toolkit offers various methods for deploying scaling, including Local Kubernetes, Azure Kubernetes Service ( AKS ), Amazon Elasic Kubernetes Service (EKS), and Docker Swarm*. In addition, administrators can use kubectl to manage the AKS . Figure 1: High-level Architecture of Scaling Implementation Figure 1 illustrates the basic high-level software flow: Managed devices use CIRA to connect and call home to instances of the MPS in the cloud. RPCs connect to an available instance of the MPS Server with WSS calls. These calls are funneled through Kong* API Gateway, which supports a variety of APIs. Kong manages load balancing, logging, authentication and more. The Kong* API Gateway handles requests from client apps, such as the Sample Web UI included in Open AMT Cloud Toolkit , sending them along to an available RPS . The MPS Router chooses an available instance of the MPS . The RPS microservices communicate with MPS microservices through the REST API. Vault is a tool used to secure, store, and tightly control access to secrets. Storing passwords used by MPS in Vault will increase the security of these assets. Docker in Swarm Mode \u00b6 If you're new to scaling, Docker in swarm mode is a great way to start developing a scaling proof of concept. Docker in swarm mode is a container orchestration tool, software used to deploy and manage large numbers of containers and services. In this mode, Docker enables the administrator to deploy and manage Docker nodes or worker nodes that are added to a Docker swarm instance. Administrator can then deploy a service to the swarm instance and expose ports to an external load balancer. Information To learn more about Docker in swarm mode, start with Swarm mode overview . Get Started with Docker Swarm Kubernetes (K8s) \u00b6 Warning The K8s deployment section is not a tutorial for beginners. It is intended for those who have prior knowledge of the service. To begin learning about K8s, start with Kubernetes , Azure Kubernetes Service , or Amazon Elastic Kubernetes Service . Local Kubernetes \u00b6 K8s is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. The instructions use kubectl, a command line tool for managing Kubernetes clusters. Get Started with K8s Azure Kubernetes Service ( AKS ) \u00b6 AKS is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. Get Started with AKS Amazon Elastic Kubernetes Service (EKS) \u00b6 EKS is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. Get Started with EKS","title":"Overview"},{"location":"Tutorials/Scaling/overview/#scaling-overview","text":"Scaling functionality in MPS enables Open AMT Cloud Toolkit to support a greater number of managed devices. The toolkit offers various methods for deploying scaling, including Local Kubernetes, Azure Kubernetes Service ( AKS ), Amazon Elasic Kubernetes Service (EKS), and Docker Swarm*. In addition, administrators can use kubectl to manage the AKS . Figure 1: High-level Architecture of Scaling Implementation Figure 1 illustrates the basic high-level software flow: Managed devices use CIRA to connect and call home to instances of the MPS in the cloud. RPCs connect to an available instance of the MPS Server with WSS calls. These calls are funneled through Kong* API Gateway, which supports a variety of APIs. Kong manages load balancing, logging, authentication and more. The Kong* API Gateway handles requests from client apps, such as the Sample Web UI included in Open AMT Cloud Toolkit , sending them along to an available RPS . The MPS Router chooses an available instance of the MPS . The RPS microservices communicate with MPS microservices through the REST API. Vault is a tool used to secure, store, and tightly control access to secrets. Storing passwords used by MPS in Vault will increase the security of these assets.","title":"Scaling Overview"},{"location":"Tutorials/Scaling/overview/#docker-in-swarm-mode","text":"If you're new to scaling, Docker in swarm mode is a great way to start developing a scaling proof of concept. Docker in swarm mode is a container orchestration tool, software used to deploy and manage large numbers of containers and services. In this mode, Docker enables the administrator to deploy and manage Docker nodes or worker nodes that are added to a Docker swarm instance. Administrator can then deploy a service to the swarm instance and expose ports to an external load balancer. Information To learn more about Docker in swarm mode, start with Swarm mode overview . Get Started with Docker Swarm","title":"Docker in Swarm Mode"},{"location":"Tutorials/Scaling/overview/#kubernetes-k8s","text":"Warning The K8s deployment section is not a tutorial for beginners. It is intended for those who have prior knowledge of the service. To begin learning about K8s, start with Kubernetes , Azure Kubernetes Service , or Amazon Elastic Kubernetes Service .","title":"Kubernetes (K8s)"},{"location":"Tutorials/Scaling/overview/#local-kubernetes","text":"K8s is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. The instructions use kubectl, a command line tool for managing Kubernetes clusters. Get Started with K8s","title":"Local Kubernetes"},{"location":"Tutorials/Scaling/overview/#azure-kubernetes-service-aks","text":"AKS is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. Get Started with AKS","title":"Azure Kubernetes Service (AKS)"},{"location":"Tutorials/Scaling/overview/#amazon-elastic-kubernetes-service-eks","text":"EKS is a container orchestration system that enables administrators to deploy and manage large numbers of containers and services. Get Started with EKS","title":"Amazon Elastic Kubernetes Service (EKS)"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/","text":"Azure Kubernetes Service ( AKS ) \u00b6 This tutorial demonstrates how to deploy the Open AMT Cloud Toolkit on a Kubernetes cluster using AKS . Alternatively, you can also perform a simpler, test deployment using a single-node cluster locally. See Kubernetes (K8s) . Azure Kubernetes Service ( AKS ) offers serverless Kubernetes, an integrated continuous integration and continuous delivery (CI/CD) experience, and enterprise-grade security and governance. Learn more about AKS here . Prerequisites \u00b6 kubectl Azure CLI (v2.24.0+) Helm CLI (v3.5+) PSQL CLI (11.13) Get the Toolkit \u00b6 Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Create SSH Key \u00b6 This key is required by Azure to create VMs that use SSH keys for authentication. For more details, see Detailed steps: Create and manage SSH keys . Create a new ssh key. ssh-keygen -t rsa -b 2048 Take note of the location it was saved at. You will need the public key ( .pub file) in a following step. Deploy AKS \u00b6 Login to Azure. az login Provide a name and region to create a new resource group. az group create --name <your-resource-group-name> --location <region> Provide the name of your new resource group from the last step and start a deployment at that resource group based on aks.json in the ./open-amt-cloud-toolkit directory. az deployment group create --resource-group <your-resource-group-name> --template-file aks.json After running the previous command, you will be prompted for 3 different strings. After the final prompt, it will take about 5 minutes to finish running. Provide a name for the AKS Cluster. Provide a name (e.g. your name) for the linux user admin name. Provide the string of the ssh key from the .pub file. Take note of the fqdnSuffix in the outputs section of the JSON response (e.g. eastus.cloudapp.azure.com ) \"outputs\" : { \"controlPlaneFQDN\" : { \"type\" : \"String\" , \"value\" : \"bwcluster-9c68035a.hcp.westus.azmk8s.io\" }, \"fqdnSuffix\" : { \"type\" : \"String\" , \"value\" : \"eastus.cloudapp.azure.com\" } }, Connect to AKS Instance \u00b6 Ensure your kubectl is connected to the Kubernetes cluster you wish to deploy/manage. Provide your resource group name and cluster name, respectively. az aks get-credentials --resource-group <your-resource-group-name> --name <your-cluster-name> Create Secrets \u00b6 1. Private Docker Registry Credentials \u00b6 If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server = <your-registry-server> --docker-username = <your-username> --docker-password = <your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password. 2. MPS /KONG JWT \u00b6 This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret. 3. KONG ACL for JWT \u00b6 This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin 4. MPS Web Username and Password \u00b6 This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character 5. Azure Storage Account Key \u00b6 Currently, we leverage Azure Storage Accounts for persistent storage of MPS certificates that can be shared by multiple instances of MPS . This creates the secret to access the provisioned Azure Storage account for use in a persistent volume (PV). Note This will likely change in a future release kubectl create secret generic azure-secret --from-literal=azurestorageaccountname=<your-cluster-name>stg --from-literal=azurestorageaccountkey=<your-storage-key> Where: <your-cluster-name> is the cluster name chosen in Deploy AKS . <your-storage-key> is one of the generated access keys of the storage account. Important - Finding Access Keys An access key can be found by either: Run az storage account keys list --account-name <your-cluster-name>stg to view access keys. Navigate to Home > Storage accounts > cluster-name > Access keys using Microsoft Azure via online. 6. Database connection strings \u00b6 Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the full username for the Postgres database (Ex: <postgres-username>@<your-cluster-name>-sql ). <PASSWORD> is the password for the Postgres database. <SERVERURL> is the url for the Azure-hosted Postgres database (Ex: <your-cluster-name>-sql.postgres.database.azure.com ). Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable Update Configuration \u00b6 Edit values.yaml \u00b6 Open the values.yaml file in ./open-amt-cloud-toolkit/kubernetes/charts/ . Update the service.beta.kubernetes.io/azure-dns-label-name key in the kong section with the desired subdomain name for your URL you would like for your cluster (i.e. myopenamtk8s). kong : proxy : annotations : service.beta.kubernetes.io/azure-dns-label-name : \"<your-subdomain-name>\" Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Update the following keys in the mps section. Key Name Update to Description commonName FQDN for your cluster For AKS , the format is <your-subdomain-name>.<location>.cloudapp.azure.com . This is the fqdnSuffix provided in the outputs section when you Deploy AKS . storageAccessMode ReadWriteMany Must set to ReadWriteMany to scale. The default access mode for storage ( storageAccessMode ) is set to ReadWriteOnce . This only works with a one node cluster. mps : commonName : \"<your-subdomain-name>.<location>.cloudapp.azure.com\" # storageClassName: \"\" storageAccessMode : \"ReadWriteOnce\" #Change to ReadWriteMany replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file. Apply Volumes \u00b6 Provide a PersistentVolume that can match the PersisentVolumeClaim for MPS . For an AKS deployment, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/azure.yaml . Note Changing storageAccessMode will update the PersistentVolumeClaim to request ReadWriteMany , this means you'll need to provide a PersistentVolume that can match that claim. The Azure deployment performed in Deploy AKS creates a Storage Account that can be used. Use the following yaml to provision the volume for the cluster. Provided azure.yaml Example apiVersion : v1 kind : PersistentVolume metadata : name : mps-certs spec : capacity : storage : 1Gi accessModes : - ReadWriteMany azureFile : secretName : azure-secret secretNamespace : default shareName : mps-certs readOnly : false mountOptions : - dir_mode=0755 - file_mode=0755 - uid=1000 - gid=1000 - mfsymlinks - nobrl Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/azure.yaml Create Databases and Schema \u00b6 Enable Access to Database \u00b6 Navigate to Home > Resource Groups > Resource Group Name using Microsoft Azure via online. Select the Postgres DB. It will have a Type of Azure Database for PostgreSQL Server . Under Settings in the left-hand menu, select Connection Security . Under Firewall rules, select Add current client IP address . Select Save. Under the Overview tab, take note of the 'Server name' and 'Admin username'. They will be needed in the next steps. Note Remember to delete this firewall rule when finished. Create Databases \u00b6 Use the database schema files to initialize the hosted Postgres DB in the following steps. Where: <HOST> is the location of the Postgres database (Ex: <your-cluster-name>-sql.postgres.database.azure.com ). <USERNAME> is the admin username for the Postgres database (Ex: <postgres-username>@<your-cluster-name>-sql ). Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb' database. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql Deploy Open AMT Cloud Toolkit using Helm \u00b6 Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Thu Jul 15 11:17:38 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None View the pods. You might notice mps , rps , and openamtstack-vault-0 are not ready. This will change after we initialize and unseal Vault. All others should be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 0/1 Pending 0 2m6s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 2m6s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 2m6s openamtstack-vault-0 0/1 Running 0 2m6s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 2m6s rps-79877bf5c5-dsg5p 0/1 CreateContainerConfigError 0 2m6s webui-6cc48f4d68-6r8b5 1/1 Running 0 2m6s Initialize and Unseal Vault \u00b6 Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine . Vault Token Secret \u00b6 Add the root token as a secret to the AKS cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault. View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 1/1 Running 0 4m5s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 4m5s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 4m5s openamtstack-vault-0 1/1 Running 0 4m5s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 4m5s rps-79877bf5c5-dsg5p 1/1 Running 0 4m5s webui-6cc48f4d68-6r8b5 1/1 Running 0 4m5s Next Steps \u00b6 Visit the Sample Web UI using the FQDN name and Continue from the Get Started steps","title":"AKS"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#azure-kubernetes-service-aks","text":"This tutorial demonstrates how to deploy the Open AMT Cloud Toolkit on a Kubernetes cluster using AKS . Alternatively, you can also perform a simpler, test deployment using a single-node cluster locally. See Kubernetes (K8s) . Azure Kubernetes Service ( AKS ) offers serverless Kubernetes, an integrated continuous integration and continuous delivery (CI/CD) experience, and enterprise-grade security and governance. Learn more about AKS here .","title":"Azure Kubernetes Service (AKS)"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#prerequisites","text":"kubectl Azure CLI (v2.24.0+) Helm CLI (v3.5+) PSQL CLI (11.13)","title":"Prerequisites"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#get-the-toolkit","text":"Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1","title":"Get the Toolkit"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#create-ssh-key","text":"This key is required by Azure to create VMs that use SSH keys for authentication. For more details, see Detailed steps: Create and manage SSH keys . Create a new ssh key. ssh-keygen -t rsa -b 2048 Take note of the location it was saved at. You will need the public key ( .pub file) in a following step.","title":"Create SSH Key"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#deploy-aks","text":"Login to Azure. az login Provide a name and region to create a new resource group. az group create --name <your-resource-group-name> --location <region> Provide the name of your new resource group from the last step and start a deployment at that resource group based on aks.json in the ./open-amt-cloud-toolkit directory. az deployment group create --resource-group <your-resource-group-name> --template-file aks.json After running the previous command, you will be prompted for 3 different strings. After the final prompt, it will take about 5 minutes to finish running. Provide a name for the AKS Cluster. Provide a name (e.g. your name) for the linux user admin name. Provide the string of the ssh key from the .pub file. Take note of the fqdnSuffix in the outputs section of the JSON response (e.g. eastus.cloudapp.azure.com ) \"outputs\" : { \"controlPlaneFQDN\" : { \"type\" : \"String\" , \"value\" : \"bwcluster-9c68035a.hcp.westus.azmk8s.io\" }, \"fqdnSuffix\" : { \"type\" : \"String\" , \"value\" : \"eastus.cloudapp.azure.com\" } },","title":"Deploy AKS"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#connect-to-aks-instance","text":"Ensure your kubectl is connected to the Kubernetes cluster you wish to deploy/manage. Provide your resource group name and cluster name, respectively. az aks get-credentials --resource-group <your-resource-group-name> --name <your-cluster-name>","title":"Connect to AKS Instance"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#create-secrets","text":"","title":"Create Secrets"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#1-private-docker-registry-credentials","text":"If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server = <your-registry-server> --docker-username = <your-username> --docker-password = <your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password.","title":"1. Private Docker Registry Credentials"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#2-mpskong-jwt","text":"This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret.","title":"2. MPS/KONG JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#3-kong-acl-for-jwt","text":"This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin","title":"3. KONG ACL for JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#4-mps-web-username-and-password","text":"This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character","title":"4. MPS Web Username and Password"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#5-azure-storage-account-key","text":"Currently, we leverage Azure Storage Accounts for persistent storage of MPS certificates that can be shared by multiple instances of MPS . This creates the secret to access the provisioned Azure Storage account for use in a persistent volume (PV). Note This will likely change in a future release kubectl create secret generic azure-secret --from-literal=azurestorageaccountname=<your-cluster-name>stg --from-literal=azurestorageaccountkey=<your-storage-key> Where: <your-cluster-name> is the cluster name chosen in Deploy AKS . <your-storage-key> is one of the generated access keys of the storage account. Important - Finding Access Keys An access key can be found by either: Run az storage account keys list --account-name <your-cluster-name>stg to view access keys. Navigate to Home > Storage accounts > cluster-name > Access keys using Microsoft Azure via online.","title":"5. Azure Storage Account Key"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#6-database-connection-strings","text":"Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the full username for the Postgres database (Ex: <postgres-username>@<your-cluster-name>-sql ). <PASSWORD> is the password for the Postgres database. <SERVERURL> is the url for the Azure-hosted Postgres database (Ex: <your-cluster-name>-sql.postgres.database.azure.com ). Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable","title":"6. Database connection strings"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#update-configuration","text":"","title":"Update Configuration"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#edit-valuesyaml","text":"Open the values.yaml file in ./open-amt-cloud-toolkit/kubernetes/charts/ . Update the service.beta.kubernetes.io/azure-dns-label-name key in the kong section with the desired subdomain name for your URL you would like for your cluster (i.e. myopenamtk8s). kong : proxy : annotations : service.beta.kubernetes.io/azure-dns-label-name : \"<your-subdomain-name>\" Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Update the following keys in the mps section. Key Name Update to Description commonName FQDN for your cluster For AKS , the format is <your-subdomain-name>.<location>.cloudapp.azure.com . This is the fqdnSuffix provided in the outputs section when you Deploy AKS . storageAccessMode ReadWriteMany Must set to ReadWriteMany to scale. The default access mode for storage ( storageAccessMode ) is set to ReadWriteOnce . This only works with a one node cluster. mps : commonName : \"<your-subdomain-name>.<location>.cloudapp.azure.com\" # storageClassName: \"\" storageAccessMode : \"ReadWriteOnce\" #Change to ReadWriteMany replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file.","title":"Edit values.yaml"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#apply-volumes","text":"Provide a PersistentVolume that can match the PersisentVolumeClaim for MPS . For an AKS deployment, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/azure.yaml . Note Changing storageAccessMode will update the PersistentVolumeClaim to request ReadWriteMany , this means you'll need to provide a PersistentVolume that can match that claim. The Azure deployment performed in Deploy AKS creates a Storage Account that can be used. Use the following yaml to provision the volume for the cluster. Provided azure.yaml Example apiVersion : v1 kind : PersistentVolume metadata : name : mps-certs spec : capacity : storage : 1Gi accessModes : - ReadWriteMany azureFile : secretName : azure-secret secretNamespace : default shareName : mps-certs readOnly : false mountOptions : - dir_mode=0755 - file_mode=0755 - uid=1000 - gid=1000 - mfsymlinks - nobrl Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/azure.yaml","title":"Apply Volumes"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#create-databases-and-schema","text":"","title":"Create Databases and Schema"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#enable-access-to-database","text":"Navigate to Home > Resource Groups > Resource Group Name using Microsoft Azure via online. Select the Postgres DB. It will have a Type of Azure Database for PostgreSQL Server . Under Settings in the left-hand menu, select Connection Security . Under Firewall rules, select Add current client IP address . Select Save. Under the Overview tab, take note of the 'Server name' and 'Admin username'. They will be needed in the next steps. Note Remember to delete this firewall rule when finished.","title":"Enable Access to Database"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#create-databases","text":"Use the database schema files to initialize the hosted Postgres DB in the following steps. Where: <HOST> is the location of the Postgres database (Ex: <your-cluster-name>-sql.postgres.database.azure.com ). <USERNAME> is the admin username for the Postgres database (Ex: <postgres-username>@<your-cluster-name>-sql ). Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb' database. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql","title":"Create Databases"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#deploy-open-amt-cloud-toolkit-using-helm","text":"Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Thu Jul 15 11:17:38 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None View the pods. You might notice mps , rps , and openamtstack-vault-0 are not ready. This will change after we initialize and unseal Vault. All others should be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 0/1 Pending 0 2m6s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 2m6s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 2m6s openamtstack-vault-0 0/1 Running 0 2m6s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 2m6s rps-79877bf5c5-dsg5p 0/1 CreateContainerConfigError 0 2m6s webui-6cc48f4d68-6r8b5 1/1 Running 0 2m6s","title":"Deploy Open AMT Cloud Toolkit using Helm"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#initialize-and-unseal-vault","text":"Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine .","title":"Initialize and Unseal Vault"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#vault-token-secret","text":"Add the root token as a secret to the AKS cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault. View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 1/1 Running 0 4m5s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 4m5s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 4m5s openamtstack-vault-0 1/1 Running 0 4m5s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 4m5s rps-79877bf5c5-dsg5p 1/1 Running 0 4m5s webui-6cc48f4d68-6r8b5 1/1 Running 0 4m5s","title":"Vault Token Secret"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-aks/#next-steps","text":"Visit the Sample Web UI using the FQDN name and Continue from the Get Started steps","title":"Next Steps"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/","text":"Amazon Elastic Kubernetes Service (EKS) \u00b6 This tutorial demonstrates how to deploy the Open AMT Cloud Toolkit on a Kubernetes cluster using EKS. To perform a simpler test deployment, use a single-mode cluster locally. See Kubernetes (K8s) . Amazon EKS offers serverless Kubernetes, an integrated continuous integration and continuous delivery (CI/CD) experience, and enterprise-grade security and governance. Learn more about EKS here . Prerequisites \u00b6 kubectl AWS CLI eksctl CLI Helm CLI (v3.5+) PSQL CLI (11.13) Create a New EKS Cluster \u00b6 Follow steps for aws configure to finish configuration of AWS CLI. Follow steps to Create a key pair using Amazon EC2 to create a SSH key for accessing the cluster. Create a new EKS cluster and supporting components. eksctl create cluster --name <cluster-name> --region <region> --with-oidc --ssh-access --ssh-public-key <ssh-keypair-name> --managed Where: <cluster-name> is the name of the new EKS cluster. <region> is the AWS region to deploy the stack (Ex: us-west-2 ). <ssh-keypair-name> is the name of the SSH key from the previous step. Create Postgres DB in RDS \u00b6 Create a Postgres DB by following the steps for Creating an Amazon RDS DB instance . Make sure to set the following configuration settings: Field Set to Virtual private cloud (VPC) Choose the VPC created from your cluster. It should follow the format: 'eksctl- <cluster-name> -cluster/VPC' Public access Yes. In the next steps, we will create Security rules to limit access. VPC security group Choose existing Existing VPC security groups default Configure Virtual Private Cloud (VPC) for access \u00b6 Go to RDS home . Select 'Databases' from the left-hand side menu. Select your created database (Ex: database-1). Under Security in Connectivity & security , click on the VPC under VPC security groups (Ex: default (sg-01b4767ggdcb52825) ). Select Inbound rules . Select Edit inbound rules . Add Two New Rules \u00b6 Rule One: Select Add rule . Under 'Type' select PostgresSQL . Under 'Source' select My IP . Rule Two: Select Add rule . Under 'Type' select PostgresSQL . Under 'Source' select Custom . In the search box, select the security group starting with the label 'eks-cluster-sg'. Select Save rules . Create Databases and Schema \u00b6 Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Use the database schema files to initialize the hosted Postgres DB in the following steps. Note The following commands will prompt for the database password you chose here . Where: <HOST> is the location of the Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). <USERNAME> is the username for the Postgres database. Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb'. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql Where: <HOST> is the location of the Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). <USERNAME> is the username for the Postgres database. Connect to EKS Instance \u00b6 Ensure your kubectl is connected to the EKS cluster you wish to deploy/manage. Provide your region and cluster name. aws eks update-kubeconfig --region <region> --name <cluster-name> Where: <cluster-name> is the name of your EKS cluster. <region> is the AWS region where the cluster is (Ex: us-west-2 ). Create Secrets \u00b6 1. Private Docker Registry Credentials \u00b6 If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server=<your-registry-server> --docker-username=<your-username> --docker-password=<your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password. 2. MPS /KONG JWT \u00b6 This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret. 3. KONG ACL for JWT \u00b6 This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin 4. MPS Web Username and Password \u00b6 This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character 5. Database connection strings \u00b6 Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the username for the Postgres database. <PASSWORD> is the password for the Postgres database. <SERVERURL> is the url for the AWS-hosted Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable Update Configuration \u00b6 Edit values.yaml \u00b6 Open the values.yaml file in the ./open-amt-cloud-toolkit/kubernetes/charts/ directory. Remove the annotations section and service.beta.kubernetes.io/azure-dns-label-name key in the kong: section. These are Azure-specific implementations. kong : proxy : annotations : # Delete this line service.beta.kubernetes.io/azure-dns-label-name : \"<your-domain-name>\" # Delete this line Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Uncomment and update the storageClassName key in the mps section to ebs-sc . mps : commonName : \"\" storageClassName : \"ebs-sc\" # Change to \"ebs-sc\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file. Apply Volumes \u00b6 Provide a StorageClass that can match the PersisentVolumeClaim for MPS . For an EKS deployment, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/aws.yaml . Provided aws.yaml Example kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : ebs-sc provisioner : ebs.csi.aws.com volumeBindingMode : WaitForFirstConsumer Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/aws.yaml Deploy Open AMT Cloud Toolkit using Helm \u00b6 Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Thu Jul 15 11:17:38 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Initialize and Unseal Vault \u00b6 Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine . Vault Token Secret \u00b6 Add the root token as a secret to the EKS cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault. Update commonName in values.yml \u00b6 Get the External-IP for accessing the UI. Note and save the value under 'EXTERNAL-IP'. kubectl get service openamtstack-kong-proxy Update the value for commonName in the mps section in the values.yml file with the External-IP from above. Recall that values.yml is located in ./kubernetes/charts/ . mps : commonName : \"\" # update with External-IP from `kubectl get service` storageClassName : \"ebs-sc\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Update the stack using helm. helm upgrade openamtstack ./kubernetes/charts Amazon EBS CSI driver \u00b6 Follow steps 1-3 for Deploying the Amazon EBS CSI driver to an Amazon EKS cluster . This will enable persistent storage in the cluster. Stop and return before deploying the sample application. This step is unnecessary. Verify running pods \u00b6 View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 1/1 Running 0 4m5s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 4m5s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 4m5s openamtstack-vault-0 1/1 Running 0 4m5s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 4m5s rps-79877bf5c5-dsg5p 1/1 Running 0 4m5s webui-6cc48f4d68-6r8b5 1/1 Running 0 4m5s Next Steps \u00b6 Tip - Accessing the Sample Web UI Find the External-IP/FQDN for the Sample Web UI by running: kubectl get services openamtstack-kong-proxy Warning - Self-signed Certificates Make sure to accept the self-signed certificate by going to port 443 during the first visit to the Sample Web UI . Visit the Sample Web UI using the FQDN name and Continue from the Get Started steps .","title":"EKS"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#amazon-elastic-kubernetes-service-eks","text":"This tutorial demonstrates how to deploy the Open AMT Cloud Toolkit on a Kubernetes cluster using EKS. To perform a simpler test deployment, use a single-mode cluster locally. See Kubernetes (K8s) . Amazon EKS offers serverless Kubernetes, an integrated continuous integration and continuous delivery (CI/CD) experience, and enterprise-grade security and governance. Learn more about EKS here .","title":"Amazon Elastic Kubernetes Service (EKS)"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#prerequisites","text":"kubectl AWS CLI eksctl CLI Helm CLI (v3.5+) PSQL CLI (11.13)","title":"Prerequisites"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#create-a-new-eks-cluster","text":"Follow steps for aws configure to finish configuration of AWS CLI. Follow steps to Create a key pair using Amazon EC2 to create a SSH key for accessing the cluster. Create a new EKS cluster and supporting components. eksctl create cluster --name <cluster-name> --region <region> --with-oidc --ssh-access --ssh-public-key <ssh-keypair-name> --managed Where: <cluster-name> is the name of the new EKS cluster. <region> is the AWS region to deploy the stack (Ex: us-west-2 ). <ssh-keypair-name> is the name of the SSH key from the previous step.","title":"Create a New EKS Cluster"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#create-postgres-db-in-rds","text":"Create a Postgres DB by following the steps for Creating an Amazon RDS DB instance . Make sure to set the following configuration settings: Field Set to Virtual private cloud (VPC) Choose the VPC created from your cluster. It should follow the format: 'eksctl- <cluster-name> -cluster/VPC' Public access Yes. In the next steps, we will create Security rules to limit access. VPC security group Choose existing Existing VPC security groups default","title":"Create Postgres DB in RDS"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#configure-virtual-private-cloud-vpc-for-access","text":"Go to RDS home . Select 'Databases' from the left-hand side menu. Select your created database (Ex: database-1). Under Security in Connectivity & security , click on the VPC under VPC security groups (Ex: default (sg-01b4767ggdcb52825) ). Select Inbound rules . Select Edit inbound rules .","title":"Configure Virtual Private Cloud (VPC) for access"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#add-two-new-rules","text":"Rule One: Select Add rule . Under 'Type' select PostgresSQL . Under 'Source' select My IP . Rule Two: Select Add rule . Under 'Type' select PostgresSQL . Under 'Source' select Custom . In the search box, select the security group starting with the label 'eks-cluster-sg'. Select Save rules .","title":"Add Two New Rules"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#create-databases-and-schema","text":"Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Use the database schema files to initialize the hosted Postgres DB in the following steps. Note The following commands will prompt for the database password you chose here . Where: <HOST> is the location of the Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). <USERNAME> is the username for the Postgres database. Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb'. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql Where: <HOST> is the location of the Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). <USERNAME> is the username for the Postgres database.","title":"Create Databases and Schema"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#connect-to-eks-instance","text":"Ensure your kubectl is connected to the EKS cluster you wish to deploy/manage. Provide your region and cluster name. aws eks update-kubeconfig --region <region> --name <cluster-name> Where: <cluster-name> is the name of your EKS cluster. <region> is the AWS region where the cluster is (Ex: us-west-2 ).","title":"Connect to EKS Instance"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#create-secrets","text":"","title":"Create Secrets"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#1-private-docker-registry-credentials","text":"If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server=<your-registry-server> --docker-username=<your-username> --docker-password=<your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password.","title":"1. Private Docker Registry Credentials"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#2-mpskong-jwt","text":"This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret.","title":"2. MPS/KONG JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#3-kong-acl-for-jwt","text":"This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin","title":"3. KONG ACL for JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#4-mps-web-username-and-password","text":"This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character","title":"4. MPS Web Username and Password"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#5-database-connection-strings","text":"Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the username for the Postgres database. <PASSWORD> is the password for the Postgres database. <SERVERURL> is the url for the AWS-hosted Postgres database (Ex: database-1.jotd7t2abapq.us-west-2.rds.amazonaws.com ). Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable","title":"5. Database connection strings"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#update-configuration","text":"","title":"Update Configuration"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#edit-valuesyaml","text":"Open the values.yaml file in the ./open-amt-cloud-toolkit/kubernetes/charts/ directory. Remove the annotations section and service.beta.kubernetes.io/azure-dns-label-name key in the kong: section. These are Azure-specific implementations. kong : proxy : annotations : # Delete this line service.beta.kubernetes.io/azure-dns-label-name : \"<your-domain-name>\" # Delete this line Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Uncomment and update the storageClassName key in the mps section to ebs-sc . mps : commonName : \"\" storageClassName : \"ebs-sc\" # Change to \"ebs-sc\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file.","title":"Edit values.yaml"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#apply-volumes","text":"Provide a StorageClass that can match the PersisentVolumeClaim for MPS . For an EKS deployment, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/aws.yaml . Provided aws.yaml Example kind : StorageClass apiVersion : storage.k8s.io/v1 metadata : name : ebs-sc provisioner : ebs.csi.aws.com volumeBindingMode : WaitForFirstConsumer Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/aws.yaml","title":"Apply Volumes"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#deploy-open-amt-cloud-toolkit-using-helm","text":"Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Thu Jul 15 11:17:38 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None","title":"Deploy Open AMT Cloud Toolkit using Helm"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#initialize-and-unseal-vault","text":"Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine .","title":"Initialize and Unseal Vault"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#vault-token-secret","text":"Add the root token as a secret to the EKS cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault.","title":"Vault Token Secret"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#update-commonname-in-valuesyml","text":"Get the External-IP for accessing the UI. Note and save the value under 'EXTERNAL-IP'. kubectl get service openamtstack-kong-proxy Update the value for commonName in the mps section in the values.yml file with the External-IP from above. Recall that values.yml is located in ./kubernetes/charts/ . mps : commonName : \"\" # update with External-IP from `kubectl get service` storageClassName : \"ebs-sc\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Update the stack using helm. helm upgrade openamtstack ./kubernetes/charts","title":"Update commonName in values.yml"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#amazon-ebs-csi-driver","text":"Follow steps 1-3 for Deploying the Amazon EBS CSI driver to an Amazon EKS cluster . This will enable persistent storage in the cluster. Stop and return before deploying the sample application. This step is unnecessary.","title":"Amazon EBS CSI driver"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#verify-running-pods","text":"View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-69786bfb47-92mpc 1/1 Running 0 4m5s mpsrouter-9b9bc499b-2tkb2 1/1 Running 0 4m5s openamtstack-kong-68d6c84bcc-fp8dl 2/2 Running 0 4m5s openamtstack-vault-0 1/1 Running 0 4m5s openamtstack-vault-agent-injector-6b564845db-zss78 1/1 Running 0 4m5s rps-79877bf5c5-dsg5p 1/1 Running 0 4m5s webui-6cc48f4d68-6r8b5 1/1 Running 0 4m5s","title":"Verify running pods"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s-eks/#next-steps","text":"Tip - Accessing the Sample Web UI Find the External-IP/FQDN for the Sample Web UI by running: kubectl get services openamtstack-kong-proxy Warning - Self-signed Certificates Make sure to accept the self-signed certificate by going to port 443 during the first visit to the Sample Web UI . Visit the Sample Web UI using the FQDN name and Continue from the Get Started steps .","title":"Next Steps"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/","text":"This tutorial demonstrates how to deploy the Open AMT Cloud Toolkit on a local Kubernetes single-node cluster. Alternatively, you can also deploy using a managed service through a Cloud Service Provider such as Azure Kubernetes Service ( AKS ). See AKS . Kubernetes, also known as K8s, is an open-source system for automating deployment, scaling, and management of containerized applications. Learn more about Kubernetes here . Prerequisites \u00b6 Docker Desktop with Kubernetes Enabled kubectl Helm CLI (v3.5+) PSQL CLI (11.13) Important - For Linux If deploying on a Linux machine, Docker Desktop is not available. You must use Docker Engine alongside a local Kubernetes cluster tool such as minikube or kubeadm . Create Kubernetes Secrets \u00b6 1. Private Docker Registry Credentials \u00b6 If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server=<your-registry-server> --docker-username=<your-username> --docker-password=<your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password. 2. MPS /KONG JWT \u00b6 This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret. 3. KONG ACL for JWT \u00b6 This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin 4. MPS Web Username and Password \u00b6 This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character 5. Database connection strings \u00b6 Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the username for the Postgres database. <PASSWORD> is the password for the Postgres database. <SERVERURL> is the loction for the Postgres database. Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable Update Configuration \u00b6 Edit values.yaml \u00b6 Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Open the values.yaml file in ./open-amt-cloud-toolkit/kubernetes/charts/ . Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Update the commonName key in the mps section with the IP Address of your development device. mps : commonName : \"<your-ip-address>\" # storageClassName: \"\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file. Apply Volumes \u00b6 Provide a PersistentVolume that can match the PersisentVolumeClaim for MPS . For a local, single-node cluster, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/local.yaml . Provided local.yaml Example apiVersion : v1 kind : PersistentVolume metadata : name : mps-certs labels : type : local spec : accessModes : - ReadWriteOnce capacity : storage : 1Gi hostPath : path : \"/mnt/data/mpscerts\" Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/local.yaml Create Databases and Schema \u00b6 Use the database schema files to initialize the hosted Postgres DB in the following steps. Where: <HOST> is the location of the Postgres database. <USERNAME> is the username for the Postgres database. Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb'. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql Deploy Open AMT Cloud Toolkit Using Helm \u00b6 Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Wed Jul 14 12:59:29 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None View the pods. You might notice openamtstack-vault-0 is not ready. This will change after we initialize and unseal Vault. All others should be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-6984b7c69d-8d5gf 1/1 Running 0 5m mpsrouter-9b9bc499b-pwn9j 1/1 Running 0 5m openamtstack-kong-55b65d558c-gzv4d 2/2 Running 0 5m openamtstack-vault-0 0/1 Running 0 5m openamtstack-vault-agent-injector-7fb7dcfcbd-dlqqg 1/1 Running 0 5m rps-79877bf5c5-hnv8t 1/1 Running 0 5m webui-784cd49976-bj7z5 1/1 Running 0 5m Initialize and Unseal Vault \u00b6 Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine . Vault Token Secret \u00b6 Add the root token as a secret to the k8s cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault. View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-6984b7c69d-8d5gf 1/1 Running 0 7m mpsrouter-9b9bc499b-pwn9j 1/1 Running 0 7m openamtstack-kong-55b65d558c-gzv4d 2/2 Running 0 7m openamtstack-vault-0 1/1 Running 0 7m openamtstack-vault-agent-injector-7fb7dcfcbd-dlqqg 1/1 Running 0 7m rps-79877bf5c5-hnv8t 1/1 Running 0 7m webui-784cd49976-bj7z5 1/1 Running 0 7m Next Steps \u00b6 Continue from the Get Started steps","title":"Kubernetes (K8s)"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#prerequisites","text":"Docker Desktop with Kubernetes Enabled kubectl Helm CLI (v3.5+) PSQL CLI (11.13) Important - For Linux If deploying on a Linux machine, Docker Desktop is not available. You must use Docker Engine alongside a local Kubernetes cluster tool such as minikube or kubeadm .","title":"Prerequisites"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#create-kubernetes-secrets","text":"","title":"Create Kubernetes Secrets"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#1-private-docker-registry-credentials","text":"If you are using a private docker registry, you'll need to provide your credentials to K8S. kubectl create secret docker-registry registrycredentials --docker-server=<your-registry-server> --docker-username=<your-username> --docker-password=<your-password> Where: <your-registry-server> is your Private Docker Registry FQDN. <your-username> is your Docker username. <your-password> is your Docker password.","title":"1. Private Docker Registry Credentials"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#2-mpskong-jwt","text":"This is the secret used for generating and verifying JWTs. kubectl create secret generic open-amt-admin-jwt --from-literal=kongCredType=jwt --from-literal=key=\"admin-issuer\" --from-literal=algorithm=HS256 --from-literal=secret=\"<your-secret>\" Where: <your-secret> is your chosen strong secret.","title":"2. MPS/KONG JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#3-kong-acl-for-jwt","text":"This configures KONG with an Access Control List (ACL) to allow an admin user open-amt-admin to access endpoints using the JWT retrieved when logging in. kubectl create secret generic open-amt-admin-acl --from-literal=kongCredType=acl --from-literal=group=open-amt-admin","title":"3. KONG ACL for JWT"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#4-mps-web-username-and-password","text":"This is the username and password that is used for requesting a JWT. These credentials are also used for logging into the Sample Web UI . kubectl create secret generic mpsweb --from-literal=user=<your-username> --from-literal=password=<your-password> Where: <your-username> is a username of your choice. <your-password> is a strong password of your choice. Important - Using Strong Passwords The password must meet standard, strong password requirements: 8 to 32 characters One uppercase, one lowercase, one numerical digit, one special character","title":"4. MPS Web Username and Password"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#5-database-connection-strings","text":"Configure the database connection strings used by MPS , RPS , and MPS Router. Where: <USERNAME> is the username for the Postgres database. <PASSWORD> is the password for the Postgres database. <SERVERURL> is the loction for the Postgres database. Create RPS connection string secret. kubectl create secret generic rps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/rpsdb?sslmode=no-verify Create MPS Router connection string secret. kubectl create secret generic mpsrouter --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=no-verify Create MPS connection string secret. kubectl create secret generic mps --from-literal=connectionString=postgresql://<USERNAME>:<PASSWORD>@<SERVERURL>:5432/mpsdb?sslmode=disable","title":"5. Database connection strings"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#update-configuration","text":"","title":"Update Configuration"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#edit-valuesyaml","text":"Clone the Open AMT Cloud Toolkit . git clone --recursive https://github.com/open-amt-cloud-toolkit/open-amt-cloud-toolkit --branch v2.0.1 Open the values.yaml file in ./open-amt-cloud-toolkit/kubernetes/charts/ . Update the mps , rps , webui , and mpsrouter keys to point to your own container registries. images : mps : \"vprodemo.azurecr.io/mps:latest\" rps : \"vprodemo.azurecr.io/rps:latest\" webui : \"vprodemo.azurecr.io/webui:latest\" mpsrouter : \"vprodemo.azurecr.io/mpsrouter:latest\" Update the commonName key in the mps section with the IP Address of your development device. mps : commonName : \"<your-ip-address>\" # storageClassName: \"\" storageAccessMode : \"ReadWriteOnce\" replicaCount : 1 logLevel : \"silly\" jwtExpiration : 1440 Save and close the file.","title":"Edit values.yaml"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#apply-volumes","text":"Provide a PersistentVolume that can match the PersisentVolumeClaim for MPS . For a local, single-node cluster, you can use the following example YAML. It is provided in ./kubernetes/charts/volumes/local.yaml . Provided local.yaml Example apiVersion : v1 kind : PersistentVolume metadata : name : mps-certs labels : type : local spec : accessModes : - ReadWriteOnce capacity : storage : 1Gi hostPath : path : \"/mnt/data/mpscerts\" Apply it to your cluster. kubectl apply -f ./kubernetes/charts/volumes/local.yaml","title":"Apply Volumes"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#create-databases-and-schema","text":"Use the database schema files to initialize the hosted Postgres DB in the following steps. Where: <HOST> is the location of the Postgres database. <USERNAME> is the username for the Postgres database. Create the RPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -c \"CREATE DATABASE rpsdb\" Create tables for the new 'rpsdb'. psql -h <HOST> -p 5432 -d rpsdb -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/init.sql Create the MPS database. psql -h <HOST> -p 5432 -d postgres -U <USERNAME> -W -f ./open-amt-cloud-toolkit/data/initMPS.sql","title":"Create Databases and Schema"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#deploy-open-amt-cloud-toolkit-using-helm","text":"Deploy using Helm. helm install openamtstack ./kubernetes/charts Success NAME: openamtstack LAST DEPLOYED: Wed Jul 14 12:59:29 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None View the pods. You might notice openamtstack-vault-0 is not ready. This will change after we initialize and unseal Vault. All others should be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-6984b7c69d-8d5gf 1/1 Running 0 5m mpsrouter-9b9bc499b-pwn9j 1/1 Running 0 5m openamtstack-kong-55b65d558c-gzv4d 2/2 Running 0 5m openamtstack-vault-0 0/1 Running 0 5m openamtstack-vault-agent-injector-7fb7dcfcbd-dlqqg 1/1 Running 0 5m rps-79877bf5c5-hnv8t 1/1 Running 0 5m webui-784cd49976-bj7z5 1/1 Running 0 5m","title":"Deploy Open AMT Cloud Toolkit Using Helm"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#initialize-and-unseal-vault","text":"Danger - Download and Save Vault Keys Make sure to download your Vault credentials and save them in a secure location when unsealing Vault. If the keys are lost, a new Vault will need to be started and any stored data will be lost. Tip - Finding the Vault UI External IP Address The external IP of your Vault UI service can be found by running: kubectl get services openamtstack-vault-ui Please refer to HashiCorp documentation on how to Initialize and unseal Vault . Stop and return here after signing in to Vault with the root_token . After initializing and unsealing the vault, you need to enable the Key Value engine. Click Enable New Engine + . Choose KV . Click Next . Leave the default path and choose version 2 from the drop down. Click Enable Engine .","title":"Initialize and Unseal Vault"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#vault-token-secret","text":"Add the root token as a secret to the k8s cluster so that the services can access Vault. kubectl create secret generic vault --from-literal=vaultKey=<your-root-token> Where: <your-root-token> is your root_token generated by Vault. View the pods. All pods should now be Ready and Running. kubectl get pods Success NAME READY STATUS RESTARTS AGE mps-6984b7c69d-8d5gf 1/1 Running 0 7m mpsrouter-9b9bc499b-pwn9j 1/1 Running 0 7m openamtstack-kong-55b65d558c-gzv4d 2/2 Running 0 7m openamtstack-vault-0 1/1 Running 0 7m openamtstack-vault-agent-injector-7fb7dcfcbd-dlqqg 1/1 Running 0 7m rps-79877bf5c5-hnv8t 1/1 Running 0 7m webui-784cd49976-bj7z5 1/1 Running 0 7m","title":"Vault Token Secret"},{"location":"Tutorials/Scaling/Kubernetes/deployingk8s/#next-steps","text":"Continue from the Get Started steps","title":"Next Steps"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/","text":"Enabling KUMA Service Mesh (Optional) \u00b6 For enhancing security in the Kubernetes deployment, use KUMA Service Mesh to enable mTLS between services. To learn more about KUMA visit their documentation . Install KUMA w/ Helm \u00b6 Follow the instructions for installing KUMA with helm . Create Service Mesh \u00b6 After KUMA is installed, next create a service mesh with mTLS enabled: echo \"apiVersion: kuma.io/v1alpha1 kind: Mesh metadata: name: open-amt-cloud-toolkit-mesh spec: mtls: enabledBackend: open-amt-cloud-toolkit-cert backends: - name: open-amt-cloud-toolkit-cert type: builtin enabled: true\" | kubectl apply -f - Turn On Sidecar Injection \u00b6 After the mesh is created, turn on sidecar-injection for the open-amt-cloud-toolkit services with: echo \"apiVersion: v1 kind: Namespace metadata: name: default namespace: default annotations: kuma.io/sidecar-injection: enabled kuma.io/mesh: open-amt-cloud-toolkit-mesh\" | kubectl apply -f - Delete all pods to ensure updated annotations from previous command take effect: kubectl delete pod --all -n default Configure Traffic Permissions \u00b6 Finally, we need to allow traffic between services: echo \"apiVersion: kuma.io/v1alpha1 kind: TrafficPermission mesh: open-amt-cloud-toolkit-mesh metadata: namespace: default name: allow-all-open-amt-cloud-toolkit-mesh spec: sources: - match: kuma.io/service: '*' destinations: - match: kuma.io/service: '*'\" | kubectl apply -f - After applying traffic permissions, you should now be able to use the Open AMT Cloud Toolkit and continue logging into the web portal following the setup instructions in the Getting Started section .","title":"KUMA Service Mesh"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/#enabling-kuma-service-mesh-optional","text":"For enhancing security in the Kubernetes deployment, use KUMA Service Mesh to enable mTLS between services. To learn more about KUMA visit their documentation .","title":"Enabling KUMA Service Mesh (Optional)"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/#install-kuma-w-helm","text":"Follow the instructions for installing KUMA with helm .","title":"Install KUMA w/ Helm"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/#create-service-mesh","text":"After KUMA is installed, next create a service mesh with mTLS enabled: echo \"apiVersion: kuma.io/v1alpha1 kind: Mesh metadata: name: open-amt-cloud-toolkit-mesh spec: mtls: enabledBackend: open-amt-cloud-toolkit-cert backends: - name: open-amt-cloud-toolkit-cert type: builtin enabled: true\" | kubectl apply -f -","title":"Create Service Mesh"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/#turn-on-sidecar-injection","text":"After the mesh is created, turn on sidecar-injection for the open-amt-cloud-toolkit services with: echo \"apiVersion: v1 kind: Namespace metadata: name: default namespace: default annotations: kuma.io/sidecar-injection: enabled kuma.io/mesh: open-amt-cloud-toolkit-mesh\" | kubectl apply -f - Delete all pods to ensure updated annotations from previous command take effect: kubectl delete pod --all -n default","title":"Turn On Sidecar Injection"},{"location":"Tutorials/Scaling/Kubernetes/service-mesh/#configure-traffic-permissions","text":"Finally, we need to allow traffic between services: echo \"apiVersion: kuma.io/v1alpha1 kind: TrafficPermission mesh: open-amt-cloud-toolkit-mesh metadata: namespace: default name: allow-all-open-amt-cloud-toolkit-mesh spec: sources: - match: kuma.io/service: '*' destinations: - match: kuma.io/service: '*'\" | kubectl apply -f - After applying traffic permissions, you should now be able to use the Open AMT Cloud Toolkit and continue logging into the web portal following the setup instructions in the Getting Started section .","title":"Configure Traffic Permissions"}]}